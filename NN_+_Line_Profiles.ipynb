{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN + Line Profiles.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlejandroMllo/UAV-Human-Influence-Detection/blob/master/NN_%2B_Line_Profiles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_EGnniPUTJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cmath\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_cvclU3UeKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def laguerre_gauss_filter(side_size, w):\n",
        "  \"\"\"\n",
        "  Computes and returns a matrix containing the Laguerre-Gauss filter.\n",
        "  \"\"\"\n",
        "  \n",
        "  scale = (1.j * math.pow(math.pi, 2) * math.pow(w, 4))\n",
        "  # Not sure if `scale` is the appropriate name\n",
        "  power_scale = -math.pow(math.pi, 2) * math.pow(w, 2)\n",
        "  # Not sure if `power_scale` is the appropriate name\n",
        "  \n",
        "  filter = np.zeros((side_size, side_size), dtype=complex)\n",
        "  \n",
        "  for x in range(side_size):\n",
        "    x_squared = math.pow(x, 2)\n",
        "    for y in range(side_size):\n",
        "      power = cmath.exp(power_scale * (x_squared + math.pow(y, 2)))\n",
        "      \n",
        "      filter[x, y] = scale * complex(x, y) * power\n",
        "    # print('Coord:', x, y, scale * complex(x, y) * power)\n",
        "      \n",
        "  return filter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNIj9GBiUfs0",
        "colab_type": "code",
        "outputId": "af0055a5-542a-45be-d7c4-18aab039a418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImwhQm7qUoUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rgb2grayscale(rgb_img):\n",
        "  \n",
        "  if rgb_img.ndim != 3:\n",
        "    # print('returning non rgb image')\n",
        "    return rgb_img\n",
        "  \n",
        "  img = np.zeros(rgb_img.shape)\n",
        "  img[:, :, 0] = rgb_img[:, :, 0] * 0.2125 # RED\n",
        "  img[:, :, 1] = rgb_img[:, :, 1] * 0.7154 # GREEN\n",
        "  img[:, :, 2] = rgb_img[:, :, 2] * 0.0721 # BLUE\n",
        "\n",
        "  return np.sum(img, axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIahfD4IVBFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kernel_transform(batch, kernel=np.fft.fft2):\n",
        "  \n",
        "  transformed_batch = []\n",
        "  \n",
        "  for instance in batch:\n",
        "    \n",
        "    instance = rgb2grayscale(instance)\n",
        "    transformed = kernel(instance)\n",
        "    transformed_batch.append(transformed)\n",
        "    \n",
        "  return np.array(transformed_batch)\n",
        "\n",
        "\n",
        "def convolve(transformed_kernel, batch):\n",
        "  \n",
        "  convolved_batch = []\n",
        "  \n",
        "  for instance in batch:\n",
        "    conv = np.multiply(transformed_kernel, instance)\n",
        "    convolved_batch.append(conv)\n",
        "    \n",
        "  return np.array(convolved_batch)\n",
        "\n",
        "\n",
        "def shift(batch):\n",
        "  \n",
        "  shifted_batch = []\n",
        "  \n",
        "  for instance in batch:\n",
        "    shifted = np.fft.fftshift(instance)\n",
        "    shifted_batch.append(shifted)\n",
        "    \n",
        "  return np.array(shifted_batch)\n",
        "\n",
        "\n",
        "def line_profile(batch, axis=1):\n",
        "  # Axis 0: y axis\n",
        "  # Axis 1: x axis\n",
        "  # Equivalent axes definition to numpy.\n",
        "  \n",
        "  line_profiles = []\n",
        "  \n",
        "  num_instances = batch.shape[0]\n",
        "  \n",
        "  for i in range(num_instances):\n",
        "   \n",
        "    instance = batch[i]\n",
        "    axis_length = instance.shape[1 - axis] - 1\n",
        "    \n",
        "    if axis == 0:\n",
        "      line_profiles.append(instance[:,axis_length//2])\n",
        "    else:\n",
        "      line_profiles.append(instance[axis_length//2,:])\n",
        "      \n",
        "  return np.array(line_profiles)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba811tUGVMv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ft_pipeline(transformed_filter, sample):\n",
        "  \n",
        "  transformed = kernel_transform(sample)\n",
        "  convolved = convolve(transformed_filter, transformed)\n",
        "  shifted = shift(convolved)\n",
        "  x_profile = line_profile(shifted, axis=1)\n",
        "  y_profile = line_profile(shifted, axis=0)\n",
        "  \n",
        "  return x_profile, y_profile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgEh5y0ybxCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorized_phase = np.vectorize(cmath.phase)\n",
        "vectorized_amplitude = np.vectorize(np.abs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYpId0wUVkhH",
        "colab_type": "text"
      },
      "source": [
        "### Data Handling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4nhusOLVnCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -- Find files\n",
        "\n",
        "def find_files(path):\n",
        "  \n",
        "  files = next(os.walk(path))[2]\n",
        "  return np.array(sorted(\n",
        "            files, key=lambda f: int(\"\".join(list(filter(str.isdigit, f))))\n",
        "         ))\n",
        "  \n",
        "\n",
        "def load_images(image_names, path):\n",
        "  \n",
        "  images = []\n",
        "  \n",
        "  for name in image_names:\n",
        "    img_path = path + name\n",
        "    images.append(mpimg.imread(img_path))\n",
        "    \n",
        "  return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY3U51nQUo6H",
        "colab_type": "text"
      },
      "source": [
        "# Architecture Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQWdUcJeUr8z",
        "colab_type": "text"
      },
      "source": [
        "## Shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OglR2RzeWbDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lg_28 = laguerre_gauss_filter(28, 0.9)\n",
        "ft_lg_28 = np.fft.fft2(lg_28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OEBREA5Uu1_",
        "colab_type": "text"
      },
      "source": [
        "### Hand-drawn unfilled shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqTF2CghUlvh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shapes_dataset_path = 'drive/My Drive/PI 1/Datasets/shapes'\n",
        "\n",
        "triangles_path = shapes_dataset_path + '/triangles/'\n",
        "squares_path = shapes_dataset_path + '/squares/'\n",
        "circles_path = shapes_dataset_path + '/circles/'\n",
        "\n",
        "\n",
        "triangles = find_files(triangles_path)\n",
        "squares = find_files(squares_path)\n",
        "circles = find_files(circles_path)\n",
        "\n",
        "\n",
        "triangle_images = load_images(triangles, triangles_path)\n",
        "square_images = load_images(squares, squares_path)\n",
        "circle_images = load_images(circles, circles_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jrsXOA9V54O",
        "colab_type": "code",
        "outputId": "185212c0-2dc4-49b5-ebd1-b92b4eb1e23d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "shapes_classes = [0, 1, 2] # 0=triangles; 1=squares; 2=circles\n",
        "shapes_images = np.array([triangle_images, square_images, circle_images]).reshape((-1, 28, 28, 3))\n",
        "shapes_labels = np.array( ([0]*len(triangle_images)) + ([1]*len(square_images)) + ([2]*len(circle_images)) )\n",
        "\n",
        "print(shapes_images.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(300, 28, 28, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_uHKD6yU3HX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Extract features from images\n",
        "x_profiles, y_profiles = ft_pipeline(ft_lg_28, shapes_images)\n",
        "\n",
        "x_profiles = vectorized_amplitude(np.concatenate((x_profiles, y_profiles), axis=1))\n",
        "\n",
        "# Split datasets\n",
        "train_features, val_features, train_labels, val_labels = \\\n",
        "  train_test_split(x_profiles, shapes_labels, test_size=0.6, random_state=420)\n",
        "\n",
        "validation_features, test_features, validation_labels, test_labels = \\\n",
        "  train_test_split(val_features, val_labels, test_size=0.5, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pyq8FG6XeeN",
        "colab_type": "text"
      },
      "source": [
        "#### KNN Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKcisU87VD5C",
        "colab_type": "code",
        "outputId": "88afa4a7-165b-4458-950f-310034df672e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "clf = KNeighborsClassifier(4)\n",
        "clf.fit(train_features, train_labels)\n",
        "\n",
        "score = clf.score(validation_features, validation_labels)\n",
        "\n",
        "print('KNN score =', score)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN score = 0.8222222222222222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "copPeueU1RgX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39a759fc-1b48-4d84-d802-2dc1ab94f6f4"
      },
      "source": [
        "clf.score(test_features, test_labels)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7777777777777778"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5iFFs3HXjL_",
        "colab_type": "text"
      },
      "source": [
        "#### MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq9gc8EEXdUf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ba95fec-823d-4c5d-a4e0-f495a9d5c169"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "num_classes = 3\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
        "validation_labels = keras.utils.to_categorical(validation_labels, num_classes)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_-jbiIMXw9A",
        "colab_type": "code",
        "outputId": "08b0ec23-b61a-4b8f-a594-00ac818010e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(28, activation='relu', input_dim=56, name='my1'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(56, activation='relu', name='my3'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(56, activation='relu', name='my4'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(8, activation='relu', name='my5'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_hinge, #categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "epochs = 2048\n",
        "batch_size = 8\n",
        "\n",
        "model.fit(train_features, train_labels,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(validation_features, validation_labels))\n",
        "score = model.evaluate(validation_features, validation_labels, verbose=0)\n",
        "print('Test loss (x_profiles):', score[0])\n",
        "print('Test accuracy (x_profiles):', score[1])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Train on 120 samples, validate on 90 samples\n",
            "Epoch 1/2048\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 1.0045 - acc: 0.3083 - val_loss: 1.0005 - val_acc: 0.4222\n",
            "Epoch 2/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 1.0013 - acc: 0.3583 - val_loss: 1.0008 - val_acc: 0.3889\n",
            "Epoch 3/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 1.0013 - acc: 0.3250 - val_loss: 1.0006 - val_acc: 0.3889\n",
            "Epoch 4/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 1.0012 - acc: 0.3000 - val_loss: 1.0002 - val_acc: 0.3556\n",
            "Epoch 5/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 1.0005 - acc: 0.3083 - val_loss: 1.0002 - val_acc: 0.3889\n",
            "Epoch 6/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 1.0004 - acc: 0.4083 - val_loss: 1.0002 - val_acc: 0.2556\n",
            "Epoch 7/2048\n",
            "120/120 [==============================] - 0s 283us/step - loss: 1.0003 - acc: 0.3417 - val_loss: 1.0005 - val_acc: 0.2556\n",
            "Epoch 8/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 1.0003 - acc: 0.3083 - val_loss: 1.0003 - val_acc: 0.2556\n",
            "Epoch 9/2048\n",
            "120/120 [==============================] - 0s 290us/step - loss: 1.0004 - acc: 0.2583 - val_loss: 1.0007 - val_acc: 0.2556\n",
            "Epoch 10/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 1.0003 - acc: 0.3833 - val_loss: 1.0003 - val_acc: 0.3889\n",
            "Epoch 11/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 1.0003 - acc: 0.3167 - val_loss: 1.0001 - val_acc: 0.3556\n",
            "Epoch 12/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 1.0005 - acc: 0.2833 - val_loss: 1.0004 - val_acc: 0.2556\n",
            "Epoch 13/2048\n",
            "120/120 [==============================] - 0s 378us/step - loss: 1.0003 - acc: 0.3333 - val_loss: 1.0003 - val_acc: 0.2556\n",
            "Epoch 14/2048\n",
            "120/120 [==============================] - 0s 360us/step - loss: 1.0004 - acc: 0.4000 - val_loss: 1.0007 - val_acc: 0.2556\n",
            "Epoch 15/2048\n",
            "120/120 [==============================] - 0s 425us/step - loss: 1.0004 - acc: 0.3000 - val_loss: 1.0003 - val_acc: 0.2556\n",
            "Epoch 16/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 1.0003 - acc: 0.3917 - val_loss: 1.0003 - val_acc: 0.2556\n",
            "Epoch 17/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 1.0003 - acc: 0.3667 - val_loss: 1.0003 - val_acc: 0.2556\n",
            "Epoch 18/2048\n",
            "120/120 [==============================] - 0s 296us/step - loss: 1.0003 - acc: 0.3583 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 19/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 1.0003 - acc: 0.2750 - val_loss: 1.0003 - val_acc: 0.3889\n",
            "Epoch 20/2048\n",
            "120/120 [==============================] - 0s 296us/step - loss: 1.0004 - acc: 0.3333 - val_loss: 1.0003 - val_acc: 0.3556\n",
            "Epoch 21/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 1.0002 - acc: 0.3417 - val_loss: 1.0001 - val_acc: 0.2556\n",
            "Epoch 22/2048\n",
            "120/120 [==============================] - 0s 354us/step - loss: 1.0003 - acc: 0.3000 - val_loss: 1.0002 - val_acc: 0.3889\n",
            "Epoch 23/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 1.0003 - acc: 0.3333 - val_loss: 1.0005 - val_acc: 0.3889\n",
            "Epoch 24/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 1.0005 - acc: 0.3583 - val_loss: 1.0003 - val_acc: 0.3889\n",
            "Epoch 25/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 1.0003 - acc: 0.3250 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 26/2048\n",
            "120/120 [==============================] - 0s 345us/step - loss: 1.0003 - acc: 0.3417 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 27/2048\n",
            "120/120 [==============================] - 0s 384us/step - loss: 1.0003 - acc: 0.2917 - val_loss: 1.0002 - val_acc: 0.3889\n",
            "Epoch 28/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 1.0003 - acc: 0.3000 - val_loss: 1.0001 - val_acc: 0.2556\n",
            "Epoch 29/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 1.0002 - acc: 0.3417 - val_loss: 1.0003 - val_acc: 0.2556\n",
            "Epoch 30/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 1.0003 - acc: 0.3083 - val_loss: 1.0001 - val_acc: 0.2556\n",
            "Epoch 31/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 1.0003 - acc: 0.2750 - val_loss: 1.0005 - val_acc: 0.2556\n",
            "Epoch 32/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.9998 - acc: 0.4083 - val_loss: 1.0005 - val_acc: 0.3889\n",
            "Epoch 33/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 1.0008 - acc: 0.2667 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 34/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 1.0001 - acc: 0.3833 - val_loss: 1.0001 - val_acc: 0.3556\n",
            "Epoch 35/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 1.0002 - acc: 0.2917 - val_loss: 1.0002 - val_acc: 0.2556\n",
            "Epoch 36/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 1.0003 - acc: 0.2500 - val_loss: 1.0002 - val_acc: 0.3889\n",
            "Epoch 37/2048\n",
            "120/120 [==============================] - 0s 349us/step - loss: 1.0003 - acc: 0.2917 - val_loss: 1.0002 - val_acc: 0.2556\n",
            "Epoch 38/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 1.0002 - acc: 0.3333 - val_loss: 1.0004 - val_acc: 0.2556\n",
            "Epoch 39/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 1.0003 - acc: 0.2750 - val_loss: 1.0002 - val_acc: 0.2556\n",
            "Epoch 40/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 1.0003 - acc: 0.3000 - val_loss: 1.0003 - val_acc: 0.2556\n",
            "Epoch 41/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 1.0002 - acc: 0.3250 - val_loss: 1.0002 - val_acc: 0.3889\n",
            "Epoch 42/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 1.0001 - acc: 0.3250 - val_loss: 1.0002 - val_acc: 0.2556\n",
            "Epoch 43/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 1.0004 - acc: 0.2583 - val_loss: 1.0002 - val_acc: 0.2556\n",
            "Epoch 44/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 1.0002 - acc: 0.3000 - val_loss: 1.0002 - val_acc: 0.3889\n",
            "Epoch 45/2048\n",
            "120/120 [==============================] - 0s 355us/step - loss: 1.0002 - acc: 0.3500 - val_loss: 1.0003 - val_acc: 0.3889\n",
            "Epoch 46/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 1.0003 - acc: 0.3000 - val_loss: 1.0002 - val_acc: 0.3889\n",
            "Epoch 47/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 1.0004 - acc: 0.2583 - val_loss: 1.0002 - val_acc: 0.3889\n",
            "Epoch 48/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 1.0003 - acc: 0.2417 - val_loss: 1.0001 - val_acc: 0.3556\n",
            "Epoch 49/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 1.0003 - acc: 0.2417 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 50/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 1.0002 - acc: 0.3500 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 51/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 1.0003 - acc: 0.2833 - val_loss: 1.0004 - val_acc: 0.2556\n",
            "Epoch 52/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 1.0003 - acc: 0.2750 - val_loss: 1.0007 - val_acc: 0.2556\n",
            "Epoch 53/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 1.0004 - acc: 0.2417 - val_loss: 1.0002 - val_acc: 0.3556\n",
            "Epoch 54/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 1.0002 - acc: 0.3333 - val_loss: 1.0002 - val_acc: 0.3889\n",
            "Epoch 55/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 1.0002 - acc: 0.3500 - val_loss: 1.0004 - val_acc: 0.3889\n",
            "Epoch 56/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 1.0002 - acc: 0.3250 - val_loss: 1.0001 - val_acc: 0.3556\n",
            "Epoch 57/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 1.0002 - acc: 0.3833 - val_loss: 1.0003 - val_acc: 0.2556\n",
            "Epoch 58/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 1.0002 - acc: 0.3167 - val_loss: 1.0006 - val_acc: 0.2556\n",
            "Epoch 59/2048\n",
            "120/120 [==============================] - 0s 344us/step - loss: 1.0003 - acc: 0.3583 - val_loss: 1.0004 - val_acc: 0.3556\n",
            "Epoch 60/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 1.0002 - acc: 0.3083 - val_loss: 1.0003 - val_acc: 0.2556\n",
            "Epoch 61/2048\n",
            "120/120 [==============================] - 0s 344us/step - loss: 1.0003 - acc: 0.3333 - val_loss: 1.0001 - val_acc: 0.3556\n",
            "Epoch 62/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 1.0003 - acc: 0.3417 - val_loss: 1.0003 - val_acc: 0.3889\n",
            "Epoch 63/2048\n",
            "120/120 [==============================] - 0s 350us/step - loss: 1.0002 - acc: 0.4000 - val_loss: 1.0002 - val_acc: 0.2556\n",
            "Epoch 64/2048\n",
            "120/120 [==============================] - 0s 345us/step - loss: 1.0004 - acc: 0.3250 - val_loss: 1.0004 - val_acc: 0.2556\n",
            "Epoch 65/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 1.0000 - acc: 0.3417 - val_loss: 1.0003 - val_acc: 0.3556\n",
            "Epoch 66/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 1.0003 - acc: 0.2750 - val_loss: 1.0004 - val_acc: 0.2556\n",
            "Epoch 67/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 1.0003 - acc: 0.2833 - val_loss: 1.0002 - val_acc: 0.2556\n",
            "Epoch 68/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 1.0002 - acc: 0.3000 - val_loss: 1.0002 - val_acc: 0.2556\n",
            "Epoch 69/2048\n",
            "120/120 [==============================] - 0s 355us/step - loss: 1.0004 - acc: 0.2333 - val_loss: 1.0004 - val_acc: 0.2556\n",
            "Epoch 70/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 1.0003 - acc: 0.3417 - val_loss: 1.0003 - val_acc: 0.3556\n",
            "Epoch 71/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 1.0001 - acc: 0.3250 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 72/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 1.0000 - acc: 0.4083 - val_loss: 1.0003 - val_acc: 0.2556\n",
            "Epoch 73/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 1.0004 - acc: 0.2833 - val_loss: 1.0003 - val_acc: 0.2556\n",
            "Epoch 74/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 1.0003 - acc: 0.3333 - val_loss: 1.0002 - val_acc: 0.2556\n",
            "Epoch 75/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 1.0002 - acc: 0.3583 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 76/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 1.0003 - acc: 0.2917 - val_loss: 1.0002 - val_acc: 0.3556\n",
            "Epoch 77/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 1.0002 - acc: 0.3583 - val_loss: 1.0002 - val_acc: 0.2556\n",
            "Epoch 78/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 1.0002 - acc: 0.2833 - val_loss: 1.0003 - val_acc: 0.3889\n",
            "Epoch 79/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 1.0003 - acc: 0.3083 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 80/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 1.0003 - acc: 0.2417 - val_loss: 1.0005 - val_acc: 0.3889\n",
            "Epoch 81/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 1.0003 - acc: 0.3000 - val_loss: 1.0005 - val_acc: 0.2556\n",
            "Epoch 82/2048\n",
            "120/120 [==============================] - 0s 345us/step - loss: 1.0003 - acc: 0.3333 - val_loss: 1.0002 - val_acc: 0.2556\n",
            "Epoch 83/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 1.0002 - acc: 0.3833 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 84/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 1.0002 - acc: 0.3417 - val_loss: 1.0005 - val_acc: 0.2556\n",
            "Epoch 85/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 1.0004 - acc: 0.2583 - val_loss: 1.0003 - val_acc: 0.2556\n",
            "Epoch 86/2048\n",
            "120/120 [==============================] - 0s 340us/step - loss: 1.0002 - acc: 0.3250 - val_loss: 1.0002 - val_acc: 0.3889\n",
            "Epoch 87/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 1.0002 - acc: 0.3667 - val_loss: 1.0002 - val_acc: 0.2556\n",
            "Epoch 88/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 1.0003 - acc: 0.3583 - val_loss: 1.0000 - val_acc: 0.3889\n",
            "Epoch 89/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 1.0003 - acc: 0.3000 - val_loss: 1.0002 - val_acc: 0.3889\n",
            "Epoch 90/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 1.0003 - acc: 0.3167 - val_loss: 1.0002 - val_acc: 0.2556\n",
            "Epoch 91/2048\n",
            "120/120 [==============================] - 0s 352us/step - loss: 1.0003 - acc: 0.2833 - val_loss: 1.0002 - val_acc: 0.3889\n",
            "Epoch 92/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 1.0003 - acc: 0.2667 - val_loss: 1.0002 - val_acc: 0.3889\n",
            "Epoch 93/2048\n",
            "120/120 [==============================] - 0s 340us/step - loss: 1.0003 - acc: 0.3333 - val_loss: 1.0003 - val_acc: 0.3556\n",
            "Epoch 94/2048\n",
            "120/120 [==============================] - 0s 296us/step - loss: 1.0003 - acc: 0.2833 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 95/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 1.0002 - acc: 0.4417 - val_loss: 1.0003 - val_acc: 0.2556\n",
            "Epoch 96/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 1.0002 - acc: 0.3750 - val_loss: 1.0002 - val_acc: 0.3889\n",
            "Epoch 97/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 1.0003 - acc: 0.3250 - val_loss: 1.0000 - val_acc: 0.3556\n",
            "Epoch 98/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 1.0002 - acc: 0.3083 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 99/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 1.0002 - acc: 0.3250 - val_loss: 1.0002 - val_acc: 0.3556\n",
            "Epoch 100/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 1.0003 - acc: 0.3167 - val_loss: 1.0001 - val_acc: 0.2556\n",
            "Epoch 101/2048\n",
            "120/120 [==============================] - 0s 344us/step - loss: 1.0003 - acc: 0.3000 - val_loss: 1.0002 - val_acc: 0.3556\n",
            "Epoch 102/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 1.0002 - acc: 0.3500 - val_loss: 1.0001 - val_acc: 0.3556\n",
            "Epoch 103/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 1.0001 - acc: 0.3667 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 104/2048\n",
            "120/120 [==============================] - 0s 295us/step - loss: 1.0004 - acc: 0.2667 - val_loss: 1.0004 - val_acc: 0.3556\n",
            "Epoch 105/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 1.0000 - acc: 0.3583 - val_loss: 1.0000 - val_acc: 0.3889\n",
            "Epoch 106/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 1.0006 - acc: 0.3333 - val_loss: 1.0002 - val_acc: 0.3556\n",
            "Epoch 107/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 1.0002 - acc: 0.3667 - val_loss: 1.0005 - val_acc: 0.2556\n",
            "Epoch 108/2048\n",
            "120/120 [==============================] - 0s 290us/step - loss: 1.0001 - acc: 0.3917 - val_loss: 1.0002 - val_acc: 0.3889\n",
            "Epoch 109/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 1.0002 - acc: 0.2833 - val_loss: 1.0004 - val_acc: 0.3556\n",
            "Epoch 110/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 1.0002 - acc: 0.3083 - val_loss: 1.0004 - val_acc: 0.3889\n",
            "Epoch 111/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 1.0002 - acc: 0.3833 - val_loss: 1.0002 - val_acc: 0.3556\n",
            "Epoch 112/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 1.0002 - acc: 0.3250 - val_loss: 1.0002 - val_acc: 0.3889\n",
            "Epoch 113/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 1.0003 - acc: 0.3417 - val_loss: 1.0003 - val_acc: 0.2556\n",
            "Epoch 114/2048\n",
            "120/120 [==============================] - 0s 295us/step - loss: 1.0003 - acc: 0.3250 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 115/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 1.0003 - acc: 0.3500 - val_loss: 1.0004 - val_acc: 0.2556\n",
            "Epoch 116/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 1.0002 - acc: 0.2917 - val_loss: 1.0002 - val_acc: 0.2556\n",
            "Epoch 117/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 1.0003 - acc: 0.3333 - val_loss: 1.0004 - val_acc: 0.3556\n",
            "Epoch 118/2048\n",
            "120/120 [==============================] - 0s 360us/step - loss: 1.0003 - acc: 0.3417 - val_loss: 1.0003 - val_acc: 0.2556\n",
            "Epoch 119/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 1.0003 - acc: 0.3333 - val_loss: 1.0000 - val_acc: 0.3889\n",
            "Epoch 120/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 1.0003 - acc: 0.3333 - val_loss: 1.0000 - val_acc: 0.3889\n",
            "Epoch 121/2048\n",
            "120/120 [==============================] - 0s 289us/step - loss: 1.0002 - acc: 0.3417 - val_loss: 1.0004 - val_acc: 0.3556\n",
            "Epoch 122/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 1.0003 - acc: 0.3167 - val_loss: 1.0003 - val_acc: 0.3889\n",
            "Epoch 123/2048\n",
            "120/120 [==============================] - 0s 356us/step - loss: 1.0002 - acc: 0.3667 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 124/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 1.0002 - acc: 0.3500 - val_loss: 1.0002 - val_acc: 0.3889\n",
            "Epoch 125/2048\n",
            "120/120 [==============================] - 0s 360us/step - loss: 1.0004 - acc: 0.3167 - val_loss: 1.0002 - val_acc: 0.3556\n",
            "Epoch 126/2048\n",
            "120/120 [==============================] - 0s 295us/step - loss: 1.0002 - acc: 0.3917 - val_loss: 1.0006 - val_acc: 0.2556\n",
            "Epoch 127/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 1.0004 - acc: 0.2833 - val_loss: 1.0002 - val_acc: 0.3889\n",
            "Epoch 128/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 1.0002 - acc: 0.3333 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 129/2048\n",
            "120/120 [==============================] - 0s 390us/step - loss: 1.0003 - acc: 0.3083 - val_loss: 1.0003 - val_acc: 0.3889\n",
            "Epoch 130/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 1.0004 - acc: 0.2833 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 131/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 1.0002 - acc: 0.3417 - val_loss: 1.0002 - val_acc: 0.2556\n",
            "Epoch 132/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 1.0002 - acc: 0.3250 - val_loss: 1.0001 - val_acc: 0.3556\n",
            "Epoch 133/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 1.0002 - acc: 0.3333 - val_loss: 1.0001 - val_acc: 0.3556\n",
            "Epoch 134/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 1.0004 - acc: 0.2583 - val_loss: 1.0003 - val_acc: 0.3889\n",
            "Epoch 135/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 1.0002 - acc: 0.3667 - val_loss: 1.0006 - val_acc: 0.2556\n",
            "Epoch 136/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 1.0003 - acc: 0.3500 - val_loss: 1.0004 - val_acc: 0.3556\n",
            "Epoch 137/2048\n",
            "120/120 [==============================] - 0s 295us/step - loss: 1.0003 - acc: 0.2750 - val_loss: 1.0004 - val_acc: 0.2556\n",
            "Epoch 138/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 1.0002 - acc: 0.3250 - val_loss: 1.0004 - val_acc: 0.3889\n",
            "Epoch 139/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 1.0002 - acc: 0.3500 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 140/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.9998 - acc: 0.4000 - val_loss: 1.0000 - val_acc: 0.3889\n",
            "Epoch 141/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 1.0008 - acc: 0.3833 - val_loss: 1.0000 - val_acc: 0.5222\n",
            "Epoch 142/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 1.0003 - acc: 0.3417 - val_loss: 1.0000 - val_acc: 0.3889\n",
            "Epoch 143/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 1.0005 - acc: 0.3667 - val_loss: 1.0003 - val_acc: 0.2667\n",
            "Epoch 144/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 1.0000 - acc: 0.4250 - val_loss: 0.9996 - val_acc: 0.5444\n",
            "Epoch 145/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 1.0002 - acc: 0.3417 - val_loss: 1.0002 - val_acc: 0.4556\n",
            "Epoch 146/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.9994 - acc: 0.3333 - val_loss: 1.0004 - val_acc: 0.3889\n",
            "Epoch 147/2048\n",
            "120/120 [==============================] - 0s 371us/step - loss: 1.0008 - acc: 0.2917 - val_loss: 1.0001 - val_acc: 0.3556\n",
            "Epoch 148/2048\n",
            "120/120 [==============================] - 0s 348us/step - loss: 0.9998 - acc: 0.3250 - val_loss: 0.9996 - val_acc: 0.4444\n",
            "Epoch 149/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 1.0003 - acc: 0.3750 - val_loss: 1.0001 - val_acc: 0.2556\n",
            "Epoch 150/2048\n",
            "120/120 [==============================] - 0s 340us/step - loss: 1.0003 - acc: 0.3500 - val_loss: 1.0005 - val_acc: 0.2556\n",
            "Epoch 151/2048\n",
            "120/120 [==============================] - 0s 358us/step - loss: 1.0003 - acc: 0.3000 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 152/2048\n",
            "120/120 [==============================] - 0s 358us/step - loss: 1.0000 - acc: 0.4000 - val_loss: 1.0002 - val_acc: 0.3556\n",
            "Epoch 153/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 1.0001 - acc: 0.3000 - val_loss: 1.0002 - val_acc: 0.2889\n",
            "Epoch 154/2048\n",
            "120/120 [==============================] - 0s 378us/step - loss: 1.0004 - acc: 0.2917 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 155/2048\n",
            "120/120 [==============================] - 0s 289us/step - loss: 1.0003 - acc: 0.2500 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 156/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.9998 - acc: 0.2917 - val_loss: 1.0000 - val_acc: 0.3889\n",
            "Epoch 157/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 1.0000 - acc: 0.3667 - val_loss: 0.9999 - val_acc: 0.4889\n",
            "Epoch 158/2048\n",
            "120/120 [==============================] - 0s 346us/step - loss: 0.9994 - acc: 0.4250 - val_loss: 1.0000 - val_acc: 0.3889\n",
            "Epoch 159/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 1.0004 - acc: 0.3250 - val_loss: 0.9997 - val_acc: 0.5778\n",
            "Epoch 160/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 0.9999 - acc: 0.3500 - val_loss: 0.9993 - val_acc: 0.3889\n",
            "Epoch 161/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 1.0006 - acc: 0.3583 - val_loss: 0.9998 - val_acc: 0.4889\n",
            "Epoch 162/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 1.0003 - acc: 0.3000 - val_loss: 1.0001 - val_acc: 0.4111\n",
            "Epoch 163/2048\n",
            "120/120 [==============================] - 0s 350us/step - loss: 0.9985 - acc: 0.3583 - val_loss: 0.9998 - val_acc: 0.3889\n",
            "Epoch 164/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 1.0005 - acc: 0.3333 - val_loss: 0.9999 - val_acc: 0.5556\n",
            "Epoch 165/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 1.0003 - acc: 0.2917 - val_loss: 1.0001 - val_acc: 0.3889\n",
            "Epoch 166/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 1.0003 - acc: 0.3417 - val_loss: 1.0006 - val_acc: 0.2556\n",
            "Epoch 167/2048\n",
            "120/120 [==============================] - 0s 367us/step - loss: 1.0002 - acc: 0.3917 - val_loss: 1.0002 - val_acc: 0.3556\n",
            "Epoch 168/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 1.0000 - acc: 0.3583 - val_loss: 0.9990 - val_acc: 0.5333\n",
            "Epoch 169/2048\n",
            "120/120 [==============================] - 0s 355us/step - loss: 1.0001 - acc: 0.4000 - val_loss: 1.0002 - val_acc: 0.3778\n",
            "Epoch 170/2048\n",
            "120/120 [==============================] - 0s 364us/step - loss: 1.0002 - acc: 0.4167 - val_loss: 0.9994 - val_acc: 0.3889\n",
            "Epoch 171/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 1.0004 - acc: 0.3667 - val_loss: 1.0004 - val_acc: 0.2556\n",
            "Epoch 172/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.9998 - acc: 0.3500 - val_loss: 0.9994 - val_acc: 0.3889\n",
            "Epoch 173/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 1.0002 - acc: 0.3750 - val_loss: 0.9999 - val_acc: 0.5111\n",
            "Epoch 174/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.9995 - acc: 0.4500 - val_loss: 0.9993 - val_acc: 0.3889\n",
            "Epoch 175/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.9994 - acc: 0.2917 - val_loss: 0.9989 - val_acc: 0.3889\n",
            "Epoch 176/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.9989 - acc: 0.4083 - val_loss: 0.9986 - val_acc: 0.5111\n",
            "Epoch 177/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 0.9999 - acc: 0.3667 - val_loss: 0.9993 - val_acc: 0.5889\n",
            "Epoch 178/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.9988 - acc: 0.4083 - val_loss: 0.9988 - val_acc: 0.6111\n",
            "Epoch 179/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.9998 - acc: 0.3667 - val_loss: 0.9992 - val_acc: 0.3889\n",
            "Epoch 180/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 1.0000 - acc: 0.3250 - val_loss: 0.9984 - val_acc: 0.5111\n",
            "Epoch 181/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.9997 - acc: 0.4083 - val_loss: 0.9983 - val_acc: 0.5111\n",
            "Epoch 182/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 1.0006 - acc: 0.3833 - val_loss: 0.9992 - val_acc: 0.3889\n",
            "Epoch 183/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 1.0005 - acc: 0.3667 - val_loss: 0.9993 - val_acc: 0.5778\n",
            "Epoch 184/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 1.0001 - acc: 0.3750 - val_loss: 0.9984 - val_acc: 0.3889\n",
            "Epoch 185/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.9994 - acc: 0.4333 - val_loss: 0.9978 - val_acc: 0.3889\n",
            "Epoch 186/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.9987 - acc: 0.3750 - val_loss: 0.9977 - val_acc: 0.5222\n",
            "Epoch 187/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.9999 - acc: 0.3583 - val_loss: 0.9979 - val_acc: 0.5111\n",
            "Epoch 188/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.9987 - acc: 0.3917 - val_loss: 0.9978 - val_acc: 0.3889\n",
            "Epoch 189/2048\n",
            "120/120 [==============================] - 0s 349us/step - loss: 0.9997 - acc: 0.3250 - val_loss: 0.9970 - val_acc: 0.4556\n",
            "Epoch 190/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 1.0007 - acc: 0.3333 - val_loss: 0.9975 - val_acc: 0.5667\n",
            "Epoch 191/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.9968 - acc: 0.4000 - val_loss: 0.9968 - val_acc: 0.4667\n",
            "Epoch 192/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.9987 - acc: 0.3333 - val_loss: 0.9962 - val_acc: 0.5222\n",
            "Epoch 193/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.9980 - acc: 0.3833 - val_loss: 0.9961 - val_acc: 0.3889\n",
            "Epoch 194/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.9976 - acc: 0.3917 - val_loss: 0.9966 - val_acc: 0.5778\n",
            "Epoch 195/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.9985 - acc: 0.3417 - val_loss: 0.9963 - val_acc: 0.5889\n",
            "Epoch 196/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.9947 - acc: 0.3500 - val_loss: 0.9957 - val_acc: 0.3889\n",
            "Epoch 197/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.9958 - acc: 0.4000 - val_loss: 0.9950 - val_acc: 0.3889\n",
            "Epoch 198/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.9946 - acc: 0.4500 - val_loss: 0.9934 - val_acc: 0.4556\n",
            "Epoch 199/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.9960 - acc: 0.4083 - val_loss: 0.9925 - val_acc: 0.5000\n",
            "Epoch 200/2048\n",
            "120/120 [==============================] - 0s 359us/step - loss: 0.9953 - acc: 0.3333 - val_loss: 0.9918 - val_acc: 0.5333\n",
            "Epoch 201/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.9955 - acc: 0.3333 - val_loss: 0.9921 - val_acc: 0.3889\n",
            "Epoch 202/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 1.0003 - acc: 0.4167 - val_loss: 0.9978 - val_acc: 0.3889\n",
            "Epoch 203/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.9982 - acc: 0.4000 - val_loss: 0.9967 - val_acc: 0.3889\n",
            "Epoch 204/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.9945 - acc: 0.3500 - val_loss: 0.9899 - val_acc: 0.5000\n",
            "Epoch 205/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.9905 - acc: 0.3917 - val_loss: 0.9877 - val_acc: 0.3889\n",
            "Epoch 206/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.9929 - acc: 0.2833 - val_loss: 0.9873 - val_acc: 0.5667\n",
            "Epoch 207/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.9912 - acc: 0.4000 - val_loss: 0.9846 - val_acc: 0.5000\n",
            "Epoch 208/2048\n",
            "120/120 [==============================] - 0s 354us/step - loss: 0.9766 - acc: 0.4000 - val_loss: 0.9832 - val_acc: 0.4556\n",
            "Epoch 209/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.9912 - acc: 0.4167 - val_loss: 0.9860 - val_acc: 0.3889\n",
            "Epoch 210/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.9886 - acc: 0.3667 - val_loss: 0.9843 - val_acc: 0.5222\n",
            "Epoch 211/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.9814 - acc: 0.3083 - val_loss: 0.9742 - val_acc: 0.5000\n",
            "Epoch 212/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.9889 - acc: 0.3083 - val_loss: 0.9759 - val_acc: 0.3889\n",
            "Epoch 213/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.9875 - acc: 0.3167 - val_loss: 0.9725 - val_acc: 0.3889\n",
            "Epoch 214/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.9844 - acc: 0.3333 - val_loss: 0.9682 - val_acc: 0.4778\n",
            "Epoch 215/2048\n",
            "120/120 [==============================] - 0s 371us/step - loss: 0.9770 - acc: 0.3333 - val_loss: 0.9692 - val_acc: 0.3889\n",
            "Epoch 216/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.9872 - acc: 0.3583 - val_loss: 0.9654 - val_acc: 0.5778\n",
            "Epoch 217/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.9808 - acc: 0.4417 - val_loss: 0.9618 - val_acc: 0.4444\n",
            "Epoch 218/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.9839 - acc: 0.3083 - val_loss: 0.9546 - val_acc: 0.4889\n",
            "Epoch 219/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.9787 - acc: 0.3833 - val_loss: 0.9556 - val_acc: 0.5111\n",
            "Epoch 220/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.9480 - acc: 0.4250 - val_loss: 0.9463 - val_acc: 0.5222\n",
            "Epoch 221/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.9376 - acc: 0.4083 - val_loss: 0.9422 - val_acc: 0.3889\n",
            "Epoch 222/2048\n",
            "120/120 [==============================] - 0s 352us/step - loss: 0.9812 - acc: 0.3250 - val_loss: 0.9357 - val_acc: 0.5111\n",
            "Epoch 223/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.9764 - acc: 0.3500 - val_loss: 0.9327 - val_acc: 0.5111\n",
            "Epoch 224/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.9738 - acc: 0.3417 - val_loss: 0.9292 - val_acc: 0.3889\n",
            "Epoch 225/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.9135 - acc: 0.3667 - val_loss: 0.9186 - val_acc: 0.5111\n",
            "Epoch 226/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.9617 - acc: 0.3000 - val_loss: 0.9173 - val_acc: 0.5111\n",
            "Epoch 227/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.9354 - acc: 0.3667 - val_loss: 0.9116 - val_acc: 0.5111\n",
            "Epoch 228/2048\n",
            "120/120 [==============================] - 0s 348us/step - loss: 0.9570 - acc: 0.4167 - val_loss: 0.9142 - val_acc: 0.5000\n",
            "Epoch 229/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.9370 - acc: 0.4000 - val_loss: 0.8983 - val_acc: 0.5222\n",
            "Epoch 230/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.9769 - acc: 0.3667 - val_loss: 0.9230 - val_acc: 0.3889\n",
            "Epoch 231/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.9666 - acc: 0.3667 - val_loss: 0.9118 - val_acc: 0.3889\n",
            "Epoch 232/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.8921 - acc: 0.4250 - val_loss: 0.8858 - val_acc: 0.5111\n",
            "Epoch 233/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.9359 - acc: 0.4083 - val_loss: 0.8951 - val_acc: 0.5111\n",
            "Epoch 234/2048\n",
            "120/120 [==============================] - 0s 346us/step - loss: 0.9070 - acc: 0.4250 - val_loss: 0.8826 - val_acc: 0.4667\n",
            "Epoch 235/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.8972 - acc: 0.4167 - val_loss: 0.8847 - val_acc: 0.5111\n",
            "Epoch 236/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.9115 - acc: 0.4083 - val_loss: 0.8645 - val_acc: 0.5000\n",
            "Epoch 237/2048\n",
            "120/120 [==============================] - 0s 363us/step - loss: 0.9618 - acc: 0.4500 - val_loss: 0.8613 - val_acc: 0.4889\n",
            "Epoch 238/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.9051 - acc: 0.3833 - val_loss: 0.9019 - val_acc: 0.5444\n",
            "Epoch 239/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.8775 - acc: 0.5250 - val_loss: 0.8610 - val_acc: 0.5778\n",
            "Epoch 240/2048\n",
            "120/120 [==============================] - 0s 296us/step - loss: 0.9005 - acc: 0.4417 - val_loss: 0.8544 - val_acc: 0.5111\n",
            "Epoch 241/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.9251 - acc: 0.3833 - val_loss: 0.8471 - val_acc: 0.5111\n",
            "Epoch 242/2048\n",
            "120/120 [==============================] - 0s 357us/step - loss: 0.9270 - acc: 0.4417 - val_loss: 0.8513 - val_acc: 0.3889\n",
            "Epoch 243/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.9507 - acc: 0.3583 - val_loss: 0.8531 - val_acc: 0.3889\n",
            "Epoch 244/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.9190 - acc: 0.4417 - val_loss: 0.8484 - val_acc: 0.5222\n",
            "Epoch 245/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.8894 - acc: 0.3917 - val_loss: 0.8375 - val_acc: 0.5111\n",
            "Epoch 246/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.9441 - acc: 0.4167 - val_loss: 0.8329 - val_acc: 0.3889\n",
            "Epoch 247/2048\n",
            "120/120 [==============================] - 0s 361us/step - loss: 0.9172 - acc: 0.3917 - val_loss: 0.8438 - val_acc: 0.5222\n",
            "Epoch 248/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.9321 - acc: 0.3667 - val_loss: 0.8543 - val_acc: 0.5444\n",
            "Epoch 249/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.9169 - acc: 0.4417 - val_loss: 0.8265 - val_acc: 0.5778\n",
            "Epoch 250/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.9121 - acc: 0.4667 - val_loss: 0.8251 - val_acc: 0.5778\n",
            "Epoch 251/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.9002 - acc: 0.4333 - val_loss: 0.8189 - val_acc: 0.5111\n",
            "Epoch 252/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.9251 - acc: 0.3333 - val_loss: 0.8194 - val_acc: 0.3889\n",
            "Epoch 253/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.9073 - acc: 0.4083 - val_loss: 0.8157 - val_acc: 0.5111\n",
            "Epoch 254/2048\n",
            "120/120 [==============================] - 0s 348us/step - loss: 0.9020 - acc: 0.3833 - val_loss: 0.8306 - val_acc: 0.6000\n",
            "Epoch 255/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.8819 - acc: 0.3667 - val_loss: 0.8107 - val_acc: 0.5667\n",
            "Epoch 256/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.8643 - acc: 0.4500 - val_loss: 0.8050 - val_acc: 0.5222\n",
            "Epoch 257/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.8969 - acc: 0.4333 - val_loss: 0.8180 - val_acc: 0.5444\n",
            "Epoch 258/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.8476 - acc: 0.4083 - val_loss: 0.8017 - val_acc: 0.5667\n",
            "Epoch 259/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.8896 - acc: 0.4917 - val_loss: 0.8001 - val_acc: 0.5222\n",
            "Epoch 260/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.9261 - acc: 0.4083 - val_loss: 0.7972 - val_acc: 0.5778\n",
            "Epoch 261/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.8483 - acc: 0.4417 - val_loss: 0.7980 - val_acc: 0.5333\n",
            "Epoch 262/2048\n",
            "120/120 [==============================] - 0s 383us/step - loss: 0.8937 - acc: 0.3500 - val_loss: 0.7929 - val_acc: 0.5222\n",
            "Epoch 263/2048\n",
            "120/120 [==============================] - 0s 359us/step - loss: 0.8521 - acc: 0.4583 - val_loss: 0.8036 - val_acc: 0.5556\n",
            "Epoch 264/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.9049 - acc: 0.4000 - val_loss: 0.7909 - val_acc: 0.5222\n",
            "Epoch 265/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.8598 - acc: 0.4583 - val_loss: 0.7912 - val_acc: 0.5111\n",
            "Epoch 266/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 0.8828 - acc: 0.4333 - val_loss: 0.7921 - val_acc: 0.6000\n",
            "Epoch 267/2048\n",
            "120/120 [==============================] - 0s 292us/step - loss: 0.8573 - acc: 0.4667 - val_loss: 0.7837 - val_acc: 0.5778\n",
            "Epoch 268/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.8860 - acc: 0.4417 - val_loss: 0.7841 - val_acc: 0.5222\n",
            "Epoch 269/2048\n",
            "120/120 [==============================] - 0s 370us/step - loss: 0.8879 - acc: 0.4583 - val_loss: 0.7871 - val_acc: 0.5333\n",
            "Epoch 270/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.9213 - acc: 0.4417 - val_loss: 0.7796 - val_acc: 0.5778\n",
            "Epoch 271/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.9104 - acc: 0.3750 - val_loss: 0.7837 - val_acc: 0.3889\n",
            "Epoch 272/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.9257 - acc: 0.4333 - val_loss: 0.7835 - val_acc: 0.5667\n",
            "Epoch 273/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 0.8907 - acc: 0.4083 - val_loss: 0.7782 - val_acc: 0.5222\n",
            "Epoch 274/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.8975 - acc: 0.4000 - val_loss: 0.7784 - val_acc: 0.3889\n",
            "Epoch 275/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.8732 - acc: 0.4417 - val_loss: 0.7808 - val_acc: 0.5667\n",
            "Epoch 276/2048\n",
            "120/120 [==============================] - 0s 366us/step - loss: 0.9055 - acc: 0.4750 - val_loss: 0.7839 - val_acc: 0.5333\n",
            "Epoch 277/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.8477 - acc: 0.4750 - val_loss: 0.7854 - val_acc: 0.5556\n",
            "Epoch 278/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.8669 - acc: 0.4917 - val_loss: 0.7726 - val_acc: 0.5889\n",
            "Epoch 279/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 0.9185 - acc: 0.4083 - val_loss: 0.7746 - val_acc: 0.5778\n",
            "Epoch 280/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.8510 - acc: 0.5167 - val_loss: 0.8008 - val_acc: 0.5222\n",
            "Epoch 281/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.9201 - acc: 0.4750 - val_loss: 0.7686 - val_acc: 0.3889\n",
            "Epoch 282/2048\n",
            "120/120 [==============================] - 0s 292us/step - loss: 0.8862 - acc: 0.4500 - val_loss: 0.7679 - val_acc: 0.5889\n",
            "Epoch 283/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.9014 - acc: 0.3833 - val_loss: 0.7876 - val_acc: 0.3889\n",
            "Epoch 284/2048\n",
            "120/120 [==============================] - 0s 366us/step - loss: 0.8571 - acc: 0.4583 - val_loss: 0.7821 - val_acc: 0.5222\n",
            "Epoch 285/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.8647 - acc: 0.4667 - val_loss: 0.7656 - val_acc: 0.5889\n",
            "Epoch 286/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.8542 - acc: 0.4917 - val_loss: 0.7658 - val_acc: 0.5333\n",
            "Epoch 287/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.8363 - acc: 0.4917 - val_loss: 0.7692 - val_acc: 0.5778\n",
            "Epoch 288/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.8745 - acc: 0.4333 - val_loss: 0.7641 - val_acc: 0.5889\n",
            "Epoch 289/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.8756 - acc: 0.4667 - val_loss: 0.7649 - val_acc: 0.5222\n",
            "Epoch 290/2048\n",
            "120/120 [==============================] - 0s 352us/step - loss: 0.9002 - acc: 0.4833 - val_loss: 0.7658 - val_acc: 0.5333\n",
            "Epoch 291/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.8179 - acc: 0.4833 - val_loss: 0.7725 - val_acc: 0.5333\n",
            "Epoch 292/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.8438 - acc: 0.4917 - val_loss: 0.7640 - val_acc: 0.6222\n",
            "Epoch 293/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.8590 - acc: 0.5250 - val_loss: 0.7648 - val_acc: 0.5444\n",
            "Epoch 294/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.8740 - acc: 0.4083 - val_loss: 0.7653 - val_acc: 0.5333\n",
            "Epoch 295/2048\n",
            "120/120 [==============================] - 0s 289us/step - loss: 0.8868 - acc: 0.4417 - val_loss: 0.7667 - val_acc: 0.5333\n",
            "Epoch 296/2048\n",
            "120/120 [==============================] - 0s 356us/step - loss: 0.8291 - acc: 0.5333 - val_loss: 0.7579 - val_acc: 0.5889\n",
            "Epoch 297/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.9102 - acc: 0.4167 - val_loss: 0.7675 - val_acc: 0.5667\n",
            "Epoch 298/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.8915 - acc: 0.4750 - val_loss: 0.7756 - val_acc: 0.3889\n",
            "Epoch 299/2048\n",
            "120/120 [==============================] - 0s 287us/step - loss: 0.8837 - acc: 0.4667 - val_loss: 0.7622 - val_acc: 0.5333\n",
            "Epoch 300/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.8708 - acc: 0.4667 - val_loss: 0.7598 - val_acc: 0.5778\n",
            "Epoch 301/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.8410 - acc: 0.5333 - val_loss: 0.7591 - val_acc: 0.3889\n",
            "Epoch 302/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.9066 - acc: 0.4000 - val_loss: 0.7627 - val_acc: 0.5667\n",
            "Epoch 303/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.8210 - acc: 0.4750 - val_loss: 0.7824 - val_acc: 0.5667\n",
            "Epoch 304/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.8739 - acc: 0.4833 - val_loss: 0.7614 - val_acc: 0.5889\n",
            "Epoch 305/2048\n",
            "120/120 [==============================] - 0s 385us/step - loss: 0.8611 - acc: 0.4750 - val_loss: 0.7488 - val_acc: 0.5778\n",
            "Epoch 306/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.8369 - acc: 0.4917 - val_loss: 0.7514 - val_acc: 0.5444\n",
            "Epoch 307/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.8732 - acc: 0.5000 - val_loss: 0.7608 - val_acc: 0.5778\n",
            "Epoch 308/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.8564 - acc: 0.4500 - val_loss: 0.7478 - val_acc: 0.5444\n",
            "Epoch 309/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.8211 - acc: 0.4417 - val_loss: 0.7535 - val_acc: 0.3889\n",
            "Epoch 310/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.8239 - acc: 0.5083 - val_loss: 0.7510 - val_acc: 0.5333\n",
            "Epoch 311/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.8714 - acc: 0.4667 - val_loss: 0.7481 - val_acc: 0.5444\n",
            "Epoch 312/2048\n",
            "120/120 [==============================] - 0s 376us/step - loss: 0.8705 - acc: 0.4417 - val_loss: 0.7478 - val_acc: 0.3889\n",
            "Epoch 313/2048\n",
            "120/120 [==============================] - 0s 364us/step - loss: 0.8534 - acc: 0.4750 - val_loss: 0.7689 - val_acc: 0.5556\n",
            "Epoch 314/2048\n",
            "120/120 [==============================] - 0s 361us/step - loss: 0.8600 - acc: 0.4833 - val_loss: 0.7435 - val_acc: 0.5222\n",
            "Epoch 315/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.8443 - acc: 0.4917 - val_loss: 0.7707 - val_acc: 0.5333\n",
            "Epoch 316/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.8315 - acc: 0.4833 - val_loss: 0.7781 - val_acc: 0.5556\n",
            "Epoch 317/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.8632 - acc: 0.4833 - val_loss: 0.7699 - val_acc: 0.5333\n",
            "Epoch 318/2048\n",
            "120/120 [==============================] - 0s 386us/step - loss: 0.8290 - acc: 0.5250 - val_loss: 0.7628 - val_acc: 0.5667\n",
            "Epoch 319/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.8336 - acc: 0.5000 - val_loss: 0.7781 - val_acc: 0.3889\n",
            "Epoch 320/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7959 - acc: 0.4917 - val_loss: 0.7407 - val_acc: 0.5222\n",
            "Epoch 321/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.8508 - acc: 0.5083 - val_loss: 0.7409 - val_acc: 0.5222\n",
            "Epoch 322/2048\n",
            "120/120 [==============================] - 0s 288us/step - loss: 0.8460 - acc: 0.4500 - val_loss: 0.7616 - val_acc: 0.5778\n",
            "Epoch 323/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.8520 - acc: 0.4417 - val_loss: 0.7630 - val_acc: 0.5778\n",
            "Epoch 324/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7735 - acc: 0.5583 - val_loss: 0.7632 - val_acc: 0.5333\n",
            "Epoch 325/2048\n",
            "120/120 [==============================] - 0s 290us/step - loss: 0.8351 - acc: 0.4833 - val_loss: 0.7408 - val_acc: 0.5333\n",
            "Epoch 326/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7866 - acc: 0.5500 - val_loss: 0.7457 - val_acc: 0.5333\n",
            "Epoch 327/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.8018 - acc: 0.5000 - val_loss: 0.7621 - val_acc: 0.5778\n",
            "Epoch 328/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7929 - acc: 0.4667 - val_loss: 0.7712 - val_acc: 0.5333\n",
            "Epoch 329/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.7964 - acc: 0.4833 - val_loss: 0.7353 - val_acc: 0.5222\n",
            "Epoch 330/2048\n",
            "120/120 [==============================] - 0s 288us/step - loss: 0.8071 - acc: 0.5417 - val_loss: 0.7731 - val_acc: 0.5667\n",
            "Epoch 331/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.8237 - acc: 0.4833 - val_loss: 0.7476 - val_acc: 0.5444\n",
            "Epoch 332/2048\n",
            "120/120 [==============================] - 0s 296us/step - loss: 0.8204 - acc: 0.4667 - val_loss: 0.7427 - val_acc: 0.5444\n",
            "Epoch 333/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7961 - acc: 0.4917 - val_loss: 0.7541 - val_acc: 0.5444\n",
            "Epoch 334/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.8219 - acc: 0.5167 - val_loss: 0.7463 - val_acc: 0.6000\n",
            "Epoch 335/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.8590 - acc: 0.4500 - val_loss: 0.7372 - val_acc: 0.6111\n",
            "Epoch 336/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.8177 - acc: 0.5000 - val_loss: 0.7663 - val_acc: 0.5778\n",
            "Epoch 337/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.8032 - acc: 0.5583 - val_loss: 0.7468 - val_acc: 0.6000\n",
            "Epoch 338/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.8056 - acc: 0.5417 - val_loss: 0.7483 - val_acc: 0.5444\n",
            "Epoch 339/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.8153 - acc: 0.4750 - val_loss: 0.7570 - val_acc: 0.5444\n",
            "Epoch 340/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.8327 - acc: 0.4583 - val_loss: 0.7603 - val_acc: 0.5444\n",
            "Epoch 341/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.8601 - acc: 0.5083 - val_loss: 0.7588 - val_acc: 0.5444\n",
            "Epoch 342/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.8217 - acc: 0.4667 - val_loss: 0.7444 - val_acc: 0.5444\n",
            "Epoch 343/2048\n",
            "120/120 [==============================] - 0s 357us/step - loss: 0.7830 - acc: 0.5667 - val_loss: 0.7604 - val_acc: 0.3889\n",
            "Epoch 344/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.7927 - acc: 0.5417 - val_loss: 0.7651 - val_acc: 0.5889\n",
            "Epoch 345/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.8230 - acc: 0.4667 - val_loss: 0.7717 - val_acc: 0.5778\n",
            "Epoch 346/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7990 - acc: 0.5000 - val_loss: 0.7355 - val_acc: 0.5222\n",
            "Epoch 347/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.8202 - acc: 0.4500 - val_loss: 0.7406 - val_acc: 0.5333\n",
            "Epoch 348/2048\n",
            "120/120 [==============================] - 0s 371us/step - loss: 0.8165 - acc: 0.4917 - val_loss: 0.7344 - val_acc: 0.3889\n",
            "Epoch 349/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.8155 - acc: 0.4833 - val_loss: 0.7343 - val_acc: 0.5889\n",
            "Epoch 350/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.8134 - acc: 0.4667 - val_loss: 0.7486 - val_acc: 0.5889\n",
            "Epoch 351/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.8109 - acc: 0.5000 - val_loss: 0.7583 - val_acc: 0.5333\n",
            "Epoch 352/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.8400 - acc: 0.4583 - val_loss: 0.7486 - val_acc: 0.5333\n",
            "Epoch 353/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7771 - acc: 0.5333 - val_loss: 0.7437 - val_acc: 0.5333\n",
            "Epoch 354/2048\n",
            "120/120 [==============================] - 0s 346us/step - loss: 0.8113 - acc: 0.5333 - val_loss: 0.7475 - val_acc: 0.5889\n",
            "Epoch 355/2048\n",
            "120/120 [==============================] - 0s 344us/step - loss: 0.8343 - acc: 0.4417 - val_loss: 0.7448 - val_acc: 0.3889\n",
            "Epoch 356/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.8091 - acc: 0.4250 - val_loss: 0.7477 - val_acc: 0.6000\n",
            "Epoch 357/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.8393 - acc: 0.4500 - val_loss: 0.7495 - val_acc: 0.5444\n",
            "Epoch 358/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.7606 - acc: 0.5250 - val_loss: 0.7562 - val_acc: 0.5333\n",
            "Epoch 359/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.8047 - acc: 0.4833 - val_loss: 0.7744 - val_acc: 0.5889\n",
            "Epoch 360/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.8085 - acc: 0.5167 - val_loss: 0.7387 - val_acc: 0.5222\n",
            "Epoch 361/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 0.7879 - acc: 0.5417 - val_loss: 0.7478 - val_acc: 0.5333\n",
            "Epoch 362/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.8334 - acc: 0.5333 - val_loss: 0.7529 - val_acc: 0.5444\n",
            "Epoch 363/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7955 - acc: 0.5167 - val_loss: 0.7535 - val_acc: 0.6000\n",
            "Epoch 364/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7708 - acc: 0.5167 - val_loss: 0.7665 - val_acc: 0.6000\n",
            "Epoch 365/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.8044 - acc: 0.5417 - val_loss: 0.7833 - val_acc: 0.5778\n",
            "Epoch 366/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7836 - acc: 0.5583 - val_loss: 0.7835 - val_acc: 0.5333\n",
            "Epoch 367/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.8209 - acc: 0.4667 - val_loss: 0.7446 - val_acc: 0.5778\n",
            "Epoch 368/2048\n",
            "120/120 [==============================] - 0s 412us/step - loss: 0.7786 - acc: 0.5333 - val_loss: 0.7582 - val_acc: 0.5333\n",
            "Epoch 369/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.8278 - acc: 0.4250 - val_loss: 0.7413 - val_acc: 0.5778\n",
            "Epoch 370/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.8234 - acc: 0.4250 - val_loss: 0.7758 - val_acc: 0.5444\n",
            "Epoch 371/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7623 - acc: 0.5417 - val_loss: 0.7427 - val_acc: 0.5222\n",
            "Epoch 372/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.8085 - acc: 0.4833 - val_loss: 0.7421 - val_acc: 0.5222\n",
            "Epoch 373/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.8165 - acc: 0.4750 - val_loss: 0.7883 - val_acc: 0.5889\n",
            "Epoch 374/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.8209 - acc: 0.4333 - val_loss: 0.7614 - val_acc: 0.5889\n",
            "Epoch 375/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.8158 - acc: 0.5250 - val_loss: 0.7344 - val_acc: 0.5222\n",
            "Epoch 376/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.8015 - acc: 0.4750 - val_loss: 0.7752 - val_acc: 0.5333\n",
            "Epoch 377/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7973 - acc: 0.4917 - val_loss: 0.7826 - val_acc: 0.5889\n",
            "Epoch 378/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.8386 - acc: 0.4250 - val_loss: 0.7813 - val_acc: 0.5889\n",
            "Epoch 379/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.8113 - acc: 0.4750 - val_loss: 0.7662 - val_acc: 0.6000\n",
            "Epoch 380/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7518 - acc: 0.5750 - val_loss: 0.7832 - val_acc: 0.5222\n",
            "Epoch 381/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7886 - acc: 0.5500 - val_loss: 0.7620 - val_acc: 0.6000\n",
            "Epoch 382/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7730 - acc: 0.5000 - val_loss: 0.7466 - val_acc: 0.5333\n",
            "Epoch 383/2048\n",
            "120/120 [==============================] - 0s 348us/step - loss: 0.7849 - acc: 0.4917 - val_loss: 0.7668 - val_acc: 0.6000\n",
            "Epoch 384/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.8029 - acc: 0.5417 - val_loss: 0.7844 - val_acc: 0.5889\n",
            "Epoch 385/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.8063 - acc: 0.5083 - val_loss: 0.7744 - val_acc: 0.5444\n",
            "Epoch 386/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.8212 - acc: 0.4583 - val_loss: 0.7603 - val_acc: 0.5333\n",
            "Epoch 387/2048\n",
            "120/120 [==============================] - 0s 348us/step - loss: 0.7864 - acc: 0.5583 - val_loss: 0.7791 - val_acc: 0.5444\n",
            "Epoch 388/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.8150 - acc: 0.4750 - val_loss: 0.7748 - val_acc: 0.5889\n",
            "Epoch 389/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.8013 - acc: 0.5083 - val_loss: 0.7327 - val_acc: 0.6222\n",
            "Epoch 390/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7608 - acc: 0.5583 - val_loss: 0.7583 - val_acc: 0.5444\n",
            "Epoch 391/2048\n",
            "120/120 [==============================] - 0s 351us/step - loss: 0.8043 - acc: 0.5083 - val_loss: 0.7571 - val_acc: 0.5444\n",
            "Epoch 392/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7573 - acc: 0.5417 - val_loss: 0.7680 - val_acc: 0.5444\n",
            "Epoch 393/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7964 - acc: 0.4833 - val_loss: 0.7663 - val_acc: 0.6000\n",
            "Epoch 394/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.8004 - acc: 0.5250 - val_loss: 0.7510 - val_acc: 0.6000\n",
            "Epoch 395/2048\n",
            "120/120 [==============================] - 0s 340us/step - loss: 0.7732 - acc: 0.5167 - val_loss: 0.7556 - val_acc: 0.5333\n",
            "Epoch 396/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7636 - acc: 0.4667 - val_loss: 0.7555 - val_acc: 0.5333\n",
            "Epoch 397/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7924 - acc: 0.5250 - val_loss: 0.7474 - val_acc: 0.6000\n",
            "Epoch 398/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.7905 - acc: 0.3750 - val_loss: 0.7292 - val_acc: 0.5333\n",
            "Epoch 399/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.8335 - acc: 0.4500 - val_loss: 0.7454 - val_acc: 0.5444\n",
            "Epoch 400/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.8174 - acc: 0.4750 - val_loss: 0.7455 - val_acc: 0.6000\n",
            "Epoch 401/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.8233 - acc: 0.5417 - val_loss: 0.7574 - val_acc: 0.6111\n",
            "Epoch 402/2048\n",
            "120/120 [==============================] - 0s 346us/step - loss: 0.7622 - acc: 0.5333 - val_loss: 0.7823 - val_acc: 0.5778\n",
            "Epoch 403/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.7851 - acc: 0.5750 - val_loss: 0.7863 - val_acc: 0.5333\n",
            "Epoch 404/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.8473 - acc: 0.4583 - val_loss: 0.7723 - val_acc: 0.6000\n",
            "Epoch 405/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.8096 - acc: 0.4917 - val_loss: 0.7566 - val_acc: 0.5444\n",
            "Epoch 406/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.8106 - acc: 0.4750 - val_loss: 0.7635 - val_acc: 0.5444\n",
            "Epoch 407/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.8130 - acc: 0.4333 - val_loss: 0.7784 - val_acc: 0.3889\n",
            "Epoch 408/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.8215 - acc: 0.5083 - val_loss: 0.7683 - val_acc: 0.5889\n",
            "Epoch 409/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.8187 - acc: 0.4500 - val_loss: 0.7488 - val_acc: 0.5444\n",
            "Epoch 410/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.8091 - acc: 0.4500 - val_loss: 0.7418 - val_acc: 0.5333\n",
            "Epoch 411/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.8179 - acc: 0.4667 - val_loss: 0.7713 - val_acc: 0.5889\n",
            "Epoch 412/2048\n",
            "120/120 [==============================] - 0s 357us/step - loss: 0.7781 - acc: 0.5500 - val_loss: 0.7478 - val_acc: 0.5444\n",
            "Epoch 413/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.8251 - acc: 0.4500 - val_loss: 0.7650 - val_acc: 0.6000\n",
            "Epoch 414/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.8211 - acc: 0.4667 - val_loss: 0.7735 - val_acc: 0.6000\n",
            "Epoch 415/2048\n",
            "120/120 [==============================] - 0s 296us/step - loss: 0.7516 - acc: 0.5917 - val_loss: 0.7740 - val_acc: 0.5444\n",
            "Epoch 416/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.8532 - acc: 0.4417 - val_loss: 0.7752 - val_acc: 0.6000\n",
            "Epoch 417/2048\n",
            "120/120 [==============================] - 0s 355us/step - loss: 0.8186 - acc: 0.4750 - val_loss: 0.7594 - val_acc: 0.5444\n",
            "Epoch 418/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.8063 - acc: 0.5500 - val_loss: 0.7466 - val_acc: 0.3889\n",
            "Epoch 419/2048\n",
            "120/120 [==============================] - 0s 352us/step - loss: 0.7750 - acc: 0.5167 - val_loss: 0.7515 - val_acc: 0.6000\n",
            "Epoch 420/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.8199 - acc: 0.4667 - val_loss: 0.7570 - val_acc: 0.6000\n",
            "Epoch 421/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7446 - acc: 0.5833 - val_loss: 0.7647 - val_acc: 0.5444\n",
            "Epoch 422/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.8426 - acc: 0.3917 - val_loss: 0.7849 - val_acc: 0.5889\n",
            "Epoch 423/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.7474 - acc: 0.5750 - val_loss: 0.7609 - val_acc: 0.5444\n",
            "Epoch 424/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7641 - acc: 0.5000 - val_loss: 0.7700 - val_acc: 0.6000\n",
            "Epoch 425/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7959 - acc: 0.5083 - val_loss: 0.7853 - val_acc: 0.5333\n",
            "Epoch 426/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7577 - acc: 0.5250 - val_loss: 0.7685 - val_acc: 0.6000\n",
            "Epoch 427/2048\n",
            "120/120 [==============================] - 0s 344us/step - loss: 0.7670 - acc: 0.5000 - val_loss: 0.7738 - val_acc: 0.5889\n",
            "Epoch 428/2048\n",
            "120/120 [==============================] - 0s 279us/step - loss: 0.7870 - acc: 0.5667 - val_loss: 0.7848 - val_acc: 0.5444\n",
            "Epoch 429/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7846 - acc: 0.5833 - val_loss: 0.7802 - val_acc: 0.5889\n",
            "Epoch 430/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7857 - acc: 0.4833 - val_loss: 0.7859 - val_acc: 0.5444\n",
            "Epoch 431/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.7658 - acc: 0.5167 - val_loss: 0.7821 - val_acc: 0.5889\n",
            "Epoch 432/2048\n",
            "120/120 [==============================] - 0s 358us/step - loss: 0.7837 - acc: 0.5000 - val_loss: 0.7772 - val_acc: 0.6000\n",
            "Epoch 433/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.8048 - acc: 0.5333 - val_loss: 0.7641 - val_acc: 0.5333\n",
            "Epoch 434/2048\n",
            "120/120 [==============================] - 0s 296us/step - loss: 0.8141 - acc: 0.4917 - val_loss: 0.7673 - val_acc: 0.5444\n",
            "Epoch 435/2048\n",
            "120/120 [==============================] - 0s 286us/step - loss: 0.7805 - acc: 0.5333 - val_loss: 0.7639 - val_acc: 0.5444\n",
            "Epoch 436/2048\n",
            "120/120 [==============================] - 0s 356us/step - loss: 0.7930 - acc: 0.5083 - val_loss: 0.7644 - val_acc: 0.6000\n",
            "Epoch 437/2048\n",
            "120/120 [==============================] - 0s 369us/step - loss: 0.7966 - acc: 0.4667 - val_loss: 0.7805 - val_acc: 0.5444\n",
            "Epoch 438/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 0.8014 - acc: 0.5750 - val_loss: 0.7590 - val_acc: 0.6000\n",
            "Epoch 439/2048\n",
            "120/120 [==============================] - 0s 362us/step - loss: 0.7635 - acc: 0.5583 - val_loss: 0.7646 - val_acc: 0.5444\n",
            "Epoch 440/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.7538 - acc: 0.5833 - val_loss: 0.7824 - val_acc: 0.5444\n",
            "Epoch 441/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.8154 - acc: 0.4917 - val_loss: 0.7700 - val_acc: 0.5444\n",
            "Epoch 442/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.8026 - acc: 0.5000 - val_loss: 0.8009 - val_acc: 0.5333\n",
            "Epoch 443/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.7808 - acc: 0.5333 - val_loss: 0.7449 - val_acc: 0.5333\n",
            "Epoch 444/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7953 - acc: 0.4583 - val_loss: 0.7525 - val_acc: 0.5444\n",
            "Epoch 445/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7961 - acc: 0.5167 - val_loss: 0.7423 - val_acc: 0.6111\n",
            "Epoch 446/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7521 - acc: 0.5583 - val_loss: 0.7564 - val_acc: 0.5444\n",
            "Epoch 447/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7694 - acc: 0.4750 - val_loss: 0.7541 - val_acc: 0.6000\n",
            "Epoch 448/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7546 - acc: 0.5333 - val_loss: 0.7747 - val_acc: 0.5444\n",
            "Epoch 449/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7768 - acc: 0.5333 - val_loss: 0.7748 - val_acc: 0.6000\n",
            "Epoch 450/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7994 - acc: 0.4667 - val_loss: 0.7669 - val_acc: 0.6000\n",
            "Epoch 451/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.7891 - acc: 0.4667 - val_loss: 0.7674 - val_acc: 0.5444\n",
            "Epoch 452/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.7738 - acc: 0.4667 - val_loss: 0.7453 - val_acc: 0.5444\n",
            "Epoch 453/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7616 - acc: 0.5917 - val_loss: 0.7506 - val_acc: 0.6111\n",
            "Epoch 454/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.8070 - acc: 0.5417 - val_loss: 0.7459 - val_acc: 0.5444\n",
            "Epoch 455/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7933 - acc: 0.5083 - val_loss: 0.7464 - val_acc: 0.5444\n",
            "Epoch 456/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7668 - acc: 0.5583 - val_loss: 0.7542 - val_acc: 0.3889\n",
            "Epoch 457/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.8033 - acc: 0.4833 - val_loss: 0.7506 - val_acc: 0.6111\n",
            "Epoch 458/2048\n",
            "120/120 [==============================] - 0s 350us/step - loss: 0.7777 - acc: 0.5417 - val_loss: 0.7593 - val_acc: 0.5444\n",
            "Epoch 459/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7763 - acc: 0.5167 - val_loss: 0.7722 - val_acc: 0.6000\n",
            "Epoch 460/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.8188 - acc: 0.5250 - val_loss: 0.7807 - val_acc: 0.5444\n",
            "Epoch 461/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 0.7894 - acc: 0.5500 - val_loss: 0.7874 - val_acc: 0.5444\n",
            "Epoch 462/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7869 - acc: 0.5750 - val_loss: 0.7896 - val_acc: 0.5778\n",
            "Epoch 463/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7704 - acc: 0.5167 - val_loss: 0.7523 - val_acc: 0.5333\n",
            "Epoch 464/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7721 - acc: 0.5417 - val_loss: 0.7759 - val_acc: 0.6000\n",
            "Epoch 465/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 0.7775 - acc: 0.5750 - val_loss: 0.7906 - val_acc: 0.5444\n",
            "Epoch 466/2048\n",
            "120/120 [==============================] - 0s 376us/step - loss: 0.7760 - acc: 0.5250 - val_loss: 0.7602 - val_acc: 0.3889\n",
            "Epoch 467/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.7981 - acc: 0.4667 - val_loss: 0.7530 - val_acc: 0.6222\n",
            "Epoch 468/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.8121 - acc: 0.4583 - val_loss: 0.7644 - val_acc: 0.6000\n",
            "Epoch 469/2048\n",
            "120/120 [==============================] - 0s 346us/step - loss: 0.7713 - acc: 0.5333 - val_loss: 0.7698 - val_acc: 0.5889\n",
            "Epoch 470/2048\n",
            "120/120 [==============================] - 0s 362us/step - loss: 0.7928 - acc: 0.5333 - val_loss: 0.7809 - val_acc: 0.5444\n",
            "Epoch 471/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.8018 - acc: 0.4083 - val_loss: 0.7684 - val_acc: 0.5444\n",
            "Epoch 472/2048\n",
            "120/120 [==============================] - 0s 288us/step - loss: 0.7879 - acc: 0.4750 - val_loss: 0.7652 - val_acc: 0.6111\n",
            "Epoch 473/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7528 - acc: 0.4917 - val_loss: 0.7673 - val_acc: 0.5444\n",
            "Epoch 474/2048\n",
            "120/120 [==============================] - 0s 289us/step - loss: 0.7728 - acc: 0.4833 - val_loss: 0.7678 - val_acc: 0.5444\n",
            "Epoch 475/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7761 - acc: 0.4667 - val_loss: 0.7771 - val_acc: 0.5444\n",
            "Epoch 476/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7775 - acc: 0.5667 - val_loss: 0.7550 - val_acc: 0.5444\n",
            "Epoch 477/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.7889 - acc: 0.4750 - val_loss: 0.7796 - val_acc: 0.5444\n",
            "Epoch 478/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7672 - acc: 0.5500 - val_loss: 0.7554 - val_acc: 0.6111\n",
            "Epoch 479/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7883 - acc: 0.5250 - val_loss: 0.7476 - val_acc: 0.5444\n",
            "Epoch 480/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7688 - acc: 0.5083 - val_loss: 0.7529 - val_acc: 0.5444\n",
            "Epoch 481/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7523 - acc: 0.5667 - val_loss: 0.7631 - val_acc: 0.5444\n",
            "Epoch 482/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.7625 - acc: 0.5667 - val_loss: 0.7686 - val_acc: 0.5444\n",
            "Epoch 483/2048\n",
            "120/120 [==============================] - 0s 287us/step - loss: 0.7758 - acc: 0.5000 - val_loss: 0.7529 - val_acc: 0.6111\n",
            "Epoch 484/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7881 - acc: 0.5000 - val_loss: 0.7709 - val_acc: 0.6000\n",
            "Epoch 485/2048\n",
            "120/120 [==============================] - 0s 295us/step - loss: 0.8048 - acc: 0.4000 - val_loss: 0.7668 - val_acc: 0.5444\n",
            "Epoch 486/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7367 - acc: 0.5583 - val_loss: 0.7558 - val_acc: 0.6000\n",
            "Epoch 487/2048\n",
            "120/120 [==============================] - 0s 381us/step - loss: 0.7489 - acc: 0.5167 - val_loss: 0.7565 - val_acc: 0.6000\n",
            "Epoch 488/2048\n",
            "120/120 [==============================] - 0s 354us/step - loss: 0.8139 - acc: 0.4917 - val_loss: 0.7512 - val_acc: 0.6000\n",
            "Epoch 489/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7770 - acc: 0.5250 - val_loss: 0.7475 - val_acc: 0.6222\n",
            "Epoch 490/2048\n",
            "120/120 [==============================] - 0s 345us/step - loss: 0.8066 - acc: 0.4583 - val_loss: 0.7505 - val_acc: 0.5444\n",
            "Epoch 491/2048\n",
            "120/120 [==============================] - 0s 345us/step - loss: 0.7630 - acc: 0.5667 - val_loss: 0.7458 - val_acc: 0.6111\n",
            "Epoch 492/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.8400 - acc: 0.4000 - val_loss: 0.7483 - val_acc: 0.5333\n",
            "Epoch 493/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7532 - acc: 0.5583 - val_loss: 0.7664 - val_acc: 0.5444\n",
            "Epoch 494/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.8144 - acc: 0.5083 - val_loss: 0.7690 - val_acc: 0.5444\n",
            "Epoch 495/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7945 - acc: 0.5500 - val_loss: 0.8044 - val_acc: 0.5778\n",
            "Epoch 496/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7695 - acc: 0.5833 - val_loss: 0.7520 - val_acc: 0.5333\n",
            "Epoch 497/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7735 - acc: 0.4833 - val_loss: 0.7923 - val_acc: 0.5778\n",
            "Epoch 498/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7913 - acc: 0.5167 - val_loss: 0.7755 - val_acc: 0.5778\n",
            "Epoch 499/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7719 - acc: 0.5583 - val_loss: 0.7651 - val_acc: 0.5444\n",
            "Epoch 500/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.8029 - acc: 0.5083 - val_loss: 0.7733 - val_acc: 0.5889\n",
            "Epoch 501/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.7673 - acc: 0.6000 - val_loss: 0.7885 - val_acc: 0.5778\n",
            "Epoch 502/2048\n",
            "120/120 [==============================] - 0s 295us/step - loss: 0.7904 - acc: 0.5000 - val_loss: 0.7539 - val_acc: 0.5444\n",
            "Epoch 503/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7529 - acc: 0.5667 - val_loss: 0.7805 - val_acc: 0.3889\n",
            "Epoch 504/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7840 - acc: 0.4833 - val_loss: 0.7656 - val_acc: 0.5889\n",
            "Epoch 505/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.8097 - acc: 0.5000 - val_loss: 0.7562 - val_acc: 0.5889\n",
            "Epoch 506/2048\n",
            "120/120 [==============================] - 0s 392us/step - loss: 0.8268 - acc: 0.4500 - val_loss: 0.7733 - val_acc: 0.5778\n",
            "Epoch 507/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7921 - acc: 0.4167 - val_loss: 0.7794 - val_acc: 0.5778\n",
            "Epoch 508/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7644 - acc: 0.5250 - val_loss: 0.7895 - val_acc: 0.5778\n",
            "Epoch 509/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7642 - acc: 0.5250 - val_loss: 0.7817 - val_acc: 0.5444\n",
            "Epoch 510/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7616 - acc: 0.5333 - val_loss: 0.7730 - val_acc: 0.3889\n",
            "Epoch 511/2048\n",
            "120/120 [==============================] - 0s 358us/step - loss: 0.8190 - acc: 0.5000 - val_loss: 0.7499 - val_acc: 0.5444\n",
            "Epoch 512/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7671 - acc: 0.5333 - val_loss: 0.7567 - val_acc: 0.5444\n",
            "Epoch 513/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 0.7465 - acc: 0.5333 - val_loss: 0.7767 - val_acc: 0.5778\n",
            "Epoch 514/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.8000 - acc: 0.4583 - val_loss: 0.7665 - val_acc: 0.3889\n",
            "Epoch 515/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.7853 - acc: 0.4833 - val_loss: 0.7559 - val_acc: 0.6000\n",
            "Epoch 516/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7732 - acc: 0.5417 - val_loss: 0.7729 - val_acc: 0.5778\n",
            "Epoch 517/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7826 - acc: 0.5250 - val_loss: 0.7684 - val_acc: 0.5778\n",
            "Epoch 518/2048\n",
            "120/120 [==============================] - 0s 352us/step - loss: 0.7794 - acc: 0.5833 - val_loss: 0.7490 - val_acc: 0.5444\n",
            "Epoch 519/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7838 - acc: 0.5083 - val_loss: 0.7532 - val_acc: 0.6111\n",
            "Epoch 520/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.7745 - acc: 0.5583 - val_loss: 0.7727 - val_acc: 0.5778\n",
            "Epoch 521/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7533 - acc: 0.6000 - val_loss: 0.7641 - val_acc: 0.5889\n",
            "Epoch 522/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.7525 - acc: 0.5583 - val_loss: 0.7824 - val_acc: 0.5778\n",
            "Epoch 523/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7550 - acc: 0.5917 - val_loss: 0.7899 - val_acc: 0.5444\n",
            "Epoch 524/2048\n",
            "120/120 [==============================] - 0s 340us/step - loss: 0.7756 - acc: 0.5000 - val_loss: 0.7541 - val_acc: 0.5444\n",
            "Epoch 525/2048\n",
            "120/120 [==============================] - 0s 351us/step - loss: 0.7716 - acc: 0.5083 - val_loss: 0.7736 - val_acc: 0.5444\n",
            "Epoch 526/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7825 - acc: 0.5250 - val_loss: 0.7809 - val_acc: 0.5778\n",
            "Epoch 527/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.7976 - acc: 0.5083 - val_loss: 0.7851 - val_acc: 0.3889\n",
            "Epoch 528/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.8023 - acc: 0.4417 - val_loss: 0.7753 - val_acc: 0.5444\n",
            "Epoch 529/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7973 - acc: 0.4500 - val_loss: 0.7825 - val_acc: 0.5444\n",
            "Epoch 530/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7913 - acc: 0.5083 - val_loss: 0.7718 - val_acc: 0.5778\n",
            "Epoch 531/2048\n",
            "120/120 [==============================] - 0s 354us/step - loss: 0.7969 - acc: 0.4333 - val_loss: 0.7651 - val_acc: 0.5778\n",
            "Epoch 532/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7913 - acc: 0.5083 - val_loss: 0.7626 - val_acc: 0.5444\n",
            "Epoch 533/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.8183 - acc: 0.4583 - val_loss: 0.7726 - val_acc: 0.5444\n",
            "Epoch 534/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.8127 - acc: 0.4500 - val_loss: 0.7515 - val_acc: 0.3889\n",
            "Epoch 535/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7858 - acc: 0.5167 - val_loss: 0.7805 - val_acc: 0.5444\n",
            "Epoch 536/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7901 - acc: 0.5083 - val_loss: 0.7513 - val_acc: 0.6000\n",
            "Epoch 537/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.7673 - acc: 0.5000 - val_loss: 0.7465 - val_acc: 0.5556\n",
            "Epoch 538/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.7924 - acc: 0.5250 - val_loss: 0.7518 - val_acc: 0.5556\n",
            "Epoch 539/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7936 - acc: 0.5333 - val_loss: 0.7604 - val_acc: 0.5444\n",
            "Epoch 540/2048\n",
            "120/120 [==============================] - 0s 364us/step - loss: 0.8179 - acc: 0.4667 - val_loss: 0.7638 - val_acc: 0.6000\n",
            "Epoch 541/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7605 - acc: 0.5500 - val_loss: 0.7591 - val_acc: 0.5444\n",
            "Epoch 542/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7897 - acc: 0.5167 - val_loss: 0.7558 - val_acc: 0.5444\n",
            "Epoch 543/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.8123 - acc: 0.4750 - val_loss: 0.7884 - val_acc: 0.3889\n",
            "Epoch 544/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.7893 - acc: 0.5167 - val_loss: 0.7768 - val_acc: 0.5444\n",
            "Epoch 545/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7807 - acc: 0.5250 - val_loss: 0.7434 - val_acc: 0.5556\n",
            "Epoch 546/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7733 - acc: 0.5917 - val_loss: 0.7782 - val_acc: 0.5444\n",
            "Epoch 547/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7816 - acc: 0.4833 - val_loss: 0.7604 - val_acc: 0.5444\n",
            "Epoch 548/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7701 - acc: 0.4583 - val_loss: 0.7732 - val_acc: 0.5444\n",
            "Epoch 549/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7800 - acc: 0.5000 - val_loss: 0.7512 - val_acc: 0.5889\n",
            "Epoch 550/2048\n",
            "120/120 [==============================] - 0s 350us/step - loss: 0.7478 - acc: 0.5500 - val_loss: 0.7492 - val_acc: 0.5889\n",
            "Epoch 551/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7967 - acc: 0.5167 - val_loss: 0.7793 - val_acc: 0.5778\n",
            "Epoch 552/2048\n",
            "120/120 [==============================] - 0s 394us/step - loss: 0.7541 - acc: 0.5167 - val_loss: 0.7479 - val_acc: 0.5444\n",
            "Epoch 553/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7654 - acc: 0.4833 - val_loss: 0.7639 - val_acc: 0.5444\n",
            "Epoch 554/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.7563 - acc: 0.5167 - val_loss: 0.7815 - val_acc: 0.5444\n",
            "Epoch 555/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 0.7360 - acc: 0.5500 - val_loss: 0.7689 - val_acc: 0.5778\n",
            "Epoch 556/2048\n",
            "120/120 [==============================] - 0s 285us/step - loss: 0.7496 - acc: 0.5333 - val_loss: 0.7544 - val_acc: 0.5556\n",
            "Epoch 557/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7586 - acc: 0.4917 - val_loss: 0.7472 - val_acc: 0.5556\n",
            "Epoch 558/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7612 - acc: 0.5583 - val_loss: 0.7347 - val_acc: 0.5556\n",
            "Epoch 559/2048\n",
            "120/120 [==============================] - 0s 295us/step - loss: 0.7704 - acc: 0.4917 - val_loss: 0.7434 - val_acc: 0.5556\n",
            "Epoch 560/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7520 - acc: 0.5417 - val_loss: 0.7640 - val_acc: 0.5556\n",
            "Epoch 561/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7774 - acc: 0.4500 - val_loss: 0.7495 - val_acc: 0.5556\n",
            "Epoch 562/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7706 - acc: 0.4833 - val_loss: 0.7798 - val_acc: 0.5778\n",
            "Epoch 563/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7683 - acc: 0.5917 - val_loss: 0.7548 - val_acc: 0.5889\n",
            "Epoch 564/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.7690 - acc: 0.5000 - val_loss: 0.7530 - val_acc: 0.5556\n",
            "Epoch 565/2048\n",
            "120/120 [==============================] - 0s 367us/step - loss: 0.7980 - acc: 0.4833 - val_loss: 0.7503 - val_acc: 0.3889\n",
            "Epoch 566/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.8005 - acc: 0.5333 - val_loss: 0.7795 - val_acc: 0.5444\n",
            "Epoch 567/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.7695 - acc: 0.5500 - val_loss: 0.7713 - val_acc: 0.5778\n",
            "Epoch 568/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.8302 - acc: 0.4250 - val_loss: 0.7815 - val_acc: 0.5778\n",
            "Epoch 569/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7479 - acc: 0.5750 - val_loss: 0.7444 - val_acc: 0.5556\n",
            "Epoch 570/2048\n",
            "120/120 [==============================] - 0s 348us/step - loss: 0.7860 - acc: 0.5167 - val_loss: 0.7504 - val_acc: 0.6000\n",
            "Epoch 571/2048\n",
            "120/120 [==============================] - 0s 370us/step - loss: 0.7962 - acc: 0.5167 - val_loss: 0.7476 - val_acc: 0.5556\n",
            "Epoch 572/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 0.7565 - acc: 0.5333 - val_loss: 0.7764 - val_acc: 0.5778\n",
            "Epoch 573/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7957 - acc: 0.4500 - val_loss: 0.7669 - val_acc: 0.5444\n",
            "Epoch 574/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7505 - acc: 0.5583 - val_loss: 0.7671 - val_acc: 0.5778\n",
            "Epoch 575/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7276 - acc: 0.5333 - val_loss: 0.7889 - val_acc: 0.5444\n",
            "Epoch 576/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 0.8093 - acc: 0.5250 - val_loss: 0.7699 - val_acc: 0.5778\n",
            "Epoch 577/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.7760 - acc: 0.5167 - val_loss: 0.7607 - val_acc: 0.5889\n",
            "Epoch 578/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7852 - acc: 0.5167 - val_loss: 0.7819 - val_acc: 0.5444\n",
            "Epoch 579/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7751 - acc: 0.4583 - val_loss: 0.7457 - val_acc: 0.6111\n",
            "Epoch 580/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7796 - acc: 0.4917 - val_loss: 0.7942 - val_acc: 0.5333\n",
            "Epoch 581/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7921 - acc: 0.5000 - val_loss: 0.7971 - val_acc: 0.3889\n",
            "Epoch 582/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7718 - acc: 0.4917 - val_loss: 0.7735 - val_acc: 0.5778\n",
            "Epoch 583/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7471 - acc: 0.5083 - val_loss: 0.7717 - val_acc: 0.5778\n",
            "Epoch 584/2048\n",
            "120/120 [==============================] - 0s 353us/step - loss: 0.7868 - acc: 0.5500 - val_loss: 0.7961 - val_acc: 0.5444\n",
            "Epoch 585/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7791 - acc: 0.5250 - val_loss: 0.7849 - val_acc: 0.5778\n",
            "Epoch 586/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7975 - acc: 0.4833 - val_loss: 0.7777 - val_acc: 0.5778\n",
            "Epoch 587/2048\n",
            "120/120 [==============================] - 0s 345us/step - loss: 0.7400 - acc: 0.4750 - val_loss: 0.7360 - val_acc: 0.5556\n",
            "Epoch 588/2048\n",
            "120/120 [==============================] - 0s 363us/step - loss: 0.7853 - acc: 0.4500 - val_loss: 0.7479 - val_acc: 0.3889\n",
            "Epoch 589/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7840 - acc: 0.4833 - val_loss: 0.7484 - val_acc: 0.6000\n",
            "Epoch 590/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7423 - acc: 0.5333 - val_loss: 0.7556 - val_acc: 0.5444\n",
            "Epoch 591/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 0.8352 - acc: 0.4500 - val_loss: 0.7746 - val_acc: 0.5778\n",
            "Epoch 592/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7539 - acc: 0.5333 - val_loss: 0.7923 - val_acc: 0.5778\n",
            "Epoch 593/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7611 - acc: 0.5583 - val_loss: 0.7832 - val_acc: 0.5778\n",
            "Epoch 594/2048\n",
            "120/120 [==============================] - 0s 287us/step - loss: 0.7519 - acc: 0.5083 - val_loss: 0.7577 - val_acc: 0.5889\n",
            "Epoch 595/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.7770 - acc: 0.4667 - val_loss: 0.7584 - val_acc: 0.5444\n",
            "Epoch 596/2048\n",
            "120/120 [==============================] - 0s 280us/step - loss: 0.8004 - acc: 0.5250 - val_loss: 0.7730 - val_acc: 0.5778\n",
            "Epoch 597/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.8025 - acc: 0.5083 - val_loss: 0.7632 - val_acc: 0.5444\n",
            "Epoch 598/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7975 - acc: 0.4750 - val_loss: 0.7515 - val_acc: 0.5889\n",
            "Epoch 599/2048\n",
            "120/120 [==============================] - 0s 367us/step - loss: 0.7950 - acc: 0.4917 - val_loss: 0.7958 - val_acc: 0.5444\n",
            "Epoch 600/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7674 - acc: 0.5833 - val_loss: 0.7547 - val_acc: 0.5444\n",
            "Epoch 601/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.8000 - acc: 0.5000 - val_loss: 0.7437 - val_acc: 0.3889\n",
            "Epoch 602/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.7627 - acc: 0.5000 - val_loss: 0.7595 - val_acc: 0.5778\n",
            "Epoch 603/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7846 - acc: 0.4500 - val_loss: 0.7646 - val_acc: 0.5444\n",
            "Epoch 604/2048\n",
            "120/120 [==============================] - 0s 374us/step - loss: 0.7756 - acc: 0.5833 - val_loss: 0.7649 - val_acc: 0.5778\n",
            "Epoch 605/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7591 - acc: 0.5667 - val_loss: 0.7755 - val_acc: 0.5444\n",
            "Epoch 606/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7945 - acc: 0.5417 - val_loss: 0.8042 - val_acc: 0.5778\n",
            "Epoch 607/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7606 - acc: 0.5583 - val_loss: 0.7869 - val_acc: 0.5778\n",
            "Epoch 608/2048\n",
            "120/120 [==============================] - 0s 287us/step - loss: 0.7773 - acc: 0.4917 - val_loss: 0.7447 - val_acc: 0.6111\n",
            "Epoch 609/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7849 - acc: 0.4833 - val_loss: 0.7619 - val_acc: 0.5889\n",
            "Epoch 610/2048\n",
            "120/120 [==============================] - 0s 366us/step - loss: 0.7953 - acc: 0.5083 - val_loss: 0.7639 - val_acc: 0.3889\n",
            "Epoch 611/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7335 - acc: 0.5500 - val_loss: 0.7657 - val_acc: 0.5778\n",
            "Epoch 612/2048\n",
            "120/120 [==============================] - 0s 358us/step - loss: 0.7709 - acc: 0.5583 - val_loss: 0.7941 - val_acc: 0.5333\n",
            "Epoch 613/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 0.8039 - acc: 0.5250 - val_loss: 0.7852 - val_acc: 0.5333\n",
            "Epoch 614/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7442 - acc: 0.5250 - val_loss: 0.7717 - val_acc: 0.5444\n",
            "Epoch 615/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7757 - acc: 0.4667 - val_loss: 0.7453 - val_acc: 0.5556\n",
            "Epoch 616/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7678 - acc: 0.5083 - val_loss: 0.7584 - val_acc: 0.6000\n",
            "Epoch 617/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 0.7720 - acc: 0.5417 - val_loss: 0.7507 - val_acc: 0.5444\n",
            "Epoch 618/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7509 - acc: 0.6250 - val_loss: 0.7652 - val_acc: 0.5889\n",
            "Epoch 619/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7637 - acc: 0.5667 - val_loss: 0.7484 - val_acc: 0.6111\n",
            "Epoch 620/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7674 - acc: 0.5000 - val_loss: 0.7617 - val_acc: 0.5444\n",
            "Epoch 621/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7635 - acc: 0.5167 - val_loss: 0.7887 - val_acc: 0.5778\n",
            "Epoch 622/2048\n",
            "120/120 [==============================] - 0s 355us/step - loss: 0.8120 - acc: 0.5000 - val_loss: 0.7867 - val_acc: 0.5778\n",
            "Epoch 623/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7589 - acc: 0.5250 - val_loss: 0.7938 - val_acc: 0.5778\n",
            "Epoch 624/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7772 - acc: 0.5167 - val_loss: 0.7653 - val_acc: 0.5889\n",
            "Epoch 625/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7681 - acc: 0.5667 - val_loss: 0.7473 - val_acc: 0.5444\n",
            "Epoch 626/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.8096 - acc: 0.4833 - val_loss: 0.7498 - val_acc: 0.6111\n",
            "Epoch 627/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 0.7524 - acc: 0.5583 - val_loss: 0.7664 - val_acc: 0.5889\n",
            "Epoch 628/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7614 - acc: 0.5833 - val_loss: 0.7724 - val_acc: 0.5444\n",
            "Epoch 629/2048\n",
            "120/120 [==============================] - 0s 346us/step - loss: 0.7646 - acc: 0.5167 - val_loss: 0.7636 - val_acc: 0.5444\n",
            "Epoch 630/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7762 - acc: 0.5750 - val_loss: 0.7795 - val_acc: 0.5778\n",
            "Epoch 631/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7664 - acc: 0.5750 - val_loss: 0.7669 - val_acc: 0.5444\n",
            "Epoch 632/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.8124 - acc: 0.4833 - val_loss: 0.7777 - val_acc: 0.5778\n",
            "Epoch 633/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 0.7672 - acc: 0.4500 - val_loss: 0.7804 - val_acc: 0.5778\n",
            "Epoch 634/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7793 - acc: 0.5333 - val_loss: 0.7643 - val_acc: 0.5444\n",
            "Epoch 635/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.8428 - acc: 0.4167 - val_loss: 0.7724 - val_acc: 0.5778\n",
            "Epoch 636/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7849 - acc: 0.5083 - val_loss: 0.7617 - val_acc: 0.5444\n",
            "Epoch 637/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7684 - acc: 0.5250 - val_loss: 0.7619 - val_acc: 0.6000\n",
            "Epoch 638/2048\n",
            "120/120 [==============================] - 0s 364us/step - loss: 0.7587 - acc: 0.4750 - val_loss: 0.7638 - val_acc: 0.5444\n",
            "Epoch 639/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7784 - acc: 0.5583 - val_loss: 0.7562 - val_acc: 0.6111\n",
            "Epoch 640/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7958 - acc: 0.4833 - val_loss: 0.7849 - val_acc: 0.5444\n",
            "Epoch 641/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7679 - acc: 0.4417 - val_loss: 0.7946 - val_acc: 0.5444\n",
            "Epoch 642/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7375 - acc: 0.5583 - val_loss: 0.7602 - val_acc: 0.5444\n",
            "Epoch 643/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.7973 - acc: 0.5167 - val_loss: 0.7569 - val_acc: 0.5444\n",
            "Epoch 644/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7772 - acc: 0.5583 - val_loss: 0.7584 - val_acc: 0.3889\n",
            "Epoch 645/2048\n",
            "120/120 [==============================] - 0s 361us/step - loss: 0.7766 - acc: 0.4667 - val_loss: 0.7809 - val_acc: 0.5778\n",
            "Epoch 646/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7445 - acc: 0.5500 - val_loss: 0.7575 - val_acc: 0.5556\n",
            "Epoch 647/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7640 - acc: 0.5083 - val_loss: 0.7677 - val_acc: 0.5444\n",
            "Epoch 648/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7389 - acc: 0.5667 - val_loss: 0.7658 - val_acc: 0.5444\n",
            "Epoch 649/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.7613 - acc: 0.5583 - val_loss: 0.7992 - val_acc: 0.5333\n",
            "Epoch 650/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.7438 - acc: 0.5500 - val_loss: 0.7808 - val_acc: 0.5444\n",
            "Epoch 651/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7600 - acc: 0.5167 - val_loss: 0.7966 - val_acc: 0.5778\n",
            "Epoch 652/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.7921 - acc: 0.5000 - val_loss: 0.7695 - val_acc: 0.5444\n",
            "Epoch 653/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7759 - acc: 0.5333 - val_loss: 0.7833 - val_acc: 0.5778\n",
            "Epoch 654/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7702 - acc: 0.5500 - val_loss: 0.8029 - val_acc: 0.5889\n",
            "Epoch 655/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7647 - acc: 0.4917 - val_loss: 0.7939 - val_acc: 0.5778\n",
            "Epoch 656/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7518 - acc: 0.5500 - val_loss: 0.7887 - val_acc: 0.5778\n",
            "Epoch 657/2048\n",
            "120/120 [==============================] - 0s 350us/step - loss: 0.7696 - acc: 0.4667 - val_loss: 0.7828 - val_acc: 0.5778\n",
            "Epoch 658/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.7846 - acc: 0.4417 - val_loss: 0.7873 - val_acc: 0.5444\n",
            "Epoch 659/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7703 - acc: 0.4917 - val_loss: 0.7446 - val_acc: 0.5556\n",
            "Epoch 660/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.7588 - acc: 0.5333 - val_loss: 0.7519 - val_acc: 0.5778\n",
            "Epoch 661/2048\n",
            "120/120 [==============================] - 0s 296us/step - loss: 0.8011 - acc: 0.4667 - val_loss: 0.7867 - val_acc: 0.5444\n",
            "Epoch 662/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7755 - acc: 0.5667 - val_loss: 0.7889 - val_acc: 0.5778\n",
            "Epoch 663/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7691 - acc: 0.5917 - val_loss: 0.7975 - val_acc: 0.5778\n",
            "Epoch 664/2048\n",
            "120/120 [==============================] - 0s 356us/step - loss: 0.7798 - acc: 0.5750 - val_loss: 0.7748 - val_acc: 0.5778\n",
            "Epoch 665/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7668 - acc: 0.5000 - val_loss: 0.7749 - val_acc: 0.5778\n",
            "Epoch 666/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.7672 - acc: 0.5083 - val_loss: 0.7781 - val_acc: 0.5778\n",
            "Epoch 667/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7842 - acc: 0.5250 - val_loss: 0.7487 - val_acc: 0.5778\n",
            "Epoch 668/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.7687 - acc: 0.5833 - val_loss: 0.7861 - val_acc: 0.5333\n",
            "Epoch 669/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7679 - acc: 0.5500 - val_loss: 0.8065 - val_acc: 0.5889\n",
            "Epoch 670/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.8200 - acc: 0.5250 - val_loss: 0.7847 - val_acc: 0.5778\n",
            "Epoch 671/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.7765 - acc: 0.5250 - val_loss: 0.7577 - val_acc: 0.5444\n",
            "Epoch 672/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7851 - acc: 0.5333 - val_loss: 0.7892 - val_acc: 0.5556\n",
            "Epoch 673/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7421 - acc: 0.5417 - val_loss: 0.7914 - val_acc: 0.5556\n",
            "Epoch 674/2048\n",
            "120/120 [==============================] - 0s 356us/step - loss: 0.7092 - acc: 0.6083 - val_loss: 0.7705 - val_acc: 0.5444\n",
            "Epoch 675/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7852 - acc: 0.4583 - val_loss: 0.7699 - val_acc: 0.5778\n",
            "Epoch 676/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7348 - acc: 0.5667 - val_loss: 0.7948 - val_acc: 0.5444\n",
            "Epoch 677/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7711 - acc: 0.5000 - val_loss: 0.7529 - val_acc: 0.5444\n",
            "Epoch 678/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.8253 - acc: 0.4500 - val_loss: 0.7539 - val_acc: 0.5444\n",
            "Epoch 679/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 0.7586 - acc: 0.5250 - val_loss: 0.7564 - val_acc: 0.5889\n",
            "Epoch 680/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.8172 - acc: 0.4750 - val_loss: 0.7693 - val_acc: 0.5444\n",
            "Epoch 681/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7683 - acc: 0.5833 - val_loss: 0.7906 - val_acc: 0.5444\n",
            "Epoch 682/2048\n",
            "120/120 [==============================] - 0s 348us/step - loss: 0.7642 - acc: 0.5167 - val_loss: 0.7606 - val_acc: 0.5444\n",
            "Epoch 683/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.7587 - acc: 0.6000 - val_loss: 0.7726 - val_acc: 0.5889\n",
            "Epoch 684/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7704 - acc: 0.4667 - val_loss: 0.7490 - val_acc: 0.6111\n",
            "Epoch 685/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7420 - acc: 0.5417 - val_loss: 0.7537 - val_acc: 0.5556\n",
            "Epoch 686/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.7872 - acc: 0.5167 - val_loss: 0.7617 - val_acc: 0.5444\n",
            "Epoch 687/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 0.7504 - acc: 0.5333 - val_loss: 0.7650 - val_acc: 0.5444\n",
            "Epoch 688/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7591 - acc: 0.5500 - val_loss: 0.7813 - val_acc: 0.5556\n",
            "Epoch 689/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7533 - acc: 0.5333 - val_loss: 0.7917 - val_acc: 0.3889\n",
            "Epoch 690/2048\n",
            "120/120 [==============================] - 0s 353us/step - loss: 0.7651 - acc: 0.5750 - val_loss: 0.8107 - val_acc: 0.5667\n",
            "Epoch 691/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7438 - acc: 0.5250 - val_loss: 0.7753 - val_acc: 0.5778\n",
            "Epoch 692/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7835 - acc: 0.5167 - val_loss: 0.7762 - val_acc: 0.5778\n",
            "Epoch 693/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7707 - acc: 0.5000 - val_loss: 0.7737 - val_acc: 0.3889\n",
            "Epoch 694/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7839 - acc: 0.4750 - val_loss: 0.7797 - val_acc: 0.5778\n",
            "Epoch 695/2048\n",
            "120/120 [==============================] - 0s 346us/step - loss: 0.7672 - acc: 0.4917 - val_loss: 0.7882 - val_acc: 0.5778\n",
            "Epoch 696/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7672 - acc: 0.5000 - val_loss: 0.7834 - val_acc: 0.5778\n",
            "Epoch 697/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7527 - acc: 0.4917 - val_loss: 0.7614 - val_acc: 0.5889\n",
            "Epoch 698/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7668 - acc: 0.5500 - val_loss: 0.7618 - val_acc: 0.5889\n",
            "Epoch 699/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.7730 - acc: 0.4667 - val_loss: 0.7629 - val_acc: 0.5444\n",
            "Epoch 700/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7369 - acc: 0.6167 - val_loss: 0.7618 - val_acc: 0.5778\n",
            "Epoch 701/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7961 - acc: 0.4417 - val_loss: 0.7924 - val_acc: 0.5778\n",
            "Epoch 702/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.7669 - acc: 0.5167 - val_loss: 0.7936 - val_acc: 0.5444\n",
            "Epoch 703/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7724 - acc: 0.5750 - val_loss: 0.7665 - val_acc: 0.5778\n",
            "Epoch 704/2048\n",
            "120/120 [==============================] - 0s 350us/step - loss: 0.7932 - acc: 0.5417 - val_loss: 0.7661 - val_acc: 0.5444\n",
            "Epoch 705/2048\n",
            "120/120 [==============================] - 0s 375us/step - loss: 0.7344 - acc: 0.5667 - val_loss: 0.7847 - val_acc: 0.5778\n",
            "Epoch 706/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.7357 - acc: 0.5500 - val_loss: 0.7596 - val_acc: 0.5444\n",
            "Epoch 707/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 0.7703 - acc: 0.5500 - val_loss: 0.7903 - val_acc: 0.5778\n",
            "Epoch 708/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 0.7529 - acc: 0.5417 - val_loss: 0.7508 - val_acc: 0.5556\n",
            "Epoch 709/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.8002 - acc: 0.5167 - val_loss: 0.7509 - val_acc: 0.5556\n",
            "Epoch 710/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 0.7810 - acc: 0.5417 - val_loss: 0.7495 - val_acc: 0.5556\n",
            "Epoch 711/2048\n",
            "120/120 [==============================] - 0s 295us/step - loss: 0.7463 - acc: 0.5667 - val_loss: 0.7777 - val_acc: 0.5778\n",
            "Epoch 712/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7502 - acc: 0.5583 - val_loss: 0.7775 - val_acc: 0.5444\n",
            "Epoch 713/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.7562 - acc: 0.5750 - val_loss: 0.7922 - val_acc: 0.5333\n",
            "Epoch 714/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7262 - acc: 0.6250 - val_loss: 0.7691 - val_acc: 0.5444\n",
            "Epoch 715/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7588 - acc: 0.5750 - val_loss: 0.7745 - val_acc: 0.5444\n",
            "Epoch 716/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7587 - acc: 0.5083 - val_loss: 0.7775 - val_acc: 0.5778\n",
            "Epoch 717/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7476 - acc: 0.5917 - val_loss: 0.7625 - val_acc: 0.5778\n",
            "Epoch 718/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7335 - acc: 0.5833 - val_loss: 0.7641 - val_acc: 0.5444\n",
            "Epoch 719/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7764 - acc: 0.4833 - val_loss: 0.7971 - val_acc: 0.5778\n",
            "Epoch 720/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7855 - acc: 0.5250 - val_loss: 0.7925 - val_acc: 0.5778\n",
            "Epoch 721/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7590 - acc: 0.5167 - val_loss: 0.7985 - val_acc: 0.5333\n",
            "Epoch 722/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.8119 - acc: 0.4667 - val_loss: 0.7518 - val_acc: 0.5556\n",
            "Epoch 723/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7849 - acc: 0.5167 - val_loss: 0.7627 - val_acc: 0.5778\n",
            "Epoch 724/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7669 - acc: 0.5083 - val_loss: 0.7808 - val_acc: 0.5444\n",
            "Epoch 725/2048\n",
            "120/120 [==============================] - 0s 288us/step - loss: 0.7787 - acc: 0.5833 - val_loss: 0.8019 - val_acc: 0.5111\n",
            "Epoch 726/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7340 - acc: 0.5500 - val_loss: 0.7727 - val_acc: 0.5778\n",
            "Epoch 727/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7840 - acc: 0.5250 - val_loss: 0.7776 - val_acc: 0.5778\n",
            "Epoch 728/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7875 - acc: 0.4917 - val_loss: 0.8061 - val_acc: 0.5222\n",
            "Epoch 729/2048\n",
            "120/120 [==============================] - 0s 340us/step - loss: 0.8055 - acc: 0.5000 - val_loss: 0.7740 - val_acc: 0.5444\n",
            "Epoch 730/2048\n",
            "120/120 [==============================] - 0s 344us/step - loss: 0.7348 - acc: 0.5667 - val_loss: 0.7704 - val_acc: 0.5889\n",
            "Epoch 731/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.7844 - acc: 0.5083 - val_loss: 0.7854 - val_acc: 0.5778\n",
            "Epoch 732/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7760 - acc: 0.5250 - val_loss: 0.7830 - val_acc: 0.5444\n",
            "Epoch 733/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7586 - acc: 0.5750 - val_loss: 0.7994 - val_acc: 0.5444\n",
            "Epoch 734/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.8672 - acc: 0.3917 - val_loss: 0.7994 - val_acc: 0.5444\n",
            "Epoch 735/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7836 - acc: 0.5750 - val_loss: 0.8000 - val_acc: 0.5778\n",
            "Epoch 736/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.8059 - acc: 0.5417 - val_loss: 0.7877 - val_acc: 0.5444\n",
            "Epoch 737/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7929 - acc: 0.4667 - val_loss: 0.7951 - val_acc: 0.5444\n",
            "Epoch 738/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.7431 - acc: 0.5917 - val_loss: 0.7763 - val_acc: 0.5778\n",
            "Epoch 739/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7756 - acc: 0.5083 - val_loss: 0.7912 - val_acc: 0.5444\n",
            "Epoch 740/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.8002 - acc: 0.4083 - val_loss: 0.7920 - val_acc: 0.3889\n",
            "Epoch 741/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7419 - acc: 0.5333 - val_loss: 0.7946 - val_acc: 0.5778\n",
            "Epoch 742/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7676 - acc: 0.4917 - val_loss: 0.7983 - val_acc: 0.5778\n",
            "Epoch 743/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7536 - acc: 0.5833 - val_loss: 0.7571 - val_acc: 0.5444\n",
            "Epoch 744/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7888 - acc: 0.5250 - val_loss: 0.7727 - val_acc: 0.5778\n",
            "Epoch 745/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7427 - acc: 0.5250 - val_loss: 0.7824 - val_acc: 0.5778\n",
            "Epoch 746/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7335 - acc: 0.5583 - val_loss: 0.7853 - val_acc: 0.5778\n",
            "Epoch 747/2048\n",
            "120/120 [==============================] - 0s 348us/step - loss: 0.8002 - acc: 0.4750 - val_loss: 0.8049 - val_acc: 0.5778\n",
            "Epoch 748/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7789 - acc: 0.5000 - val_loss: 0.7881 - val_acc: 0.5444\n",
            "Epoch 749/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7772 - acc: 0.4583 - val_loss: 0.7932 - val_acc: 0.5444\n",
            "Epoch 750/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7943 - acc: 0.4833 - val_loss: 0.7585 - val_acc: 0.5778\n",
            "Epoch 751/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7588 - acc: 0.5000 - val_loss: 0.7632 - val_acc: 0.5444\n",
            "Epoch 752/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.7466 - acc: 0.5500 - val_loss: 0.7659 - val_acc: 0.5444\n",
            "Epoch 753/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7714 - acc: 0.4667 - val_loss: 0.7935 - val_acc: 0.5444\n",
            "Epoch 754/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7594 - acc: 0.5417 - val_loss: 0.8005 - val_acc: 0.3889\n",
            "Epoch 755/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7502 - acc: 0.5083 - val_loss: 0.8005 - val_acc: 0.5444\n",
            "Epoch 756/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 0.7347 - acc: 0.6000 - val_loss: 0.7876 - val_acc: 0.5444\n",
            "Epoch 757/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7587 - acc: 0.4917 - val_loss: 0.7520 - val_acc: 0.5444\n",
            "Epoch 758/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7956 - acc: 0.5083 - val_loss: 0.7940 - val_acc: 0.5444\n",
            "Epoch 759/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.8045 - acc: 0.4500 - val_loss: 0.7968 - val_acc: 0.5444\n",
            "Epoch 760/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7756 - acc: 0.5417 - val_loss: 0.7663 - val_acc: 0.5778\n",
            "Epoch 761/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7541 - acc: 0.5167 - val_loss: 0.7490 - val_acc: 0.6111\n",
            "Epoch 762/2048\n",
            "120/120 [==============================] - 0s 355us/step - loss: 0.7420 - acc: 0.5667 - val_loss: 0.7564 - val_acc: 0.5556\n",
            "Epoch 763/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7957 - acc: 0.5250 - val_loss: 0.7764 - val_acc: 0.5778\n",
            "Epoch 764/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.7607 - acc: 0.5333 - val_loss: 0.7485 - val_acc: 0.3889\n",
            "Epoch 765/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7760 - acc: 0.5167 - val_loss: 0.7531 - val_acc: 0.6111\n",
            "Epoch 766/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7422 - acc: 0.5583 - val_loss: 0.7556 - val_acc: 0.5556\n",
            "Epoch 767/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7837 - acc: 0.4917 - val_loss: 0.7559 - val_acc: 0.5556\n",
            "Epoch 768/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.8085 - acc: 0.4833 - val_loss: 0.7561 - val_acc: 0.6000\n",
            "Epoch 769/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7774 - acc: 0.5250 - val_loss: 0.7891 - val_acc: 0.5333\n",
            "Epoch 770/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.7547 - acc: 0.5750 - val_loss: 0.7924 - val_acc: 0.5444\n",
            "Epoch 771/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7783 - acc: 0.4750 - val_loss: 0.7929 - val_acc: 0.5444\n",
            "Epoch 772/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7754 - acc: 0.5250 - val_loss: 0.7925 - val_acc: 0.3889\n",
            "Epoch 773/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7649 - acc: 0.5250 - val_loss: 0.8017 - val_acc: 0.5333\n",
            "Epoch 774/2048\n",
            "120/120 [==============================] - 0s 376us/step - loss: 0.7453 - acc: 0.5417 - val_loss: 0.7633 - val_acc: 0.5778\n",
            "Epoch 775/2048\n",
            "120/120 [==============================] - 0s 365us/step - loss: 0.7921 - acc: 0.4583 - val_loss: 0.7609 - val_acc: 0.5444\n",
            "Epoch 776/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7758 - acc: 0.5167 - val_loss: 0.7730 - val_acc: 0.5778\n",
            "Epoch 777/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7660 - acc: 0.5417 - val_loss: 0.7920 - val_acc: 0.5667\n",
            "Epoch 778/2048\n",
            "120/120 [==============================] - 0s 287us/step - loss: 0.7693 - acc: 0.4583 - val_loss: 0.8000 - val_acc: 0.5333\n",
            "Epoch 779/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7669 - acc: 0.4833 - val_loss: 0.7852 - val_acc: 0.5444\n",
            "Epoch 780/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7814 - acc: 0.5000 - val_loss: 0.7683 - val_acc: 0.5444\n",
            "Epoch 781/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 0.7336 - acc: 0.6000 - val_loss: 0.7714 - val_acc: 0.5444\n",
            "Epoch 782/2048\n",
            "120/120 [==============================] - 0s 395us/step - loss: 0.7887 - acc: 0.5083 - val_loss: 0.7734 - val_acc: 0.5889\n",
            "Epoch 783/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7670 - acc: 0.4583 - val_loss: 0.7797 - val_acc: 0.5889\n",
            "Epoch 784/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 0.7372 - acc: 0.5833 - val_loss: 0.7936 - val_acc: 0.5333\n",
            "Epoch 785/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7426 - acc: 0.4667 - val_loss: 0.8016 - val_acc: 0.5889\n",
            "Epoch 786/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7692 - acc: 0.5500 - val_loss: 0.7560 - val_acc: 0.5556\n",
            "Epoch 787/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7891 - acc: 0.4750 - val_loss: 0.7861 - val_acc: 0.5778\n",
            "Epoch 788/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.8372 - acc: 0.4750 - val_loss: 0.7549 - val_acc: 0.6000\n",
            "Epoch 789/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7355 - acc: 0.6083 - val_loss: 0.7583 - val_acc: 0.5444\n",
            "Epoch 790/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7670 - acc: 0.5583 - val_loss: 0.7600 - val_acc: 0.6000\n",
            "Epoch 791/2048\n",
            "120/120 [==============================] - 0s 355us/step - loss: 0.8007 - acc: 0.4917 - val_loss: 0.7795 - val_acc: 0.5778\n",
            "Epoch 792/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.7419 - acc: 0.5583 - val_loss: 0.7837 - val_acc: 0.5444\n",
            "Epoch 793/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.8023 - acc: 0.5000 - val_loss: 0.7535 - val_acc: 0.5556\n",
            "Epoch 794/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.8336 - acc: 0.5083 - val_loss: 0.7532 - val_acc: 0.6111\n",
            "Epoch 795/2048\n",
            "120/120 [==============================] - 0s 367us/step - loss: 0.7753 - acc: 0.5500 - val_loss: 0.7538 - val_acc: 0.5556\n",
            "Epoch 796/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7336 - acc: 0.5333 - val_loss: 0.7558 - val_acc: 0.6111\n",
            "Epoch 797/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7593 - acc: 0.5750 - val_loss: 0.7868 - val_acc: 0.5444\n",
            "Epoch 798/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.8005 - acc: 0.5333 - val_loss: 0.7969 - val_acc: 0.5444\n",
            "Epoch 799/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.8039 - acc: 0.4583 - val_loss: 0.7670 - val_acc: 0.5889\n",
            "Epoch 800/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7824 - acc: 0.5250 - val_loss: 0.7826 - val_acc: 0.5444\n",
            "Epoch 801/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7337 - acc: 0.5833 - val_loss: 0.7893 - val_acc: 0.5778\n",
            "Epoch 802/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7669 - acc: 0.4917 - val_loss: 0.7901 - val_acc: 0.5444\n",
            "Epoch 803/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7757 - acc: 0.4917 - val_loss: 0.7823 - val_acc: 0.5778\n",
            "Epoch 804/2048\n",
            "120/120 [==============================] - 0s 292us/step - loss: 0.7849 - acc: 0.5000 - val_loss: 0.7913 - val_acc: 0.5444\n",
            "Epoch 805/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7572 - acc: 0.5167 - val_loss: 0.7568 - val_acc: 0.5444\n",
            "Epoch 806/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7757 - acc: 0.4917 - val_loss: 0.7706 - val_acc: 0.5778\n",
            "Epoch 807/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7754 - acc: 0.5417 - val_loss: 0.7767 - val_acc: 0.5444\n",
            "Epoch 808/2048\n",
            "120/120 [==============================] - 0s 353us/step - loss: 0.7943 - acc: 0.5000 - val_loss: 0.7993 - val_acc: 0.5889\n",
            "Epoch 809/2048\n",
            "120/120 [==============================] - 0s 344us/step - loss: 0.8133 - acc: 0.5083 - val_loss: 0.7738 - val_acc: 0.5778\n",
            "Epoch 810/2048\n",
            "120/120 [==============================] - 0s 290us/step - loss: 0.7593 - acc: 0.5250 - val_loss: 0.7772 - val_acc: 0.5444\n",
            "Epoch 811/2048\n",
            "120/120 [==============================] - 0s 349us/step - loss: 0.7585 - acc: 0.5667 - val_loss: 0.7775 - val_acc: 0.5444\n",
            "Epoch 812/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7841 - acc: 0.5667 - val_loss: 0.7898 - val_acc: 0.5444\n",
            "Epoch 813/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7773 - acc: 0.5417 - val_loss: 0.7712 - val_acc: 0.5778\n",
            "Epoch 814/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7675 - acc: 0.5333 - val_loss: 0.7757 - val_acc: 0.5778\n",
            "Epoch 815/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7622 - acc: 0.5667 - val_loss: 0.7963 - val_acc: 0.5778\n",
            "Epoch 816/2048\n",
            "120/120 [==============================] - 0s 350us/step - loss: 0.7739 - acc: 0.5917 - val_loss: 0.7990 - val_acc: 0.5778\n",
            "Epoch 817/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.8090 - acc: 0.5000 - val_loss: 0.7878 - val_acc: 0.5444\n",
            "Epoch 818/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7668 - acc: 0.5250 - val_loss: 0.7880 - val_acc: 0.5778\n",
            "Epoch 819/2048\n",
            "120/120 [==============================] - 0s 285us/step - loss: 0.7344 - acc: 0.5750 - val_loss: 0.7991 - val_acc: 0.5444\n",
            "Epoch 820/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 0.8049 - acc: 0.4667 - val_loss: 0.8017 - val_acc: 0.3889\n",
            "Epoch 821/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7543 - acc: 0.5583 - val_loss: 0.7951 - val_acc: 0.5778\n",
            "Epoch 822/2048\n",
            "120/120 [==============================] - 0s 286us/step - loss: 0.7588 - acc: 0.5917 - val_loss: 0.7997 - val_acc: 0.5778\n",
            "Epoch 823/2048\n",
            "120/120 [==============================] - 0s 295us/step - loss: 0.7371 - acc: 0.5583 - val_loss: 0.7538 - val_acc: 0.5444\n",
            "Epoch 824/2048\n",
            "120/120 [==============================] - 0s 290us/step - loss: 0.7836 - acc: 0.5583 - val_loss: 0.7608 - val_acc: 0.6000\n",
            "Epoch 825/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.8027 - acc: 0.4833 - val_loss: 0.7451 - val_acc: 0.6111\n",
            "Epoch 826/2048\n",
            "120/120 [==============================] - 0s 289us/step - loss: 0.7919 - acc: 0.5083 - val_loss: 0.7453 - val_acc: 0.5556\n",
            "Epoch 827/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.7611 - acc: 0.5500 - val_loss: 0.7544 - val_acc: 0.5889\n",
            "Epoch 828/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.7762 - acc: 0.5667 - val_loss: 0.7502 - val_acc: 0.5889\n",
            "Epoch 829/2048\n",
            "120/120 [==============================] - 0s 289us/step - loss: 0.7567 - acc: 0.5333 - val_loss: 0.7784 - val_acc: 0.5778\n",
            "Epoch 830/2048\n",
            "120/120 [==============================] - 0s 286us/step - loss: 0.7921 - acc: 0.5167 - val_loss: 0.7810 - val_acc: 0.5778\n",
            "Epoch 831/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.8055 - acc: 0.5167 - val_loss: 0.7741 - val_acc: 0.5444\n",
            "Epoch 832/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7918 - acc: 0.5250 - val_loss: 0.7744 - val_acc: 0.5444\n",
            "Epoch 833/2048\n",
            "120/120 [==============================] - 0s 284us/step - loss: 0.7586 - acc: 0.5667 - val_loss: 0.7785 - val_acc: 0.3889\n",
            "Epoch 834/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7668 - acc: 0.5333 - val_loss: 0.7788 - val_acc: 0.5778\n",
            "Epoch 835/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.7586 - acc: 0.5500 - val_loss: 0.7837 - val_acc: 0.5444\n",
            "Epoch 836/2048\n",
            "120/120 [==============================] - 0s 296us/step - loss: 0.7418 - acc: 0.5667 - val_loss: 0.7712 - val_acc: 0.5778\n",
            "Epoch 837/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7840 - acc: 0.4833 - val_loss: 0.7856 - val_acc: 0.5778\n",
            "Epoch 838/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.7790 - acc: 0.5167 - val_loss: 0.7477 - val_acc: 0.5556\n",
            "Epoch 839/2048\n",
            "120/120 [==============================] - 0s 359us/step - loss: 0.7723 - acc: 0.5250 - val_loss: 0.7877 - val_acc: 0.3889\n",
            "Epoch 840/2048\n",
            "120/120 [==============================] - 0s 357us/step - loss: 0.7174 - acc: 0.5583 - val_loss: 0.8000 - val_acc: 0.5444\n",
            "Epoch 841/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7437 - acc: 0.6000 - val_loss: 0.7697 - val_acc: 0.5778\n",
            "Epoch 842/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.7450 - acc: 0.5833 - val_loss: 0.7978 - val_acc: 0.5778\n",
            "Epoch 843/2048\n",
            "120/120 [==============================] - 0s 295us/step - loss: 0.7761 - acc: 0.4667 - val_loss: 0.7950 - val_acc: 0.5444\n",
            "Epoch 844/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7336 - acc: 0.4833 - val_loss: 0.7797 - val_acc: 0.5444\n",
            "Epoch 845/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7836 - acc: 0.5083 - val_loss: 0.7820 - val_acc: 0.5444\n",
            "Epoch 846/2048\n",
            "120/120 [==============================] - 0s 368us/step - loss: 0.7891 - acc: 0.5167 - val_loss: 0.7694 - val_acc: 0.5444\n",
            "Epoch 847/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7920 - acc: 0.5250 - val_loss: 0.7737 - val_acc: 0.5444\n",
            "Epoch 848/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.7419 - acc: 0.5583 - val_loss: 0.7743 - val_acc: 0.5444\n",
            "Epoch 849/2048\n",
            "120/120 [==============================] - 0s 296us/step - loss: 0.7758 - acc: 0.5083 - val_loss: 0.7957 - val_acc: 0.5444\n",
            "Epoch 850/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7533 - acc: 0.5750 - val_loss: 0.7654 - val_acc: 0.5444\n",
            "Epoch 851/2048\n",
            "120/120 [==============================] - 0s 360us/step - loss: 0.7342 - acc: 0.5333 - val_loss: 0.7839 - val_acc: 0.5444\n",
            "Epoch 852/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7755 - acc: 0.5917 - val_loss: 0.7931 - val_acc: 0.5444\n",
            "Epoch 853/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7295 - acc: 0.5500 - val_loss: 0.7807 - val_acc: 0.5444\n",
            "Epoch 854/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7659 - acc: 0.5417 - val_loss: 0.8094 - val_acc: 0.3889\n",
            "Epoch 855/2048\n",
            "120/120 [==============================] - 0s 282us/step - loss: 0.7939 - acc: 0.4833 - val_loss: 0.7995 - val_acc: 0.5333\n",
            "Epoch 856/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.7464 - acc: 0.4833 - val_loss: 0.7797 - val_acc: 0.5778\n",
            "Epoch 857/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.8092 - acc: 0.4083 - val_loss: 0.7646 - val_acc: 0.5889\n",
            "Epoch 858/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.7917 - acc: 0.5167 - val_loss: 0.7566 - val_acc: 0.5444\n",
            "Epoch 859/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7589 - acc: 0.5833 - val_loss: 0.7589 - val_acc: 0.5444\n",
            "Epoch 860/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.7835 - acc: 0.5500 - val_loss: 0.7590 - val_acc: 0.6000\n",
            "Epoch 861/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7380 - acc: 0.5667 - val_loss: 0.7891 - val_acc: 0.5778\n",
            "Epoch 862/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7504 - acc: 0.5333 - val_loss: 0.7926 - val_acc: 0.5444\n",
            "Epoch 863/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.7434 - acc: 0.5750 - val_loss: 0.8044 - val_acc: 0.5222\n",
            "Epoch 864/2048\n",
            "120/120 [==============================] - 0s 410us/step - loss: 0.7780 - acc: 0.5167 - val_loss: 0.7723 - val_acc: 0.5444\n",
            "Epoch 865/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7168 - acc: 0.6167 - val_loss: 0.7728 - val_acc: 0.5889\n",
            "Epoch 866/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.7757 - acc: 0.4750 - val_loss: 0.7718 - val_acc: 0.5444\n",
            "Epoch 867/2048\n",
            "120/120 [==============================] - 0s 356us/step - loss: 0.7428 - acc: 0.5500 - val_loss: 0.7645 - val_acc: 0.5444\n",
            "Epoch 868/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7836 - acc: 0.5000 - val_loss: 0.7673 - val_acc: 0.5444\n",
            "Epoch 869/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.7384 - acc: 0.5000 - val_loss: 0.8005 - val_acc: 0.5778\n",
            "Epoch 870/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7681 - acc: 0.6333 - val_loss: 0.7815 - val_acc: 0.5444\n",
            "Epoch 871/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 0.7850 - acc: 0.5583 - val_loss: 0.7860 - val_acc: 0.5778\n",
            "Epoch 872/2048\n",
            "120/120 [==============================] - 0s 295us/step - loss: 0.7502 - acc: 0.5583 - val_loss: 0.7865 - val_acc: 0.3889\n",
            "Epoch 873/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7919 - acc: 0.5083 - val_loss: 0.7864 - val_acc: 0.5778\n",
            "Epoch 874/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7673 - acc: 0.4833 - val_loss: 0.7971 - val_acc: 0.5778\n",
            "Epoch 875/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7269 - acc: 0.5500 - val_loss: 0.7904 - val_acc: 0.5444\n",
            "Epoch 876/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7586 - acc: 0.5667 - val_loss: 0.7993 - val_acc: 0.5778\n",
            "Epoch 877/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.7826 - acc: 0.4833 - val_loss: 0.7976 - val_acc: 0.5444\n",
            "Epoch 878/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7836 - acc: 0.4583 - val_loss: 0.7986 - val_acc: 0.3889\n",
            "Epoch 879/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7622 - acc: 0.5000 - val_loss: 0.7599 - val_acc: 0.5778\n",
            "Epoch 880/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.8012 - acc: 0.4583 - val_loss: 0.7659 - val_acc: 0.5778\n",
            "Epoch 881/2048\n",
            "120/120 [==============================] - 0s 284us/step - loss: 0.7503 - acc: 0.4583 - val_loss: 0.7686 - val_acc: 0.5778\n",
            "Epoch 882/2048\n",
            "120/120 [==============================] - 0s 365us/step - loss: 0.7592 - acc: 0.5500 - val_loss: 0.7868 - val_acc: 0.5778\n",
            "Epoch 883/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.8115 - acc: 0.4917 - val_loss: 0.8031 - val_acc: 0.5333\n",
            "Epoch 884/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7861 - acc: 0.5083 - val_loss: 0.7674 - val_acc: 0.5444\n",
            "Epoch 885/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7256 - acc: 0.5750 - val_loss: 0.7848 - val_acc: 0.5778\n",
            "Epoch 886/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7760 - acc: 0.5417 - val_loss: 0.8013 - val_acc: 0.5444\n",
            "Epoch 887/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.7876 - acc: 0.5417 - val_loss: 0.7869 - val_acc: 0.5444\n",
            "Epoch 888/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.7669 - acc: 0.5000 - val_loss: 0.7882 - val_acc: 0.5444\n",
            "Epoch 889/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.8003 - acc: 0.4750 - val_loss: 0.7896 - val_acc: 0.5778\n",
            "Epoch 890/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.8085 - acc: 0.4917 - val_loss: 0.7774 - val_acc: 0.5778\n",
            "Epoch 891/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7605 - acc: 0.5583 - val_loss: 0.8001 - val_acc: 0.5778\n",
            "Epoch 892/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.8085 - acc: 0.5083 - val_loss: 0.8004 - val_acc: 0.5778\n",
            "Epoch 893/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7795 - acc: 0.5250 - val_loss: 0.7743 - val_acc: 0.5444\n",
            "Epoch 894/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7423 - acc: 0.5250 - val_loss: 0.8011 - val_acc: 0.5778\n",
            "Epoch 895/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7710 - acc: 0.5167 - val_loss: 0.7777 - val_acc: 0.5778\n",
            "Epoch 896/2048\n",
            "120/120 [==============================] - 0s 350us/step - loss: 0.7762 - acc: 0.5417 - val_loss: 0.8004 - val_acc: 0.5444\n",
            "Epoch 897/2048\n",
            "120/120 [==============================] - 0s 426us/step - loss: 0.7374 - acc: 0.5667 - val_loss: 0.7640 - val_acc: 0.6000\n",
            "Epoch 898/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7757 - acc: 0.4750 - val_loss: 0.7780 - val_acc: 0.5444\n",
            "Epoch 899/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7590 - acc: 0.5167 - val_loss: 0.7947 - val_acc: 0.5444\n",
            "Epoch 900/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7760 - acc: 0.5000 - val_loss: 0.7644 - val_acc: 0.6000\n",
            "Epoch 901/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.7918 - acc: 0.4583 - val_loss: 0.7949 - val_acc: 0.3889\n",
            "Epoch 902/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.8004 - acc: 0.4750 - val_loss: 0.7945 - val_acc: 0.5778\n",
            "Epoch 903/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7587 - acc: 0.5333 - val_loss: 0.7969 - val_acc: 0.5444\n",
            "Epoch 904/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 0.7823 - acc: 0.5250 - val_loss: 0.8048 - val_acc: 0.5444\n",
            "Epoch 905/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7692 - acc: 0.5250 - val_loss: 0.7811 - val_acc: 0.5444\n",
            "Epoch 906/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7751 - acc: 0.4833 - val_loss: 0.7819 - val_acc: 0.5444\n",
            "Epoch 907/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.7513 - acc: 0.5417 - val_loss: 0.8033 - val_acc: 0.5778\n",
            "Epoch 908/2048\n",
            "120/120 [==============================] - 0s 349us/step - loss: 0.7751 - acc: 0.5333 - val_loss: 0.8039 - val_acc: 0.5556\n",
            "Epoch 909/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.7841 - acc: 0.4250 - val_loss: 0.7860 - val_acc: 0.5444\n",
            "Epoch 910/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7265 - acc: 0.5667 - val_loss: 0.8040 - val_acc: 0.5556\n",
            "Epoch 911/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7871 - acc: 0.5917 - val_loss: 0.7770 - val_acc: 0.5778\n",
            "Epoch 912/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.8002 - acc: 0.5583 - val_loss: 0.7898 - val_acc: 0.5556\n",
            "Epoch 913/2048\n",
            "120/120 [==============================] - 0s 354us/step - loss: 0.8002 - acc: 0.4750 - val_loss: 0.7894 - val_acc: 0.3889\n",
            "Epoch 914/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7979 - acc: 0.4667 - val_loss: 0.7937 - val_acc: 0.5444\n",
            "Epoch 915/2048\n",
            "120/120 [==============================] - 0s 358us/step - loss: 0.7606 - acc: 0.4917 - val_loss: 0.7974 - val_acc: 0.5889\n",
            "Epoch 916/2048\n",
            "120/120 [==============================] - 0s 287us/step - loss: 0.7679 - acc: 0.4833 - val_loss: 0.7745 - val_acc: 0.5444\n",
            "Epoch 917/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7674 - acc: 0.5417 - val_loss: 0.7835 - val_acc: 0.5444\n",
            "Epoch 918/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.8006 - acc: 0.5583 - val_loss: 0.7641 - val_acc: 0.5556\n",
            "Epoch 919/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7335 - acc: 0.5500 - val_loss: 0.7665 - val_acc: 0.5778\n",
            "Epoch 920/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7335 - acc: 0.5500 - val_loss: 0.7670 - val_acc: 0.5444\n",
            "Epoch 921/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7789 - acc: 0.4667 - val_loss: 0.7988 - val_acc: 0.5889\n",
            "Epoch 922/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7411 - acc: 0.6167 - val_loss: 0.8030 - val_acc: 0.5889\n",
            "Epoch 923/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7757 - acc: 0.4833 - val_loss: 0.7596 - val_acc: 0.5889\n",
            "Epoch 924/2048\n",
            "120/120 [==============================] - 0s 360us/step - loss: 0.8024 - acc: 0.4750 - val_loss: 0.7758 - val_acc: 0.3889\n",
            "Epoch 925/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.7489 - acc: 0.5250 - val_loss: 0.7568 - val_acc: 0.5556\n",
            "Epoch 926/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7585 - acc: 0.4583 - val_loss: 0.7569 - val_acc: 0.5556\n",
            "Epoch 927/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7754 - acc: 0.4750 - val_loss: 0.7608 - val_acc: 0.5889\n",
            "Epoch 928/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7942 - acc: 0.4833 - val_loss: 0.7913 - val_acc: 0.5889\n",
            "Epoch 929/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7420 - acc: 0.5917 - val_loss: 0.7932 - val_acc: 0.5556\n",
            "Epoch 930/2048\n",
            "120/120 [==============================] - 0s 289us/step - loss: 0.7411 - acc: 0.5083 - val_loss: 0.7748 - val_acc: 0.5444\n",
            "Epoch 931/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7086 - acc: 0.5583 - val_loss: 0.7798 - val_acc: 0.5444\n",
            "Epoch 932/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.7353 - acc: 0.5583 - val_loss: 0.7901 - val_acc: 0.5444\n",
            "Epoch 933/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7755 - acc: 0.5250 - val_loss: 0.7653 - val_acc: 0.5556\n",
            "Epoch 934/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7671 - acc: 0.4917 - val_loss: 0.7866 - val_acc: 0.5444\n",
            "Epoch 935/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 0.7902 - acc: 0.4917 - val_loss: 0.7823 - val_acc: 0.5444\n",
            "Epoch 936/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7839 - acc: 0.4833 - val_loss: 0.7993 - val_acc: 0.5778\n",
            "Epoch 937/2048\n",
            "120/120 [==============================] - 0s 362us/step - loss: 0.7618 - acc: 0.5583 - val_loss: 0.7878 - val_acc: 0.3889\n",
            "Epoch 938/2048\n",
            "120/120 [==============================] - 0s 344us/step - loss: 0.7760 - acc: 0.5000 - val_loss: 0.7790 - val_acc: 0.5778\n",
            "Epoch 939/2048\n",
            "120/120 [==============================] - 0s 382us/step - loss: 0.7503 - acc: 0.5750 - val_loss: 0.7890 - val_acc: 0.5778\n",
            "Epoch 940/2048\n",
            "120/120 [==============================] - 0s 365us/step - loss: 0.7837 - acc: 0.4750 - val_loss: 0.7806 - val_acc: 0.5444\n",
            "Epoch 941/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7670 - acc: 0.5500 - val_loss: 0.8006 - val_acc: 0.5778\n",
            "Epoch 942/2048\n",
            "120/120 [==============================] - 0s 384us/step - loss: 0.7502 - acc: 0.5000 - val_loss: 0.8007 - val_acc: 0.5444\n",
            "Epoch 943/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7451 - acc: 0.5417 - val_loss: 0.8017 - val_acc: 0.5778\n",
            "Epoch 944/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7999 - acc: 0.4917 - val_loss: 0.7850 - val_acc: 0.5444\n",
            "Epoch 945/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7529 - acc: 0.6000 - val_loss: 0.7788 - val_acc: 0.5444\n",
            "Epoch 946/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7874 - acc: 0.4667 - val_loss: 0.7999 - val_acc: 0.5444\n",
            "Epoch 947/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.7605 - acc: 0.6167 - val_loss: 0.7682 - val_acc: 0.5778\n",
            "Epoch 948/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.7419 - acc: 0.5167 - val_loss: 0.7686 - val_acc: 0.5778\n",
            "Epoch 949/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7421 - acc: 0.5750 - val_loss: 0.7804 - val_acc: 0.5444\n",
            "Epoch 950/2048\n",
            "120/120 [==============================] - 0s 346us/step - loss: 0.7418 - acc: 0.5083 - val_loss: 0.7805 - val_acc: 0.5444\n",
            "Epoch 951/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7668 - acc: 0.5250 - val_loss: 0.7807 - val_acc: 0.5444\n",
            "Epoch 952/2048\n",
            "120/120 [==============================] - 0s 286us/step - loss: 0.7835 - acc: 0.4667 - val_loss: 0.7809 - val_acc: 0.5444\n",
            "Epoch 953/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.7839 - acc: 0.5000 - val_loss: 0.7976 - val_acc: 0.3889\n",
            "Epoch 954/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.7468 - acc: 0.5083 - val_loss: 0.7805 - val_acc: 0.5444\n",
            "Epoch 955/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7420 - acc: 0.5583 - val_loss: 0.7807 - val_acc: 0.5889\n",
            "Epoch 956/2048\n",
            "120/120 [==============================] - 0s 345us/step - loss: 0.7835 - acc: 0.5167 - val_loss: 0.7860 - val_acc: 0.5444\n",
            "Epoch 957/2048\n",
            "120/120 [==============================] - 0s 349us/step - loss: 0.7895 - acc: 0.5250 - val_loss: 0.7576 - val_acc: 0.5444\n",
            "Epoch 958/2048\n",
            "120/120 [==============================] - 0s 286us/step - loss: 0.7592 - acc: 0.5083 - val_loss: 0.7547 - val_acc: 0.5444\n",
            "Epoch 959/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.8064 - acc: 0.5000 - val_loss: 0.7402 - val_acc: 0.5556\n",
            "Epoch 960/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7752 - acc: 0.5250 - val_loss: 0.7417 - val_acc: 0.5556\n",
            "Epoch 961/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7875 - acc: 0.5083 - val_loss: 0.7677 - val_acc: 0.5444\n",
            "Epoch 962/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7502 - acc: 0.5667 - val_loss: 0.7679 - val_acc: 0.5444\n",
            "Epoch 963/2048\n",
            "120/120 [==============================] - 0s 361us/step - loss: 0.7829 - acc: 0.4917 - val_loss: 0.7503 - val_acc: 0.6222\n",
            "Epoch 964/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7919 - acc: 0.4917 - val_loss: 0.7511 - val_acc: 0.5556\n",
            "Epoch 965/2048\n",
            "120/120 [==============================] - 0s 290us/step - loss: 0.7683 - acc: 0.5667 - val_loss: 0.7773 - val_acc: 0.5889\n",
            "Epoch 966/2048\n",
            "120/120 [==============================] - 0s 287us/step - loss: 0.7757 - acc: 0.5000 - val_loss: 0.7952 - val_acc: 0.5444\n",
            "Epoch 967/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.8003 - acc: 0.4917 - val_loss: 0.7694 - val_acc: 0.5889\n",
            "Epoch 968/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7422 - acc: 0.5750 - val_loss: 0.7847 - val_acc: 0.5778\n",
            "Epoch 969/2048\n",
            "120/120 [==============================] - 0s 362us/step - loss: 0.7502 - acc: 0.5417 - val_loss: 0.7866 - val_acc: 0.5444\n",
            "Epoch 970/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7586 - acc: 0.4750 - val_loss: 0.7873 - val_acc: 0.5444\n",
            "Epoch 971/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7508 - acc: 0.5333 - val_loss: 0.7875 - val_acc: 0.5778\n",
            "Epoch 972/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.7760 - acc: 0.5000 - val_loss: 0.7817 - val_acc: 0.3889\n",
            "Epoch 973/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7586 - acc: 0.5583 - val_loss: 0.7865 - val_acc: 0.5778\n",
            "Epoch 974/2048\n",
            "120/120 [==============================] - 0s 353us/step - loss: 0.7779 - acc: 0.5083 - val_loss: 0.8048 - val_acc: 0.5444\n",
            "Epoch 975/2048\n",
            "120/120 [==============================] - 0s 289us/step - loss: 0.7752 - acc: 0.5833 - val_loss: 0.8056 - val_acc: 0.5778\n",
            "Epoch 976/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.7859 - acc: 0.5583 - val_loss: 0.7575 - val_acc: 0.5778\n",
            "Epoch 977/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7753 - acc: 0.5333 - val_loss: 0.7714 - val_acc: 0.5444\n",
            "Epoch 978/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7418 - acc: 0.6250 - val_loss: 0.7775 - val_acc: 0.5444\n",
            "Epoch 979/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.8086 - acc: 0.5417 - val_loss: 0.7888 - val_acc: 0.5444\n",
            "Epoch 980/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7586 - acc: 0.4833 - val_loss: 0.7948 - val_acc: 0.5778\n",
            "Epoch 981/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7585 - acc: 0.5833 - val_loss: 0.7965 - val_acc: 0.5778\n",
            "Epoch 982/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 0.7835 - acc: 0.5667 - val_loss: 0.8005 - val_acc: 0.5778\n",
            "Epoch 983/2048\n",
            "120/120 [==============================] - 0s 340us/step - loss: 0.7585 - acc: 0.5333 - val_loss: 0.8016 - val_acc: 0.5778\n",
            "Epoch 984/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7668 - acc: 0.5333 - val_loss: 0.8017 - val_acc: 0.5778\n",
            "Epoch 985/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7918 - acc: 0.5083 - val_loss: 0.8017 - val_acc: 0.5444\n",
            "Epoch 986/2048\n",
            "120/120 [==============================] - 0s 368us/step - loss: 0.8030 - acc: 0.4750 - val_loss: 0.7746 - val_acc: 0.5778\n",
            "Epoch 987/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7502 - acc: 0.5167 - val_loss: 0.7758 - val_acc: 0.5778\n",
            "Epoch 988/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7673 - acc: 0.5417 - val_loss: 0.7769 - val_acc: 0.5778\n",
            "Epoch 989/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.7668 - acc: 0.5500 - val_loss: 0.7863 - val_acc: 0.5444\n",
            "Epoch 990/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.7668 - acc: 0.5417 - val_loss: 0.7920 - val_acc: 0.5778\n",
            "Epoch 991/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7989 - acc: 0.4833 - val_loss: 0.8041 - val_acc: 0.5778\n",
            "Epoch 992/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7937 - acc: 0.4333 - val_loss: 0.8011 - val_acc: 0.5778\n",
            "Epoch 993/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.7587 - acc: 0.5250 - val_loss: 0.8043 - val_acc: 0.5444\n",
            "Epoch 994/2048\n",
            "120/120 [==============================] - 0s 340us/step - loss: 0.7696 - acc: 0.5750 - val_loss: 0.8036 - val_acc: 0.5778\n",
            "Epoch 995/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7835 - acc: 0.5417 - val_loss: 0.8036 - val_acc: 0.5778\n",
            "Epoch 996/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7585 - acc: 0.5833 - val_loss: 0.8062 - val_acc: 0.5778\n",
            "Epoch 997/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7754 - acc: 0.4333 - val_loss: 0.8005 - val_acc: 0.5778\n",
            "Epoch 998/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7835 - acc: 0.4750 - val_loss: 0.8011 - val_acc: 0.5444\n",
            "Epoch 999/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.7469 - acc: 0.5167 - val_loss: 0.7837 - val_acc: 0.5444\n",
            "Epoch 1000/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7856 - acc: 0.5583 - val_loss: 0.7966 - val_acc: 0.3889\n",
            "Epoch 1001/2048\n",
            "120/120 [==============================] - 0s 344us/step - loss: 0.7668 - acc: 0.5417 - val_loss: 0.7977 - val_acc: 0.5778\n",
            "Epoch 1002/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7426 - acc: 0.5250 - val_loss: 0.7822 - val_acc: 0.5444\n",
            "Epoch 1003/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 0.7695 - acc: 0.5250 - val_loss: 0.7919 - val_acc: 0.5444\n",
            "Epoch 1004/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7347 - acc: 0.5750 - val_loss: 0.7943 - val_acc: 0.5778\n",
            "Epoch 1005/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.8191 - acc: 0.5500 - val_loss: 0.7565 - val_acc: 0.5444\n",
            "Epoch 1006/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7835 - acc: 0.4833 - val_loss: 0.7568 - val_acc: 0.5444\n",
            "Epoch 1007/2048\n",
            "120/120 [==============================] - 0s 290us/step - loss: 0.8187 - acc: 0.4333 - val_loss: 0.7782 - val_acc: 0.5889\n",
            "Epoch 1008/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 0.8091 - acc: 0.5000 - val_loss: 0.7915 - val_acc: 0.5778\n",
            "Epoch 1009/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.8092 - acc: 0.5000 - val_loss: 0.7894 - val_acc: 0.5778\n",
            "Epoch 1010/2048\n",
            "120/120 [==============================] - 0s 288us/step - loss: 0.7754 - acc: 0.5417 - val_loss: 0.7868 - val_acc: 0.5444\n",
            "Epoch 1011/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 0.8091 - acc: 0.4417 - val_loss: 0.8051 - val_acc: 0.5444\n",
            "Epoch 1012/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7644 - acc: 0.6000 - val_loss: 0.8014 - val_acc: 0.5889\n",
            "Epoch 1013/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7603 - acc: 0.5500 - val_loss: 0.7727 - val_acc: 0.5778\n",
            "Epoch 1014/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7761 - acc: 0.5583 - val_loss: 0.7863 - val_acc: 0.5444\n",
            "Epoch 1015/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7504 - acc: 0.5667 - val_loss: 0.7887 - val_acc: 0.5778\n",
            "Epoch 1016/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.7921 - acc: 0.5667 - val_loss: 0.7860 - val_acc: 0.3889\n",
            "Epoch 1017/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7759 - acc: 0.5167 - val_loss: 0.8000 - val_acc: 0.5444\n",
            "Epoch 1018/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.8009 - acc: 0.4667 - val_loss: 0.7713 - val_acc: 0.5444\n",
            "Epoch 1019/2048\n",
            "120/120 [==============================] - 0s 348us/step - loss: 0.7661 - acc: 0.5583 - val_loss: 0.7996 - val_acc: 0.5889\n",
            "Epoch 1020/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 0.7835 - acc: 0.5833 - val_loss: 0.7997 - val_acc: 0.5556\n",
            "Epoch 1021/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.8009 - acc: 0.5167 - val_loss: 0.7545 - val_acc: 0.6111\n",
            "Epoch 1022/2048\n",
            "120/120 [==============================] - 0s 287us/step - loss: 0.7311 - acc: 0.5667 - val_loss: 0.7762 - val_acc: 0.5444\n",
            "Epoch 1023/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.7950 - acc: 0.5000 - val_loss: 0.7925 - val_acc: 0.5556\n",
            "Epoch 1024/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7508 - acc: 0.5750 - val_loss: 0.7796 - val_acc: 0.5444\n",
            "Epoch 1025/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7503 - acc: 0.5500 - val_loss: 0.7797 - val_acc: 0.5444\n",
            "Epoch 1026/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.7471 - acc: 0.5583 - val_loss: 0.7709 - val_acc: 0.5444\n",
            "Epoch 1027/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.8169 - acc: 0.4583 - val_loss: 0.7807 - val_acc: 0.5444\n",
            "Epoch 1028/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7668 - acc: 0.5000 - val_loss: 0.7835 - val_acc: 0.5444\n",
            "Epoch 1029/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7589 - acc: 0.5750 - val_loss: 0.7994 - val_acc: 0.5778\n",
            "Epoch 1030/2048\n",
            "120/120 [==============================] - 0s 280us/step - loss: 0.7846 - acc: 0.4750 - val_loss: 0.7821 - val_acc: 0.5778\n",
            "Epoch 1031/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7691 - acc: 0.5083 - val_loss: 0.8024 - val_acc: 0.5444\n",
            "Epoch 1032/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.8018 - acc: 0.4750 - val_loss: 0.7611 - val_acc: 0.5444\n",
            "Epoch 1033/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7587 - acc: 0.5500 - val_loss: 0.7624 - val_acc: 0.5889\n",
            "Epoch 1034/2048\n",
            "120/120 [==============================] - 0s 353us/step - loss: 0.7920 - acc: 0.4917 - val_loss: 0.7628 - val_acc: 0.3889\n",
            "Epoch 1035/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.7586 - acc: 0.4917 - val_loss: 0.7572 - val_acc: 0.5889\n",
            "Epoch 1036/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.7949 - acc: 0.5583 - val_loss: 0.7940 - val_acc: 0.5778\n",
            "Epoch 1037/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7987 - acc: 0.5083 - val_loss: 0.8082 - val_acc: 0.5556\n",
            "Epoch 1038/2048\n",
            "120/120 [==============================] - 0s 345us/step - loss: 0.7599 - acc: 0.5000 - val_loss: 0.7965 - val_acc: 0.5778\n",
            "Epoch 1039/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7170 - acc: 0.6167 - val_loss: 0.7985 - val_acc: 0.5444\n",
            "Epoch 1040/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7692 - acc: 0.5667 - val_loss: 0.7817 - val_acc: 0.5778\n",
            "Epoch 1041/2048\n",
            "120/120 [==============================] - 0s 283us/step - loss: 0.8008 - acc: 0.4417 - val_loss: 0.7778 - val_acc: 0.5778\n",
            "Epoch 1042/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7535 - acc: 0.5917 - val_loss: 0.7985 - val_acc: 0.5778\n",
            "Epoch 1043/2048\n",
            "120/120 [==============================] - 0s 364us/step - loss: 0.8000 - acc: 0.4417 - val_loss: 0.7883 - val_acc: 0.5778\n",
            "Epoch 1044/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7423 - acc: 0.5500 - val_loss: 0.8010 - val_acc: 0.5778\n",
            "Epoch 1045/2048\n",
            "120/120 [==============================] - 0s 288us/step - loss: 0.7503 - acc: 0.5000 - val_loss: 0.8031 - val_acc: 0.5444\n",
            "Epoch 1046/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7504 - acc: 0.5417 - val_loss: 0.8059 - val_acc: 0.5778\n",
            "Epoch 1047/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7670 - acc: 0.5750 - val_loss: 0.8077 - val_acc: 0.5444\n",
            "Epoch 1048/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7722 - acc: 0.5500 - val_loss: 0.7662 - val_acc: 0.5444\n",
            "Epoch 1049/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7585 - acc: 0.5833 - val_loss: 0.7665 - val_acc: 0.5444\n",
            "Epoch 1050/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7335 - acc: 0.5500 - val_loss: 0.7679 - val_acc: 0.5889\n",
            "Epoch 1051/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7695 - acc: 0.5583 - val_loss: 0.7501 - val_acc: 0.5556\n",
            "Epoch 1052/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7585 - acc: 0.5833 - val_loss: 0.7508 - val_acc: 0.5556\n",
            "Epoch 1053/2048\n",
            "120/120 [==============================] - 0s 382us/step - loss: 0.7831 - acc: 0.4750 - val_loss: 0.7700 - val_acc: 0.5444\n",
            "Epoch 1054/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7434 - acc: 0.5750 - val_loss: 0.7913 - val_acc: 0.5444\n",
            "Epoch 1055/2048\n",
            "120/120 [==============================] - 0s 352us/step - loss: 0.7585 - acc: 0.5250 - val_loss: 0.7914 - val_acc: 0.5778\n",
            "Epoch 1056/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7502 - acc: 0.5917 - val_loss: 0.7944 - val_acc: 0.5556\n",
            "Epoch 1057/2048\n",
            "120/120 [==============================] - 0s 346us/step - loss: 0.7536 - acc: 0.5500 - val_loss: 0.7837 - val_acc: 0.5444\n",
            "Epoch 1058/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.7669 - acc: 0.6000 - val_loss: 0.7900 - val_acc: 0.5778\n",
            "Epoch 1059/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7336 - acc: 0.5500 - val_loss: 0.7896 - val_acc: 0.5444\n",
            "Epoch 1060/2048\n",
            "120/120 [==============================] - 0s 348us/step - loss: 0.7671 - acc: 0.5167 - val_loss: 0.8038 - val_acc: 0.5778\n",
            "Epoch 1061/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7503 - acc: 0.4917 - val_loss: 0.8038 - val_acc: 0.5778\n",
            "Epoch 1062/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7503 - acc: 0.5333 - val_loss: 0.8077 - val_acc: 0.5444\n",
            "Epoch 1063/2048\n",
            "120/120 [==============================] - 0s 290us/step - loss: 0.7919 - acc: 0.5750 - val_loss: 0.8084 - val_acc: 0.5444\n",
            "Epoch 1064/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7676 - acc: 0.5333 - val_loss: 0.7842 - val_acc: 0.5778\n",
            "Epoch 1065/2048\n",
            "120/120 [==============================] - 0s 351us/step - loss: 0.7755 - acc: 0.5417 - val_loss: 0.8029 - val_acc: 0.5444\n",
            "Epoch 1066/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7752 - acc: 0.5000 - val_loss: 0.8033 - val_acc: 0.5778\n",
            "Epoch 1067/2048\n",
            "120/120 [==============================] - 0s 361us/step - loss: 0.7865 - acc: 0.4667 - val_loss: 0.7785 - val_acc: 0.5778\n",
            "Epoch 1068/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.7338 - acc: 0.5500 - val_loss: 0.7957 - val_acc: 0.5778\n",
            "Epoch 1069/2048\n",
            "120/120 [==============================] - 0s 288us/step - loss: 0.7835 - acc: 0.5333 - val_loss: 0.7960 - val_acc: 0.5778\n",
            "Epoch 1070/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7834 - acc: 0.5333 - val_loss: 0.7960 - val_acc: 0.5444\n",
            "Epoch 1071/2048\n",
            "120/120 [==============================] - 0s 371us/step - loss: 0.7585 - acc: 0.5417 - val_loss: 0.7992 - val_acc: 0.5444\n",
            "Epoch 1072/2048\n",
            "120/120 [==============================] - 0s 399us/step - loss: 0.7337 - acc: 0.5250 - val_loss: 0.8047 - val_acc: 0.5556\n",
            "Epoch 1073/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.8249 - acc: 0.4750 - val_loss: 0.7823 - val_acc: 0.5444\n",
            "Epoch 1074/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7519 - acc: 0.5750 - val_loss: 0.7530 - val_acc: 0.5556\n",
            "Epoch 1075/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.7503 - acc: 0.5333 - val_loss: 0.7545 - val_acc: 0.3889\n",
            "Epoch 1076/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7587 - acc: 0.5583 - val_loss: 0.7711 - val_acc: 0.5778\n",
            "Epoch 1077/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.7922 - acc: 0.5167 - val_loss: 0.7930 - val_acc: 0.5778\n",
            "Epoch 1078/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7503 - acc: 0.5083 - val_loss: 0.7931 - val_acc: 0.5444\n",
            "Epoch 1079/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7501 - acc: 0.5333 - val_loss: 0.7932 - val_acc: 0.5444\n",
            "Epoch 1080/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7418 - acc: 0.5333 - val_loss: 0.7935 - val_acc: 0.5444\n",
            "Epoch 1081/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7753 - acc: 0.4667 - val_loss: 0.7953 - val_acc: 0.5778\n",
            "Epoch 1082/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7842 - acc: 0.5167 - val_loss: 0.7833 - val_acc: 0.5444\n",
            "Epoch 1083/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7752 - acc: 0.4833 - val_loss: 0.7847 - val_acc: 0.5444\n",
            "Epoch 1084/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7853 - acc: 0.5000 - val_loss: 0.7922 - val_acc: 0.5444\n",
            "Epoch 1085/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7585 - acc: 0.5167 - val_loss: 0.7984 - val_acc: 0.5778\n",
            "Epoch 1086/2048\n",
            "120/120 [==============================] - 0s 365us/step - loss: 0.7752 - acc: 0.5333 - val_loss: 0.8038 - val_acc: 0.5778\n",
            "Epoch 1087/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7703 - acc: 0.5500 - val_loss: 0.7937 - val_acc: 0.5778\n",
            "Epoch 1088/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.8002 - acc: 0.5083 - val_loss: 0.7937 - val_acc: 0.5444\n",
            "Epoch 1089/2048\n",
            "120/120 [==============================] - 0s 351us/step - loss: 0.7803 - acc: 0.5750 - val_loss: 0.8057 - val_acc: 0.5778\n",
            "Epoch 1090/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7831 - acc: 0.5000 - val_loss: 0.7928 - val_acc: 0.5444\n",
            "Epoch 1091/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7918 - acc: 0.4833 - val_loss: 0.7935 - val_acc: 0.3889\n",
            "Epoch 1092/2048\n",
            "120/120 [==============================] - 0s 382us/step - loss: 0.7763 - acc: 0.5333 - val_loss: 0.7998 - val_acc: 0.5778\n",
            "Epoch 1093/2048\n",
            "120/120 [==============================] - 0s 368us/step - loss: 0.7586 - acc: 0.5667 - val_loss: 0.8057 - val_acc: 0.5778\n",
            "Epoch 1094/2048\n",
            "120/120 [==============================] - 0s 380us/step - loss: 0.8416 - acc: 0.4667 - val_loss: 0.7554 - val_acc: 0.6000\n",
            "Epoch 1095/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7751 - acc: 0.5750 - val_loss: 0.7558 - val_acc: 0.5556\n",
            "Epoch 1096/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.7422 - acc: 0.5333 - val_loss: 0.7733 - val_acc: 0.5444\n",
            "Epoch 1097/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.7612 - acc: 0.6083 - val_loss: 0.8047 - val_acc: 0.5444\n",
            "Epoch 1098/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.8002 - acc: 0.5667 - val_loss: 0.8055 - val_acc: 0.5778\n",
            "Epoch 1099/2048\n",
            "120/120 [==============================] - 0s 363us/step - loss: 0.8012 - acc: 0.5417 - val_loss: 0.7822 - val_acc: 0.5889\n",
            "Epoch 1100/2048\n",
            "120/120 [==============================] - 0s 352us/step - loss: 0.7753 - acc: 0.5000 - val_loss: 0.7830 - val_acc: 0.5444\n",
            "Epoch 1101/2048\n",
            "120/120 [==============================] - 0s 361us/step - loss: 0.7418 - acc: 0.5833 - val_loss: 0.7859 - val_acc: 0.5778\n",
            "Epoch 1102/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7668 - acc: 0.5250 - val_loss: 0.7865 - val_acc: 0.5778\n",
            "Epoch 1103/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.7668 - acc: 0.5750 - val_loss: 0.7926 - val_acc: 0.5778\n",
            "Epoch 1104/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7628 - acc: 0.5917 - val_loss: 0.7891 - val_acc: 0.5778\n",
            "Epoch 1105/2048\n",
            "120/120 [==============================] - 0s 365us/step - loss: 0.7441 - acc: 0.6167 - val_loss: 0.7906 - val_acc: 0.5444\n",
            "Epoch 1106/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7418 - acc: 0.5917 - val_loss: 0.7942 - val_acc: 0.5444\n",
            "Epoch 1107/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7520 - acc: 0.5250 - val_loss: 0.8059 - val_acc: 0.5444\n",
            "Epoch 1108/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7835 - acc: 0.5417 - val_loss: 0.8054 - val_acc: 0.5778\n",
            "Epoch 1109/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.8189 - acc: 0.4083 - val_loss: 0.7588 - val_acc: 0.3889\n",
            "Epoch 1110/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7505 - acc: 0.5083 - val_loss: 0.7572 - val_acc: 0.6000\n",
            "Epoch 1111/2048\n",
            "120/120 [==============================] - 0s 340us/step - loss: 0.8085 - acc: 0.5167 - val_loss: 0.7574 - val_acc: 0.6000\n",
            "Epoch 1112/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.7752 - acc: 0.5083 - val_loss: 0.7600 - val_acc: 0.6000\n",
            "Epoch 1113/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7529 - acc: 0.6000 - val_loss: 0.8011 - val_acc: 0.5444\n",
            "Epoch 1114/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 0.7945 - acc: 0.5083 - val_loss: 0.8077 - val_acc: 0.5889\n",
            "Epoch 1115/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.7551 - acc: 0.4917 - val_loss: 0.7923 - val_acc: 0.5778\n",
            "Epoch 1116/2048\n",
            "120/120 [==============================] - 0s 345us/step - loss: 0.7585 - acc: 0.5917 - val_loss: 0.7931 - val_acc: 0.5444\n",
            "Epoch 1117/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7590 - acc: 0.5333 - val_loss: 0.8012 - val_acc: 0.5778\n",
            "Epoch 1118/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7592 - acc: 0.5000 - val_loss: 0.7788 - val_acc: 0.5778\n",
            "Epoch 1119/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7598 - acc: 0.5000 - val_loss: 0.8000 - val_acc: 0.3889\n",
            "Epoch 1120/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7836 - acc: 0.5167 - val_loss: 0.8026 - val_acc: 0.3889\n",
            "Epoch 1121/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7752 - acc: 0.4750 - val_loss: 0.8026 - val_acc: 0.5444\n",
            "Epoch 1122/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7752 - acc: 0.5083 - val_loss: 0.8033 - val_acc: 0.5444\n",
            "Epoch 1123/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7753 - acc: 0.5167 - val_loss: 0.7833 - val_acc: 0.5444\n",
            "Epoch 1124/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.7751 - acc: 0.5250 - val_loss: 0.7837 - val_acc: 0.5444\n",
            "Epoch 1125/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.7754 - acc: 0.5167 - val_loss: 0.7770 - val_acc: 0.5444\n",
            "Epoch 1126/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.8170 - acc: 0.4833 - val_loss: 0.7946 - val_acc: 0.5444\n",
            "Epoch 1127/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7417 - acc: 0.5750 - val_loss: 0.7946 - val_acc: 0.5778\n",
            "Epoch 1128/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.7842 - acc: 0.4750 - val_loss: 0.8018 - val_acc: 0.5444\n",
            "Epoch 1129/2048\n",
            "120/120 [==============================] - 0s 351us/step - loss: 0.7502 - acc: 0.5250 - val_loss: 0.8022 - val_acc: 0.5778\n",
            "Epoch 1130/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7876 - acc: 0.4583 - val_loss: 0.7862 - val_acc: 0.5778\n",
            "Epoch 1131/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.7586 - acc: 0.5000 - val_loss: 0.7933 - val_acc: 0.5444\n",
            "Epoch 1132/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7503 - acc: 0.5000 - val_loss: 0.7972 - val_acc: 0.5444\n",
            "Epoch 1133/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7669 - acc: 0.5417 - val_loss: 0.7978 - val_acc: 0.5556\n",
            "Epoch 1134/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.7681 - acc: 0.5917 - val_loss: 0.7771 - val_acc: 0.3889\n",
            "Epoch 1135/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.8087 - acc: 0.4917 - val_loss: 0.7909 - val_acc: 0.5444\n",
            "Epoch 1136/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.7752 - acc: 0.5167 - val_loss: 0.7966 - val_acc: 0.5444\n",
            "Epoch 1137/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.8088 - acc: 0.4667 - val_loss: 0.8063 - val_acc: 0.5444\n",
            "Epoch 1138/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 0.7423 - acc: 0.5167 - val_loss: 0.8086 - val_acc: 0.5444\n",
            "Epoch 1139/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.7620 - acc: 0.5417 - val_loss: 0.7936 - val_acc: 0.5778\n",
            "Epoch 1140/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7502 - acc: 0.5417 - val_loss: 0.7970 - val_acc: 0.5778\n",
            "Epoch 1141/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7674 - acc: 0.5250 - val_loss: 0.8023 - val_acc: 0.5444\n",
            "Epoch 1142/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.7368 - acc: 0.6083 - val_loss: 0.7633 - val_acc: 0.5556\n",
            "Epoch 1143/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.7921 - acc: 0.4833 - val_loss: 0.7634 - val_acc: 0.5556\n",
            "Epoch 1144/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7523 - acc: 0.6167 - val_loss: 0.7821 - val_acc: 0.5778\n",
            "Epoch 1145/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7502 - acc: 0.4917 - val_loss: 0.7861 - val_acc: 0.5444\n",
            "Epoch 1146/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7586 - acc: 0.4667 - val_loss: 0.7925 - val_acc: 0.5444\n",
            "Epoch 1147/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7628 - acc: 0.5833 - val_loss: 0.7825 - val_acc: 0.5778\n",
            "Epoch 1148/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.8001 - acc: 0.5917 - val_loss: 0.7848 - val_acc: 0.5444\n",
            "Epoch 1149/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7701 - acc: 0.5667 - val_loss: 0.7736 - val_acc: 0.5556\n",
            "Epoch 1150/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 0.7923 - acc: 0.5083 - val_loss: 0.7805 - val_acc: 0.5778\n",
            "Epoch 1151/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7840 - acc: 0.5250 - val_loss: 0.7906 - val_acc: 0.5778\n",
            "Epoch 1152/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7929 - acc: 0.4750 - val_loss: 0.7746 - val_acc: 0.5556\n",
            "Epoch 1153/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7586 - acc: 0.5750 - val_loss: 0.7772 - val_acc: 0.5778\n",
            "Epoch 1154/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7585 - acc: 0.5417 - val_loss: 0.7774 - val_acc: 0.5556\n",
            "Epoch 1155/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7943 - acc: 0.5000 - val_loss: 0.7829 - val_acc: 0.5444\n",
            "Epoch 1156/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7337 - acc: 0.6250 - val_loss: 0.7975 - val_acc: 0.5444\n",
            "Epoch 1157/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7422 - acc: 0.5250 - val_loss: 0.7910 - val_acc: 0.5778\n",
            "Epoch 1158/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7919 - acc: 0.5000 - val_loss: 0.7940 - val_acc: 0.5778\n",
            "Epoch 1159/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7669 - acc: 0.5667 - val_loss: 0.7952 - val_acc: 0.5444\n",
            "Epoch 1160/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7770 - acc: 0.4417 - val_loss: 0.7773 - val_acc: 0.5444\n",
            "Epoch 1161/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7511 - acc: 0.5333 - val_loss: 0.8013 - val_acc: 0.3889\n",
            "Epoch 1162/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7335 - acc: 0.5500 - val_loss: 0.8011 - val_acc: 0.5556\n",
            "Epoch 1163/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7601 - acc: 0.5083 - val_loss: 0.7787 - val_acc: 0.5778\n",
            "Epoch 1164/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7502 - acc: 0.5583 - val_loss: 0.7844 - val_acc: 0.5444\n",
            "Epoch 1165/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7752 - acc: 0.5000 - val_loss: 0.7872 - val_acc: 0.5444\n",
            "Epoch 1166/2048\n",
            "120/120 [==============================] - 0s 348us/step - loss: 0.7585 - acc: 0.5333 - val_loss: 0.7888 - val_acc: 0.5444\n",
            "Epoch 1167/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7674 - acc: 0.5917 - val_loss: 0.8068 - val_acc: 0.5556\n",
            "Epoch 1168/2048\n",
            "120/120 [==============================] - 0s 362us/step - loss: 0.8186 - acc: 0.5000 - val_loss: 0.7828 - val_acc: 0.5444\n",
            "Epoch 1169/2048\n",
            "120/120 [==============================] - 0s 1ms/step - loss: 0.7752 - acc: 0.5083 - val_loss: 0.7822 - val_acc: 0.5444\n",
            "Epoch 1170/2048\n",
            "120/120 [==============================] - 0s 360us/step - loss: 0.7586 - acc: 0.5333 - val_loss: 0.7874 - val_acc: 0.5444\n",
            "Epoch 1171/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7252 - acc: 0.4833 - val_loss: 0.7872 - val_acc: 0.5444\n",
            "Epoch 1172/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7502 - acc: 0.5583 - val_loss: 0.7955 - val_acc: 0.5444\n",
            "Epoch 1173/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.8086 - acc: 0.4750 - val_loss: 0.8039 - val_acc: 0.5778\n",
            "Epoch 1174/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.7666 - acc: 0.6083 - val_loss: 0.7821 - val_acc: 0.3889\n",
            "Epoch 1175/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7335 - acc: 0.5667 - val_loss: 0.7840 - val_acc: 0.5444\n",
            "Epoch 1176/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.8255 - acc: 0.4500 - val_loss: 0.8038 - val_acc: 0.5778\n",
            "Epoch 1177/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7585 - acc: 0.5750 - val_loss: 0.8059 - val_acc: 0.5778\n",
            "Epoch 1178/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7809 - acc: 0.5250 - val_loss: 0.7551 - val_acc: 0.5556\n",
            "Epoch 1179/2048\n",
            "120/120 [==============================] - 0s 349us/step - loss: 0.7506 - acc: 0.5167 - val_loss: 0.7768 - val_acc: 0.5778\n",
            "Epoch 1180/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7867 - acc: 0.4833 - val_loss: 0.7705 - val_acc: 0.5444\n",
            "Epoch 1181/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7918 - acc: 0.5083 - val_loss: 0.7707 - val_acc: 0.3889\n",
            "Epoch 1182/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.7835 - acc: 0.4917 - val_loss: 0.7727 - val_acc: 0.5444\n",
            "Epoch 1183/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7836 - acc: 0.5083 - val_loss: 0.7747 - val_acc: 0.5778\n",
            "Epoch 1184/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7753 - acc: 0.5417 - val_loss: 0.7918 - val_acc: 0.5778\n",
            "Epoch 1185/2048\n",
            "120/120 [==============================] - 0s 292us/step - loss: 0.7677 - acc: 0.5500 - val_loss: 0.8058 - val_acc: 0.5778\n",
            "Epoch 1186/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.7317 - acc: 0.6000 - val_loss: 0.8023 - val_acc: 0.5444\n",
            "Epoch 1187/2048\n",
            "120/120 [==============================] - 0s 361us/step - loss: 0.7423 - acc: 0.5917 - val_loss: 0.7737 - val_acc: 0.5778\n",
            "Epoch 1188/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7569 - acc: 0.5583 - val_loss: 0.7930 - val_acc: 0.5444\n",
            "Epoch 1189/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7836 - acc: 0.4750 - val_loss: 0.7992 - val_acc: 0.5444\n",
            "Epoch 1190/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7528 - acc: 0.5083 - val_loss: 0.8069 - val_acc: 0.5778\n",
            "Epoch 1191/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.8022 - acc: 0.5333 - val_loss: 0.7983 - val_acc: 0.5778\n",
            "Epoch 1192/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.8223 - acc: 0.5000 - val_loss: 0.8056 - val_acc: 0.5778\n",
            "Epoch 1193/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7419 - acc: 0.5500 - val_loss: 0.8060 - val_acc: 0.5444\n",
            "Epoch 1194/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.8013 - acc: 0.5000 - val_loss: 0.7875 - val_acc: 0.3889\n",
            "Epoch 1195/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 0.7585 - acc: 0.5333 - val_loss: 0.7903 - val_acc: 0.5444\n",
            "Epoch 1196/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7589 - acc: 0.5000 - val_loss: 0.8007 - val_acc: 0.5778\n",
            "Epoch 1197/2048\n",
            "120/120 [==============================] - 0s 348us/step - loss: 0.7335 - acc: 0.5417 - val_loss: 0.8009 - val_acc: 0.3889\n",
            "Epoch 1198/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7751 - acc: 0.5583 - val_loss: 0.8017 - val_acc: 0.5778\n",
            "Epoch 1199/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7835 - acc: 0.5250 - val_loss: 0.8018 - val_acc: 0.5778\n",
            "Epoch 1200/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7835 - acc: 0.5167 - val_loss: 0.8019 - val_acc: 0.5778\n",
            "Epoch 1201/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7752 - acc: 0.5083 - val_loss: 0.8023 - val_acc: 0.5778\n",
            "Epoch 1202/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.7352 - acc: 0.6000 - val_loss: 0.7698 - val_acc: 0.5444\n",
            "Epoch 1203/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.7862 - acc: 0.5083 - val_loss: 0.7651 - val_acc: 0.5889\n",
            "Epoch 1204/2048\n",
            "120/120 [==============================] - 0s 366us/step - loss: 0.8003 - acc: 0.4667 - val_loss: 0.7684 - val_acc: 0.5444\n",
            "Epoch 1205/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7668 - acc: 0.5583 - val_loss: 0.7691 - val_acc: 0.3889\n",
            "Epoch 1206/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7420 - acc: 0.5083 - val_loss: 0.7838 - val_acc: 0.5444\n",
            "Epoch 1207/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7753 - acc: 0.5250 - val_loss: 0.7900 - val_acc: 0.5444\n",
            "Epoch 1208/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7920 - acc: 0.5167 - val_loss: 0.7902 - val_acc: 0.5778\n",
            "Epoch 1209/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.7836 - acc: 0.4917 - val_loss: 0.7905 - val_acc: 0.5778\n",
            "Epoch 1210/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 0.8094 - acc: 0.4667 - val_loss: 0.7760 - val_acc: 0.5444\n",
            "Epoch 1211/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7566 - acc: 0.5750 - val_loss: 0.7536 - val_acc: 0.6111\n",
            "Epoch 1212/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.7855 - acc: 0.4500 - val_loss: 0.7668 - val_acc: 0.6000\n",
            "Epoch 1213/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7670 - acc: 0.5417 - val_loss: 0.7750 - val_acc: 0.5444\n",
            "Epoch 1214/2048\n",
            "120/120 [==============================] - 0s 345us/step - loss: 0.7379 - acc: 0.5500 - val_loss: 0.7575 - val_acc: 0.5556\n",
            "Epoch 1215/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.8085 - acc: 0.5167 - val_loss: 0.7584 - val_acc: 0.5889\n",
            "Epoch 1216/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 0.7669 - acc: 0.5083 - val_loss: 0.7589 - val_acc: 0.5556\n",
            "Epoch 1217/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.7676 - acc: 0.4833 - val_loss: 0.7689 - val_acc: 0.5778\n",
            "Epoch 1218/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.8085 - acc: 0.4917 - val_loss: 0.7730 - val_acc: 0.5444\n",
            "Epoch 1219/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7335 - acc: 0.5750 - val_loss: 0.7784 - val_acc: 0.5444\n",
            "Epoch 1220/2048\n",
            "120/120 [==============================] - 0s 362us/step - loss: 0.8088 - acc: 0.4500 - val_loss: 0.7856 - val_acc: 0.5778\n",
            "Epoch 1221/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.8010 - acc: 0.5000 - val_loss: 0.8066 - val_acc: 0.5778\n",
            "Epoch 1222/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.7838 - acc: 0.5000 - val_loss: 0.7886 - val_acc: 0.5444\n",
            "Epoch 1223/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 0.7835 - acc: 0.5167 - val_loss: 0.7894 - val_acc: 0.5778\n",
            "Epoch 1224/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7418 - acc: 0.5750 - val_loss: 0.7915 - val_acc: 0.5778\n",
            "Epoch 1225/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.7421 - acc: 0.5667 - val_loss: 0.8051 - val_acc: 0.5444\n",
            "Epoch 1226/2048\n",
            "120/120 [==============================] - 0s 364us/step - loss: 0.7669 - acc: 0.5167 - val_loss: 0.7876 - val_acc: 0.5778\n",
            "Epoch 1227/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.7835 - acc: 0.5167 - val_loss: 0.7880 - val_acc: 0.5444\n",
            "Epoch 1228/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.8003 - acc: 0.4833 - val_loss: 0.7926 - val_acc: 0.5778\n",
            "Epoch 1229/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7835 - acc: 0.5083 - val_loss: 0.7937 - val_acc: 0.5444\n",
            "Epoch 1230/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7668 - acc: 0.5167 - val_loss: 0.7949 - val_acc: 0.5444\n",
            "Epoch 1231/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7523 - acc: 0.5417 - val_loss: 0.7641 - val_acc: 0.3889\n",
            "Epoch 1232/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7669 - acc: 0.5333 - val_loss: 0.7765 - val_acc: 0.5889\n",
            "Epoch 1233/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7919 - acc: 0.4750 - val_loss: 0.7807 - val_acc: 0.5889\n",
            "Epoch 1234/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7774 - acc: 0.5083 - val_loss: 0.7555 - val_acc: 0.6111\n",
            "Epoch 1235/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7587 - acc: 0.5333 - val_loss: 0.7604 - val_acc: 0.5444\n",
            "Epoch 1236/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.8002 - acc: 0.5250 - val_loss: 0.7605 - val_acc: 0.6000\n",
            "Epoch 1237/2048\n",
            "120/120 [==============================] - 0s 349us/step - loss: 0.7585 - acc: 0.5333 - val_loss: 0.7611 - val_acc: 0.6000\n",
            "Epoch 1238/2048\n",
            "120/120 [==============================] - 0s 357us/step - loss: 0.7739 - acc: 0.5333 - val_loss: 0.7930 - val_acc: 0.5778\n",
            "Epoch 1239/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7668 - acc: 0.5500 - val_loss: 0.7932 - val_acc: 0.5444\n",
            "Epoch 1240/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7419 - acc: 0.5500 - val_loss: 0.7927 - val_acc: 0.5778\n",
            "Epoch 1241/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.7855 - acc: 0.5417 - val_loss: 0.7936 - val_acc: 0.5444\n",
            "Epoch 1242/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7670 - acc: 0.6167 - val_loss: 0.7981 - val_acc: 0.5778\n",
            "Epoch 1243/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.7670 - acc: 0.4750 - val_loss: 0.7995 - val_acc: 0.5778\n",
            "Epoch 1244/2048\n",
            "120/120 [==============================] - 0s 346us/step - loss: 0.7835 - acc: 0.5167 - val_loss: 0.8011 - val_acc: 0.5444\n",
            "Epoch 1245/2048\n",
            "120/120 [==============================] - 0s 345us/step - loss: 0.7751 - acc: 0.5417 - val_loss: 0.8016 - val_acc: 0.5778\n",
            "Epoch 1246/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7668 - acc: 0.5250 - val_loss: 0.8015 - val_acc: 0.5778\n",
            "Epoch 1247/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7669 - acc: 0.5083 - val_loss: 0.8050 - val_acc: 0.5778\n",
            "Epoch 1248/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7585 - acc: 0.5333 - val_loss: 0.8050 - val_acc: 0.5778\n",
            "Epoch 1249/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7542 - acc: 0.5667 - val_loss: 0.8055 - val_acc: 0.5778\n",
            "Epoch 1250/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7836 - acc: 0.4667 - val_loss: 0.8057 - val_acc: 0.5444\n",
            "Epoch 1251/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.8172 - acc: 0.4667 - val_loss: 0.8042 - val_acc: 0.5778\n",
            "Epoch 1252/2048\n",
            "120/120 [==============================] - 0s 361us/step - loss: 0.7521 - acc: 0.5750 - val_loss: 0.7971 - val_acc: 0.5444\n",
            "Epoch 1253/2048\n",
            "120/120 [==============================] - 0s 431us/step - loss: 0.7920 - acc: 0.4750 - val_loss: 0.7988 - val_acc: 0.5444\n",
            "Epoch 1254/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.7919 - acc: 0.4583 - val_loss: 0.7765 - val_acc: 0.5444\n",
            "Epoch 1255/2048\n",
            "120/120 [==============================] - 0s 340us/step - loss: 0.7169 - acc: 0.5750 - val_loss: 0.7789 - val_acc: 0.5444\n",
            "Epoch 1256/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7806 - acc: 0.5000 - val_loss: 0.8041 - val_acc: 0.5444\n",
            "Epoch 1257/2048\n",
            "120/120 [==============================] - 0s 402us/step - loss: 0.7588 - acc: 0.5750 - val_loss: 0.8013 - val_acc: 0.5444\n",
            "Epoch 1258/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7964 - acc: 0.5083 - val_loss: 0.8162 - val_acc: 0.5333\n",
            "Epoch 1259/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7592 - acc: 0.5417 - val_loss: 0.8040 - val_acc: 0.5444\n",
            "Epoch 1260/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7668 - acc: 0.4833 - val_loss: 0.8042 - val_acc: 0.5778\n",
            "Epoch 1261/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7360 - acc: 0.5750 - val_loss: 0.7760 - val_acc: 0.5444\n",
            "Epoch 1262/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7934 - acc: 0.5250 - val_loss: 0.7969 - val_acc: 0.5444\n",
            "Epoch 1263/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7919 - acc: 0.5667 - val_loss: 0.7985 - val_acc: 0.5778\n",
            "Epoch 1264/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7585 - acc: 0.4667 - val_loss: 0.7993 - val_acc: 0.5444\n",
            "Epoch 1265/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7585 - acc: 0.5583 - val_loss: 0.8010 - val_acc: 0.5444\n",
            "Epoch 1266/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7585 - acc: 0.5167 - val_loss: 0.8013 - val_acc: 0.5444\n",
            "Epoch 1267/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7418 - acc: 0.5917 - val_loss: 0.8018 - val_acc: 0.5778\n",
            "Epoch 1268/2048\n",
            "120/120 [==============================] - 0s 340us/step - loss: 0.7488 - acc: 0.5167 - val_loss: 0.7780 - val_acc: 0.5889\n",
            "Epoch 1269/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7752 - acc: 0.5583 - val_loss: 0.7832 - val_acc: 0.5444\n",
            "Epoch 1270/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7587 - acc: 0.5583 - val_loss: 0.7881 - val_acc: 0.5444\n",
            "Epoch 1271/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7585 - acc: 0.5167 - val_loss: 0.7882 - val_acc: 0.5444\n",
            "Epoch 1272/2048\n",
            "120/120 [==============================] - 0s 370us/step - loss: 0.7418 - acc: 0.5833 - val_loss: 0.7881 - val_acc: 0.5778\n",
            "Epoch 1273/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7668 - acc: 0.6167 - val_loss: 0.7931 - val_acc: 0.5778\n",
            "Epoch 1274/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.7506 - acc: 0.5667 - val_loss: 0.8063 - val_acc: 0.5889\n",
            "Epoch 1275/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7501 - acc: 0.5750 - val_loss: 0.8023 - val_acc: 0.5778\n",
            "Epoch 1276/2048\n",
            "120/120 [==============================] - 0s 287us/step - loss: 0.7987 - acc: 0.4917 - val_loss: 0.7718 - val_acc: 0.5889\n",
            "Epoch 1277/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7922 - acc: 0.5000 - val_loss: 0.7672 - val_acc: 0.5889\n",
            "Epoch 1278/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7770 - acc: 0.5167 - val_loss: 0.7922 - val_acc: 0.5444\n",
            "Epoch 1279/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7415 - acc: 0.5583 - val_loss: 0.8049 - val_acc: 0.5778\n",
            "Epoch 1280/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.7752 - acc: 0.5583 - val_loss: 0.8052 - val_acc: 0.5444\n",
            "Epoch 1281/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7752 - acc: 0.5250 - val_loss: 0.8053 - val_acc: 0.5778\n",
            "Epoch 1282/2048\n",
            "120/120 [==============================] - 0s 351us/step - loss: 0.7753 - acc: 0.5583 - val_loss: 0.8072 - val_acc: 0.5444\n",
            "Epoch 1283/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 0.7744 - acc: 0.5417 - val_loss: 0.7980 - val_acc: 0.5778\n",
            "Epoch 1284/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.8169 - acc: 0.4500 - val_loss: 0.7980 - val_acc: 0.5778\n",
            "Epoch 1285/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.8336 - acc: 0.4167 - val_loss: 0.7982 - val_acc: 0.5444\n",
            "Epoch 1286/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7751 - acc: 0.5417 - val_loss: 0.8015 - val_acc: 0.5444\n",
            "Epoch 1287/2048\n",
            "120/120 [==============================] - 0s 356us/step - loss: 0.7425 - acc: 0.5333 - val_loss: 0.7875 - val_acc: 0.5444\n",
            "Epoch 1288/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 0.7835 - acc: 0.5083 - val_loss: 0.7923 - val_acc: 0.5444\n",
            "Epoch 1289/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 0.8003 - acc: 0.4833 - val_loss: 0.7784 - val_acc: 0.5778\n",
            "Epoch 1290/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7836 - acc: 0.4417 - val_loss: 0.7851 - val_acc: 0.5778\n",
            "Epoch 1291/2048\n",
            "120/120 [==============================] - 0s 296us/step - loss: 0.7765 - acc: 0.5583 - val_loss: 0.7753 - val_acc: 0.5778\n",
            "Epoch 1292/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7418 - acc: 0.5083 - val_loss: 0.7786 - val_acc: 0.5444\n",
            "Epoch 1293/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.7802 - acc: 0.5167 - val_loss: 0.7988 - val_acc: 0.5444\n",
            "Epoch 1294/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.7671 - acc: 0.5417 - val_loss: 0.8057 - val_acc: 0.5778\n",
            "Epoch 1295/2048\n",
            "120/120 [==============================] - 0s 345us/step - loss: 0.7921 - acc: 0.4167 - val_loss: 0.8072 - val_acc: 0.5778\n",
            "Epoch 1296/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7251 - acc: 0.6000 - val_loss: 0.8073 - val_acc: 0.5444\n",
            "Epoch 1297/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7611 - acc: 0.5250 - val_loss: 0.7934 - val_acc: 0.5444\n",
            "Epoch 1298/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7839 - acc: 0.5083 - val_loss: 0.7993 - val_acc: 0.3889\n",
            "Epoch 1299/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7418 - acc: 0.5750 - val_loss: 0.8001 - val_acc: 0.5778\n",
            "Epoch 1300/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7668 - acc: 0.5667 - val_loss: 0.8011 - val_acc: 0.5444\n",
            "Epoch 1301/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7501 - acc: 0.5583 - val_loss: 0.8015 - val_acc: 0.5444\n",
            "Epoch 1302/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7753 - acc: 0.5083 - val_loss: 0.7725 - val_acc: 0.5444\n",
            "Epoch 1303/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7585 - acc: 0.5750 - val_loss: 0.7741 - val_acc: 0.5444\n",
            "Epoch 1304/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7668 - acc: 0.4917 - val_loss: 0.7744 - val_acc: 0.5444\n",
            "Epoch 1305/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.7419 - acc: 0.5333 - val_loss: 0.7810 - val_acc: 0.5778\n",
            "Epoch 1306/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7920 - acc: 0.5000 - val_loss: 0.7888 - val_acc: 0.5778\n",
            "Epoch 1307/2048\n",
            "120/120 [==============================] - 0s 360us/step - loss: 0.7910 - acc: 0.4833 - val_loss: 0.7993 - val_acc: 0.5444\n",
            "Epoch 1308/2048\n",
            "120/120 [==============================] - 0s 295us/step - loss: 0.7619 - acc: 0.5250 - val_loss: 0.8087 - val_acc: 0.5333\n",
            "Epoch 1309/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7918 - acc: 0.5667 - val_loss: 0.8086 - val_acc: 0.5778\n",
            "Epoch 1310/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7919 - acc: 0.5083 - val_loss: 0.8088 - val_acc: 0.5333\n",
            "Epoch 1311/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7674 - acc: 0.5333 - val_loss: 0.8029 - val_acc: 0.3889\n",
            "Epoch 1312/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.7793 - acc: 0.5333 - val_loss: 0.8075 - val_acc: 0.5889\n",
            "Epoch 1313/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7418 - acc: 0.5750 - val_loss: 0.8073 - val_acc: 0.5889\n",
            "Epoch 1314/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7628 - acc: 0.5167 - val_loss: 0.8011 - val_acc: 0.5444\n",
            "Epoch 1315/2048\n",
            "120/120 [==============================] - 0s 350us/step - loss: 0.8105 - acc: 0.4833 - val_loss: 0.7931 - val_acc: 0.5444\n",
            "Epoch 1316/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7585 - acc: 0.5000 - val_loss: 0.7937 - val_acc: 0.5444\n",
            "Epoch 1317/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7589 - acc: 0.4917 - val_loss: 0.7997 - val_acc: 0.5444\n",
            "Epoch 1318/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7804 - acc: 0.5167 - val_loss: 0.7973 - val_acc: 0.5778\n",
            "Epoch 1319/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7688 - acc: 0.5917 - val_loss: 0.7675 - val_acc: 0.5889\n",
            "Epoch 1320/2048\n",
            "120/120 [==============================] - 0s 349us/step - loss: 0.7755 - acc: 0.5000 - val_loss: 0.7677 - val_acc: 0.3889\n",
            "Epoch 1321/2048\n",
            "120/120 [==============================] - 0s 350us/step - loss: 0.7941 - acc: 0.5417 - val_loss: 0.7876 - val_acc: 0.3889\n",
            "Epoch 1322/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.7668 - acc: 0.5417 - val_loss: 0.7876 - val_acc: 0.5556\n",
            "Epoch 1323/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7496 - acc: 0.5667 - val_loss: 0.7857 - val_acc: 0.5444\n",
            "Epoch 1324/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7652 - acc: 0.5500 - val_loss: 0.7928 - val_acc: 0.5444\n",
            "Epoch 1325/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7752 - acc: 0.4917 - val_loss: 0.7928 - val_acc: 0.5778\n",
            "Epoch 1326/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7585 - acc: 0.5167 - val_loss: 0.7931 - val_acc: 0.5444\n",
            "Epoch 1327/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7673 - acc: 0.5083 - val_loss: 0.7962 - val_acc: 0.5444\n",
            "Epoch 1328/2048\n",
            "120/120 [==============================] - 0s 361us/step - loss: 0.7836 - acc: 0.4583 - val_loss: 0.7968 - val_acc: 0.5778\n",
            "Epoch 1329/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.8002 - acc: 0.5000 - val_loss: 0.8017 - val_acc: 0.3889\n",
            "Epoch 1330/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7722 - acc: 0.4667 - val_loss: 0.7847 - val_acc: 0.5444\n",
            "Epoch 1331/2048\n",
            "120/120 [==============================] - 0s 357us/step - loss: 0.8089 - acc: 0.4500 - val_loss: 0.7834 - val_acc: 0.5444\n",
            "Epoch 1332/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.8002 - acc: 0.4917 - val_loss: 0.7847 - val_acc: 0.5778\n",
            "Epoch 1333/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7684 - acc: 0.6000 - val_loss: 0.7986 - val_acc: 0.5556\n",
            "Epoch 1334/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7419 - acc: 0.5000 - val_loss: 0.7992 - val_acc: 0.5556\n",
            "Epoch 1335/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7336 - acc: 0.5917 - val_loss: 0.7999 - val_acc: 0.5889\n",
            "Epoch 1336/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 0.7585 - acc: 0.5000 - val_loss: 0.7999 - val_acc: 0.5556\n",
            "Epoch 1337/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7536 - acc: 0.4750 - val_loss: 0.7789 - val_acc: 0.5778\n",
            "Epoch 1338/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.8086 - acc: 0.4500 - val_loss: 0.7874 - val_acc: 0.5444\n",
            "Epoch 1339/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7669 - acc: 0.5417 - val_loss: 0.7909 - val_acc: 0.5444\n",
            "Epoch 1340/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7505 - acc: 0.4833 - val_loss: 0.7708 - val_acc: 0.5889\n",
            "Epoch 1341/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.8125 - acc: 0.5083 - val_loss: 0.8059 - val_acc: 0.3889\n",
            "Epoch 1342/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7335 - acc: 0.6250 - val_loss: 0.8066 - val_acc: 0.5333\n",
            "Epoch 1343/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7598 - acc: 0.5583 - val_loss: 0.7911 - val_acc: 0.5444\n",
            "Epoch 1344/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.8003 - acc: 0.4750 - val_loss: 0.7910 - val_acc: 0.5778\n",
            "Epoch 1345/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7419 - acc: 0.5667 - val_loss: 0.7922 - val_acc: 0.5778\n",
            "Epoch 1346/2048\n",
            "120/120 [==============================] - 0s 292us/step - loss: 0.7752 - acc: 0.5667 - val_loss: 0.7930 - val_acc: 0.5444\n",
            "Epoch 1347/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7361 - acc: 0.5833 - val_loss: 0.7866 - val_acc: 0.5444\n",
            "Epoch 1348/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.7752 - acc: 0.5333 - val_loss: 0.7945 - val_acc: 0.5778\n",
            "Epoch 1349/2048\n",
            "120/120 [==============================] - 0s 282us/step - loss: 0.7919 - acc: 0.4333 - val_loss: 0.8000 - val_acc: 0.5778\n",
            "Epoch 1350/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.7585 - acc: 0.5333 - val_loss: 0.8000 - val_acc: 0.5778\n",
            "Epoch 1351/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7501 - acc: 0.5333 - val_loss: 0.8003 - val_acc: 0.5778\n",
            "Epoch 1352/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7339 - acc: 0.5000 - val_loss: 0.8101 - val_acc: 0.5778\n",
            "Epoch 1353/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.8001 - acc: 0.4583 - val_loss: 0.8080 - val_acc: 0.5778\n",
            "Epoch 1354/2048\n",
            "120/120 [==============================] - 0s 356us/step - loss: 0.7998 - acc: 0.4667 - val_loss: 0.8073 - val_acc: 0.5889\n",
            "Epoch 1355/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7418 - acc: 0.5417 - val_loss: 0.8074 - val_acc: 0.5444\n",
            "Epoch 1356/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7986 - acc: 0.4417 - val_loss: 0.8098 - val_acc: 0.5889\n",
            "Epoch 1357/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.8118 - acc: 0.4917 - val_loss: 0.8033 - val_acc: 0.5444\n",
            "Epoch 1358/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7919 - acc: 0.5167 - val_loss: 0.8037 - val_acc: 0.5444\n",
            "Epoch 1359/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7669 - acc: 0.5083 - val_loss: 0.8049 - val_acc: 0.5444\n",
            "Epoch 1360/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7691 - acc: 0.4250 - val_loss: 0.7907 - val_acc: 0.5444\n",
            "Epoch 1361/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7513 - acc: 0.5750 - val_loss: 0.8042 - val_acc: 0.5444\n",
            "Epoch 1362/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.8087 - acc: 0.5083 - val_loss: 0.8022 - val_acc: 0.3889\n",
            "Epoch 1363/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.7726 - acc: 0.5083 - val_loss: 0.7869 - val_acc: 0.5778\n",
            "Epoch 1364/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.8003 - acc: 0.4917 - val_loss: 0.7969 - val_acc: 0.5778\n",
            "Epoch 1365/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7752 - acc: 0.5417 - val_loss: 0.7979 - val_acc: 0.5444\n",
            "Epoch 1366/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7418 - acc: 0.5333 - val_loss: 0.7979 - val_acc: 0.5444\n",
            "Epoch 1367/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.8091 - acc: 0.4917 - val_loss: 0.8010 - val_acc: 0.5444\n",
            "Epoch 1368/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.7668 - acc: 0.4750 - val_loss: 0.8011 - val_acc: 0.5444\n",
            "Epoch 1369/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7752 - acc: 0.5833 - val_loss: 0.8030 - val_acc: 0.5778\n",
            "Epoch 1370/2048\n",
            "120/120 [==============================] - 0s 348us/step - loss: 0.8009 - acc: 0.5667 - val_loss: 0.7958 - val_acc: 0.5778\n",
            "Epoch 1371/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.8019 - acc: 0.4583 - val_loss: 0.8057 - val_acc: 0.5778\n",
            "Epoch 1372/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.7502 - acc: 0.5000 - val_loss: 0.8063 - val_acc: 0.5556\n",
            "Epoch 1373/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7838 - acc: 0.4667 - val_loss: 0.8056 - val_acc: 0.5444\n",
            "Epoch 1374/2048\n",
            "120/120 [==============================] - 0s 399us/step - loss: 0.7835 - acc: 0.5417 - val_loss: 0.8069 - val_acc: 0.5889\n",
            "Epoch 1375/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7668 - acc: 0.5250 - val_loss: 0.8069 - val_acc: 0.5556\n",
            "Epoch 1376/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7595 - acc: 0.5417 - val_loss: 0.7738 - val_acc: 0.5444\n",
            "Epoch 1377/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7419 - acc: 0.5917 - val_loss: 0.7810 - val_acc: 0.5444\n",
            "Epoch 1378/2048\n",
            "120/120 [==============================] - 0s 295us/step - loss: 0.7503 - acc: 0.5333 - val_loss: 0.7848 - val_acc: 0.5778\n",
            "Epoch 1379/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7421 - acc: 0.6083 - val_loss: 0.8003 - val_acc: 0.5778\n",
            "Epoch 1380/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.8085 - acc: 0.5250 - val_loss: 0.8004 - val_acc: 0.3889\n",
            "Epoch 1381/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7748 - acc: 0.4333 - val_loss: 0.7739 - val_acc: 0.5778\n",
            "Epoch 1382/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7606 - acc: 0.5000 - val_loss: 0.7615 - val_acc: 0.5556\n",
            "Epoch 1383/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.7670 - acc: 0.5500 - val_loss: 0.7616 - val_acc: 0.3889\n",
            "Epoch 1384/2048\n",
            "120/120 [==============================] - 0s 359us/step - loss: 0.7585 - acc: 0.6000 - val_loss: 0.7622 - val_acc: 0.6111\n",
            "Epoch 1385/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7419 - acc: 0.5667 - val_loss: 0.7715 - val_acc: 0.5556\n",
            "Epoch 1386/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7501 - acc: 0.5583 - val_loss: 0.7715 - val_acc: 0.5889\n",
            "Epoch 1387/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 0.7752 - acc: 0.5500 - val_loss: 0.7759 - val_acc: 0.5889\n",
            "Epoch 1388/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.8085 - acc: 0.5083 - val_loss: 0.7778 - val_acc: 0.3889\n",
            "Epoch 1389/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.7586 - acc: 0.4917 - val_loss: 0.7910 - val_acc: 0.5444\n",
            "Epoch 1390/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.7752 - acc: 0.5667 - val_loss: 0.7950 - val_acc: 0.5556\n",
            "Epoch 1391/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7739 - acc: 0.5750 - val_loss: 0.8000 - val_acc: 0.5444\n",
            "Epoch 1392/2048\n",
            "120/120 [==============================] - 0s 362us/step - loss: 0.7585 - acc: 0.5500 - val_loss: 0.8003 - val_acc: 0.3889\n",
            "Epoch 1393/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7821 - acc: 0.4917 - val_loss: 0.7984 - val_acc: 0.5778\n",
            "Epoch 1394/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7418 - acc: 0.5750 - val_loss: 0.7999 - val_acc: 0.5556\n",
            "Epoch 1395/2048\n",
            "120/120 [==============================] - 0s 289us/step - loss: 0.7669 - acc: 0.5083 - val_loss: 0.7999 - val_acc: 0.5556\n",
            "Epoch 1396/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7836 - acc: 0.5083 - val_loss: 0.8003 - val_acc: 0.5889\n",
            "Epoch 1397/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.7919 - acc: 0.5083 - val_loss: 0.8004 - val_acc: 0.5556\n",
            "Epoch 1398/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7672 - acc: 0.5583 - val_loss: 0.7869 - val_acc: 0.3889\n",
            "Epoch 1399/2048\n",
            "120/120 [==============================] - 0s 340us/step - loss: 0.8176 - acc: 0.4583 - val_loss: 0.7805 - val_acc: 0.5778\n",
            "Epoch 1400/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7669 - acc: 0.5000 - val_loss: 0.7809 - val_acc: 0.5778\n",
            "Epoch 1401/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.7837 - acc: 0.5083 - val_loss: 0.7874 - val_acc: 0.5778\n",
            "Epoch 1402/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7836 - acc: 0.5417 - val_loss: 0.8020 - val_acc: 0.5444\n",
            "Epoch 1403/2048\n",
            "120/120 [==============================] - 0s 362us/step - loss: 0.7690 - acc: 0.5500 - val_loss: 0.7944 - val_acc: 0.5444\n",
            "Epoch 1404/2048\n",
            "120/120 [==============================] - 0s 362us/step - loss: 0.8254 - acc: 0.4833 - val_loss: 0.7880 - val_acc: 0.5444\n",
            "Epoch 1405/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7419 - acc: 0.5000 - val_loss: 0.7884 - val_acc: 0.5444\n",
            "Epoch 1406/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7919 - acc: 0.4583 - val_loss: 0.7887 - val_acc: 0.5778\n",
            "Epoch 1407/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7751 - acc: 0.5167 - val_loss: 0.7904 - val_acc: 0.5778\n",
            "Epoch 1408/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7589 - acc: 0.5333 - val_loss: 0.8060 - val_acc: 0.5778\n",
            "Epoch 1409/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7592 - acc: 0.5667 - val_loss: 0.7851 - val_acc: 0.5778\n",
            "Epoch 1410/2048\n",
            "120/120 [==============================] - 0s 353us/step - loss: 0.7335 - acc: 0.5750 - val_loss: 0.7861 - val_acc: 0.5444\n",
            "Epoch 1411/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7752 - acc: 0.5833 - val_loss: 0.7864 - val_acc: 0.5778\n",
            "Epoch 1412/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7420 - acc: 0.5833 - val_loss: 0.7992 - val_acc: 0.5444\n",
            "Epoch 1413/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7609 - acc: 0.5250 - val_loss: 0.7934 - val_acc: 0.5778\n",
            "Epoch 1414/2048\n",
            "120/120 [==============================] - 0s 358us/step - loss: 0.7919 - acc: 0.5333 - val_loss: 0.7942 - val_acc: 0.5444\n",
            "Epoch 1415/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7601 - acc: 0.5333 - val_loss: 0.7987 - val_acc: 0.5444\n",
            "Epoch 1416/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.7671 - acc: 0.5750 - val_loss: 0.7998 - val_acc: 0.5444\n",
            "Epoch 1417/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7918 - acc: 0.5417 - val_loss: 0.8002 - val_acc: 0.5444\n",
            "Epoch 1418/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.8252 - acc: 0.4917 - val_loss: 0.8002 - val_acc: 0.5444\n",
            "Epoch 1419/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 0.7834 - acc: 0.6083 - val_loss: 0.8003 - val_acc: 0.5778\n",
            "Epoch 1420/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7835 - acc: 0.5250 - val_loss: 0.8012 - val_acc: 0.5778\n",
            "Epoch 1421/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7560 - acc: 0.5083 - val_loss: 0.8093 - val_acc: 0.5444\n",
            "Epoch 1422/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 0.8002 - acc: 0.5333 - val_loss: 0.8095 - val_acc: 0.3889\n",
            "Epoch 1423/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7976 - acc: 0.5333 - val_loss: 0.7796 - val_acc: 0.3889\n",
            "Epoch 1424/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.8087 - acc: 0.5167 - val_loss: 0.7870 - val_acc: 0.5444\n",
            "Epoch 1425/2048\n",
            "120/120 [==============================] - 0s 348us/step - loss: 0.8182 - acc: 0.4417 - val_loss: 0.8020 - val_acc: 0.5444\n",
            "Epoch 1426/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.8002 - acc: 0.5500 - val_loss: 0.8025 - val_acc: 0.5778\n",
            "Epoch 1427/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.8002 - acc: 0.4500 - val_loss: 0.8025 - val_acc: 0.5778\n",
            "Epoch 1428/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7751 - acc: 0.5417 - val_loss: 0.8027 - val_acc: 0.5444\n",
            "Epoch 1429/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7585 - acc: 0.5083 - val_loss: 0.8064 - val_acc: 0.5444\n",
            "Epoch 1430/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.7893 - acc: 0.5083 - val_loss: 0.8113 - val_acc: 0.5333\n",
            "Epoch 1431/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.8001 - acc: 0.4833 - val_loss: 0.8062 - val_acc: 0.5444\n",
            "Epoch 1432/2048\n",
            "120/120 [==============================] - 0s 345us/step - loss: 0.7502 - acc: 0.4750 - val_loss: 0.8062 - val_acc: 0.5444\n",
            "Epoch 1433/2048\n",
            "120/120 [==============================] - 0s 290us/step - loss: 0.7835 - acc: 0.4833 - val_loss: 0.8062 - val_acc: 0.5444\n",
            "Epoch 1434/2048\n",
            "120/120 [==============================] - 0s 346us/step - loss: 0.7526 - acc: 0.5167 - val_loss: 0.7661 - val_acc: 0.5556\n",
            "Epoch 1435/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7585 - acc: 0.5583 - val_loss: 0.7661 - val_acc: 0.5889\n",
            "Epoch 1436/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 0.7839 - acc: 0.5417 - val_loss: 0.7782 - val_acc: 0.5778\n",
            "Epoch 1437/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7752 - acc: 0.5083 - val_loss: 0.7791 - val_acc: 0.5444\n",
            "Epoch 1438/2048\n",
            "120/120 [==============================] - 0s 286us/step - loss: 0.8006 - acc: 0.4917 - val_loss: 0.7937 - val_acc: 0.5444\n",
            "Epoch 1439/2048\n",
            "120/120 [==============================] - 0s 346us/step - loss: 0.7752 - acc: 0.5667 - val_loss: 0.7964 - val_acc: 0.5778\n",
            "Epoch 1440/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.7920 - acc: 0.5500 - val_loss: 0.7797 - val_acc: 0.5556\n",
            "Epoch 1441/2048\n",
            "120/120 [==============================] - 0s 359us/step - loss: 0.8002 - acc: 0.5250 - val_loss: 0.7827 - val_acc: 0.5778\n",
            "Epoch 1442/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7880 - acc: 0.5583 - val_loss: 0.8057 - val_acc: 0.5444\n",
            "Epoch 1443/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 0.7752 - acc: 0.5583 - val_loss: 0.8057 - val_acc: 0.5444\n",
            "Epoch 1444/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7919 - acc: 0.4917 - val_loss: 0.8057 - val_acc: 0.5444\n",
            "Epoch 1445/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.7758 - acc: 0.5167 - val_loss: 0.7861 - val_acc: 0.5778\n",
            "Epoch 1446/2048\n",
            "120/120 [==============================] - 0s 359us/step - loss: 0.7762 - acc: 0.4750 - val_loss: 0.7752 - val_acc: 0.5556\n",
            "Epoch 1447/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7919 - acc: 0.5583 - val_loss: 0.7752 - val_acc: 0.5556\n",
            "Epoch 1448/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 0.7835 - acc: 0.4833 - val_loss: 0.7753 - val_acc: 0.5778\n",
            "Epoch 1449/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7836 - acc: 0.5333 - val_loss: 0.7796 - val_acc: 0.5556\n",
            "Epoch 1450/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.8094 - acc: 0.4417 - val_loss: 0.8013 - val_acc: 0.5444\n",
            "Epoch 1451/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7501 - acc: 0.5417 - val_loss: 0.8017 - val_acc: 0.5444\n",
            "Epoch 1452/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.7946 - acc: 0.5167 - val_loss: 0.7856 - val_acc: 0.5444\n",
            "Epoch 1453/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7501 - acc: 0.5667 - val_loss: 0.7944 - val_acc: 0.5778\n",
            "Epoch 1454/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7921 - acc: 0.5000 - val_loss: 0.7869 - val_acc: 0.5444\n",
            "Epoch 1455/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7608 - acc: 0.5333 - val_loss: 0.7597 - val_acc: 0.6000\n",
            "Epoch 1456/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7335 - acc: 0.5917 - val_loss: 0.7638 - val_acc: 0.6000\n",
            "Epoch 1457/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7678 - acc: 0.5083 - val_loss: 0.7902 - val_acc: 0.5444\n",
            "Epoch 1458/2048\n",
            "120/120 [==============================] - 0s 359us/step - loss: 0.7335 - acc: 0.5667 - val_loss: 0.7902 - val_acc: 0.5444\n",
            "Epoch 1459/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7669 - acc: 0.5000 - val_loss: 0.7914 - val_acc: 0.5778\n",
            "Epoch 1460/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7719 - acc: 0.4833 - val_loss: 0.7765 - val_acc: 0.5444\n",
            "Epoch 1461/2048\n",
            "120/120 [==============================] - 0s 371us/step - loss: 0.8085 - acc: 0.5583 - val_loss: 0.7767 - val_acc: 0.5444\n",
            "Epoch 1462/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7680 - acc: 0.5833 - val_loss: 0.7772 - val_acc: 0.5444\n",
            "Epoch 1463/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.7751 - acc: 0.5417 - val_loss: 0.7785 - val_acc: 0.5778\n",
            "Epoch 1464/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7428 - acc: 0.6250 - val_loss: 0.8034 - val_acc: 0.5778\n",
            "Epoch 1465/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.7585 - acc: 0.5667 - val_loss: 0.8034 - val_acc: 0.5444\n",
            "Epoch 1466/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7669 - acc: 0.5833 - val_loss: 0.8048 - val_acc: 0.5444\n",
            "Epoch 1467/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7669 - acc: 0.5083 - val_loss: 0.8048 - val_acc: 0.5444\n",
            "Epoch 1468/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7918 - acc: 0.5333 - val_loss: 0.8049 - val_acc: 0.5444\n",
            "Epoch 1469/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7754 - acc: 0.5333 - val_loss: 0.7916 - val_acc: 0.5778\n",
            "Epoch 1470/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.7752 - acc: 0.5667 - val_loss: 0.7936 - val_acc: 0.5444\n",
            "Epoch 1471/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7752 - acc: 0.4917 - val_loss: 0.7939 - val_acc: 0.5444\n",
            "Epoch 1472/2048\n",
            "120/120 [==============================] - 0s 283us/step - loss: 0.7585 - acc: 0.5417 - val_loss: 0.8059 - val_acc: 0.5556\n",
            "Epoch 1473/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7546 - acc: 0.5250 - val_loss: 0.7787 - val_acc: 0.5444\n",
            "Epoch 1474/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7756 - acc: 0.4833 - val_loss: 0.7699 - val_acc: 0.5444\n",
            "Epoch 1475/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.7688 - acc: 0.5417 - val_loss: 0.7714 - val_acc: 0.6000\n",
            "Epoch 1476/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7835 - acc: 0.4667 - val_loss: 0.7716 - val_acc: 0.5444\n",
            "Epoch 1477/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7585 - acc: 0.5583 - val_loss: 0.7724 - val_acc: 0.5444\n",
            "Epoch 1478/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7586 - acc: 0.4750 - val_loss: 0.7750 - val_acc: 0.5778\n",
            "Epoch 1479/2048\n",
            "120/120 [==============================] - 0s 348us/step - loss: 0.7672 - acc: 0.4917 - val_loss: 0.7910 - val_acc: 0.5778\n",
            "Epoch 1480/2048\n",
            "120/120 [==============================] - 0s 346us/step - loss: 0.7505 - acc: 0.5750 - val_loss: 0.8014 - val_acc: 0.5444\n",
            "Epoch 1481/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.7585 - acc: 0.5750 - val_loss: 0.8027 - val_acc: 0.5444\n",
            "Epoch 1482/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.8003 - acc: 0.5167 - val_loss: 0.8002 - val_acc: 0.5444\n",
            "Epoch 1483/2048\n",
            "120/120 [==============================] - 0s 344us/step - loss: 0.7882 - acc: 0.5500 - val_loss: 0.8086 - val_acc: 0.6000\n",
            "Epoch 1484/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7850 - acc: 0.5250 - val_loss: 0.7740 - val_acc: 0.5556\n",
            "Epoch 1485/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7585 - acc: 0.4917 - val_loss: 0.7740 - val_acc: 0.5556\n",
            "Epoch 1486/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7502 - acc: 0.5583 - val_loss: 0.7786 - val_acc: 0.5444\n",
            "Epoch 1487/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.8002 - acc: 0.5250 - val_loss: 0.7788 - val_acc: 0.5778\n",
            "Epoch 1488/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.8002 - acc: 0.5083 - val_loss: 0.7866 - val_acc: 0.5778\n",
            "Epoch 1489/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7918 - acc: 0.5000 - val_loss: 0.7876 - val_acc: 0.5444\n",
            "Epoch 1490/2048\n",
            "120/120 [==============================] - 0s 387us/step - loss: 0.7668 - acc: 0.5417 - val_loss: 0.7884 - val_acc: 0.5444\n",
            "Epoch 1491/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.7505 - acc: 0.5833 - val_loss: 0.8048 - val_acc: 0.5778\n",
            "Epoch 1492/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7506 - acc: 0.4917 - val_loss: 0.7824 - val_acc: 0.5778\n",
            "Epoch 1493/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7836 - acc: 0.4750 - val_loss: 0.7824 - val_acc: 0.5778\n",
            "Epoch 1494/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7668 - acc: 0.5000 - val_loss: 0.7824 - val_acc: 0.5778\n",
            "Epoch 1495/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7918 - acc: 0.5333 - val_loss: 0.7847 - val_acc: 0.5778\n",
            "Epoch 1496/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7669 - acc: 0.5333 - val_loss: 0.7994 - val_acc: 0.5444\n",
            "Epoch 1497/2048\n",
            "120/120 [==============================] - 0s 373us/step - loss: 0.7679 - acc: 0.5833 - val_loss: 0.7789 - val_acc: 0.5444\n",
            "Epoch 1498/2048\n",
            "120/120 [==============================] - 0s 344us/step - loss: 0.7418 - acc: 0.5917 - val_loss: 0.7789 - val_acc: 0.5778\n",
            "Epoch 1499/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.7835 - acc: 0.4750 - val_loss: 0.7791 - val_acc: 0.5444\n",
            "Epoch 1500/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7348 - acc: 0.5917 - val_loss: 0.7934 - val_acc: 0.5444\n",
            "Epoch 1501/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7169 - acc: 0.6083 - val_loss: 0.7959 - val_acc: 0.5444\n",
            "Epoch 1502/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 0.7751 - acc: 0.5500 - val_loss: 0.7959 - val_acc: 0.5778\n",
            "Epoch 1503/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 0.7168 - acc: 0.5750 - val_loss: 0.7962 - val_acc: 0.5444\n",
            "Epoch 1504/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7919 - acc: 0.5417 - val_loss: 0.8061 - val_acc: 0.5444\n",
            "Epoch 1505/2048\n",
            "120/120 [==============================] - 0s 360us/step - loss: 0.7681 - acc: 0.5083 - val_loss: 0.8113 - val_acc: 0.3889\n",
            "Epoch 1506/2048\n",
            "120/120 [==============================] - 0s 393us/step - loss: 0.7408 - acc: 0.5750 - val_loss: 0.7969 - val_acc: 0.5778\n",
            "Epoch 1507/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7836 - acc: 0.5167 - val_loss: 0.7979 - val_acc: 0.5444\n",
            "Epoch 1508/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7586 - acc: 0.5667 - val_loss: 0.8008 - val_acc: 0.5778\n",
            "Epoch 1509/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.7839 - acc: 0.5583 - val_loss: 0.7979 - val_acc: 0.5444\n",
            "Epoch 1510/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7585 - acc: 0.5833 - val_loss: 0.8000 - val_acc: 0.5778\n",
            "Epoch 1511/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7687 - acc: 0.5083 - val_loss: 0.8088 - val_acc: 0.5333\n",
            "Epoch 1512/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7762 - acc: 0.5417 - val_loss: 0.7987 - val_acc: 0.5778\n",
            "Epoch 1513/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7668 - acc: 0.5833 - val_loss: 0.8001 - val_acc: 0.5444\n",
            "Epoch 1514/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7668 - acc: 0.5917 - val_loss: 0.8006 - val_acc: 0.5778\n",
            "Epoch 1515/2048\n",
            "120/120 [==============================] - 0s 287us/step - loss: 0.7766 - acc: 0.5083 - val_loss: 0.7652 - val_acc: 0.6000\n",
            "Epoch 1516/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7423 - acc: 0.5500 - val_loss: 0.7870 - val_acc: 0.5889\n",
            "Epoch 1517/2048\n",
            "120/120 [==============================] - 0s 354us/step - loss: 0.7722 - acc: 0.6250 - val_loss: 0.8047 - val_acc: 0.5444\n",
            "Epoch 1518/2048\n",
            "120/120 [==============================] - 0s 353us/step - loss: 0.7526 - acc: 0.5583 - val_loss: 0.7694 - val_acc: 0.5444\n",
            "Epoch 1519/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7586 - acc: 0.5000 - val_loss: 0.7744 - val_acc: 0.5778\n",
            "Epoch 1520/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7835 - acc: 0.5417 - val_loss: 0.7752 - val_acc: 0.5778\n",
            "Epoch 1521/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7687 - acc: 0.4667 - val_loss: 0.8065 - val_acc: 0.5333\n",
            "Epoch 1522/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7562 - acc: 0.5083 - val_loss: 0.7875 - val_acc: 0.5444\n",
            "Epoch 1523/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.7503 - acc: 0.5083 - val_loss: 0.7920 - val_acc: 0.5444\n",
            "Epoch 1524/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7503 - acc: 0.5417 - val_loss: 0.7924 - val_acc: 0.5444\n",
            "Epoch 1525/2048\n",
            "120/120 [==============================] - 0s 355us/step - loss: 0.8169 - acc: 0.5000 - val_loss: 0.7953 - val_acc: 0.5778\n",
            "Epoch 1526/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.8086 - acc: 0.4583 - val_loss: 0.7963 - val_acc: 0.5778\n",
            "Epoch 1527/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.7502 - acc: 0.5583 - val_loss: 0.7966 - val_acc: 0.5444\n",
            "Epoch 1528/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7503 - acc: 0.5417 - val_loss: 0.8043 - val_acc: 0.5444\n",
            "Epoch 1529/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.8029 - acc: 0.5000 - val_loss: 0.7663 - val_acc: 0.6000\n",
            "Epoch 1530/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7919 - acc: 0.4750 - val_loss: 0.7663 - val_acc: 0.5556\n",
            "Epoch 1531/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7418 - acc: 0.5750 - val_loss: 0.7664 - val_acc: 0.6000\n",
            "Epoch 1532/2048\n",
            "120/120 [==============================] - 0s 350us/step - loss: 0.7752 - acc: 0.4917 - val_loss: 0.7663 - val_acc: 0.5556\n",
            "Epoch 1533/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.8170 - acc: 0.4833 - val_loss: 0.7673 - val_acc: 0.5556\n",
            "Epoch 1534/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7502 - acc: 0.4750 - val_loss: 0.7729 - val_acc: 0.5778\n",
            "Epoch 1535/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7502 - acc: 0.4583 - val_loss: 0.7844 - val_acc: 0.5444\n",
            "Epoch 1536/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.7501 - acc: 0.5667 - val_loss: 0.7941 - val_acc: 0.5444\n",
            "Epoch 1537/2048\n",
            "120/120 [==============================] - 0s 355us/step - loss: 0.7418 - acc: 0.5667 - val_loss: 0.8069 - val_acc: 0.5556\n",
            "Epoch 1538/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7517 - acc: 0.5167 - val_loss: 0.7908 - val_acc: 0.5778\n",
            "Epoch 1539/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7503 - acc: 0.5333 - val_loss: 0.8039 - val_acc: 0.5444\n",
            "Epoch 1540/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.7335 - acc: 0.5833 - val_loss: 0.8046 - val_acc: 0.5444\n",
            "Epoch 1541/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7864 - acc: 0.4750 - val_loss: 0.7531 - val_acc: 0.5889\n",
            "Epoch 1542/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7532 - acc: 0.5250 - val_loss: 0.7395 - val_acc: 0.6222\n",
            "Epoch 1543/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.8252 - acc: 0.4667 - val_loss: 0.7413 - val_acc: 0.5556\n",
            "Epoch 1544/2048\n",
            "120/120 [==============================] - 0s 374us/step - loss: 0.7510 - acc: 0.5833 - val_loss: 0.7606 - val_acc: 0.5556\n",
            "Epoch 1545/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.8002 - acc: 0.4917 - val_loss: 0.7605 - val_acc: 0.5889\n",
            "Epoch 1546/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.7752 - acc: 0.5083 - val_loss: 0.7617 - val_acc: 0.3889\n",
            "Epoch 1547/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7585 - acc: 0.5583 - val_loss: 0.7618 - val_acc: 0.5556\n",
            "Epoch 1548/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.7752 - acc: 0.5500 - val_loss: 0.7618 - val_acc: 0.5889\n",
            "Epoch 1549/2048\n",
            "120/120 [==============================] - 0s 295us/step - loss: 0.7504 - acc: 0.4917 - val_loss: 0.7835 - val_acc: 0.3889\n",
            "Epoch 1550/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7671 - acc: 0.5167 - val_loss: 0.8037 - val_acc: 0.5444\n",
            "Epoch 1551/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7777 - acc: 0.5000 - val_loss: 0.7827 - val_acc: 0.5778\n",
            "Epoch 1552/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 0.7168 - acc: 0.5917 - val_loss: 0.7883 - val_acc: 0.5556\n",
            "Epoch 1553/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7337 - acc: 0.5500 - val_loss: 0.8035 - val_acc: 0.5444\n",
            "Epoch 1554/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7374 - acc: 0.6250 - val_loss: 0.7797 - val_acc: 0.5778\n",
            "Epoch 1555/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7836 - acc: 0.5000 - val_loss: 0.7867 - val_acc: 0.5778\n",
            "Epoch 1556/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7712 - acc: 0.5333 - val_loss: 0.8028 - val_acc: 0.5444\n",
            "Epoch 1557/2048\n",
            "120/120 [==============================] - 0s 346us/step - loss: 0.8006 - acc: 0.5083 - val_loss: 0.7884 - val_acc: 0.5778\n",
            "Epoch 1558/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7668 - acc: 0.5917 - val_loss: 0.7905 - val_acc: 0.5444\n",
            "Epoch 1559/2048\n",
            "120/120 [==============================] - 0s 391us/step - loss: 0.8002 - acc: 0.5000 - val_loss: 0.7905 - val_acc: 0.5778\n",
            "Epoch 1560/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7584 - acc: 0.5250 - val_loss: 0.7908 - val_acc: 0.5778\n",
            "Epoch 1561/2048\n",
            "120/120 [==============================] - 0s 287us/step - loss: 0.7587 - acc: 0.5167 - val_loss: 0.7631 - val_acc: 0.5556\n",
            "Epoch 1562/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7340 - acc: 0.5500 - val_loss: 0.7811 - val_acc: 0.5444\n",
            "Epoch 1563/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7668 - acc: 0.5333 - val_loss: 0.7815 - val_acc: 0.5444\n",
            "Epoch 1564/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.7668 - acc: 0.5500 - val_loss: 0.7818 - val_acc: 0.3889\n",
            "Epoch 1565/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7751 - acc: 0.5833 - val_loss: 0.7840 - val_acc: 0.5444\n",
            "Epoch 1566/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.7836 - acc: 0.4917 - val_loss: 0.7848 - val_acc: 0.5444\n",
            "Epoch 1567/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 0.7592 - acc: 0.5500 - val_loss: 0.8053 - val_acc: 0.5778\n",
            "Epoch 1568/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7436 - acc: 0.5500 - val_loss: 0.7979 - val_acc: 0.5778\n",
            "Epoch 1569/2048\n",
            "120/120 [==============================] - 0s 280us/step - loss: 0.7336 - acc: 0.5083 - val_loss: 0.7984 - val_acc: 0.5778\n",
            "Epoch 1570/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.7835 - acc: 0.4667 - val_loss: 0.7984 - val_acc: 0.5444\n",
            "Epoch 1571/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7751 - acc: 0.5833 - val_loss: 0.7984 - val_acc: 0.5778\n",
            "Epoch 1572/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.8168 - acc: 0.5000 - val_loss: 0.7984 - val_acc: 0.5778\n",
            "Epoch 1573/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7418 - acc: 0.6083 - val_loss: 0.7992 - val_acc: 0.5444\n",
            "Epoch 1574/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.8002 - acc: 0.5000 - val_loss: 0.7999 - val_acc: 0.5778\n",
            "Epoch 1575/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7863 - acc: 0.4917 - val_loss: 0.7702 - val_acc: 0.6000\n",
            "Epoch 1576/2048\n",
            "120/120 [==============================] - 0s 340us/step - loss: 0.7923 - acc: 0.4917 - val_loss: 0.7951 - val_acc: 0.5778\n",
            "Epoch 1577/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7919 - acc: 0.5333 - val_loss: 0.7950 - val_acc: 0.5778\n",
            "Epoch 1578/2048\n",
            "120/120 [==============================] - 0s 286us/step - loss: 0.7592 - acc: 0.5583 - val_loss: 0.7856 - val_acc: 0.5444\n",
            "Epoch 1579/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7336 - acc: 0.5417 - val_loss: 0.7944 - val_acc: 0.5778\n",
            "Epoch 1580/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7590 - acc: 0.5000 - val_loss: 0.8049 - val_acc: 0.5778\n",
            "Epoch 1581/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7770 - acc: 0.5833 - val_loss: 0.8002 - val_acc: 0.5778\n",
            "Epoch 1582/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.7585 - acc: 0.5083 - val_loss: 0.8002 - val_acc: 0.5444\n",
            "Epoch 1583/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.8085 - acc: 0.5500 - val_loss: 0.8004 - val_acc: 0.5444\n",
            "Epoch 1584/2048\n",
            "120/120 [==============================] - 0s 367us/step - loss: 0.7336 - acc: 0.4750 - val_loss: 0.8012 - val_acc: 0.5444\n",
            "Epoch 1585/2048\n",
            "120/120 [==============================] - 0s 361us/step - loss: 0.7835 - acc: 0.4917 - val_loss: 0.8030 - val_acc: 0.5778\n",
            "Epoch 1586/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.7752 - acc: 0.5583 - val_loss: 0.8033 - val_acc: 0.5778\n",
            "Epoch 1587/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7753 - acc: 0.5750 - val_loss: 0.8058 - val_acc: 0.5444\n",
            "Epoch 1588/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7669 - acc: 0.5167 - val_loss: 0.8060 - val_acc: 0.5778\n",
            "Epoch 1589/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7918 - acc: 0.5167 - val_loss: 0.8086 - val_acc: 0.5778\n",
            "Epoch 1590/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7593 - acc: 0.5250 - val_loss: 0.7950 - val_acc: 0.5444\n",
            "Epoch 1591/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7336 - acc: 0.5167 - val_loss: 0.8018 - val_acc: 0.5444\n",
            "Epoch 1592/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.7668 - acc: 0.5500 - val_loss: 0.8018 - val_acc: 0.5778\n",
            "Epoch 1593/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.7717 - acc: 0.5333 - val_loss: 0.8012 - val_acc: 0.5444\n",
            "Epoch 1594/2048\n",
            "120/120 [==============================] - 0s 346us/step - loss: 0.7752 - acc: 0.5500 - val_loss: 0.8040 - val_acc: 0.5778\n",
            "Epoch 1595/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7835 - acc: 0.5083 - val_loss: 0.8058 - val_acc: 0.5444\n",
            "Epoch 1596/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.8010 - acc: 0.4667 - val_loss: 0.7936 - val_acc: 0.5778\n",
            "Epoch 1597/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7585 - acc: 0.5417 - val_loss: 0.7942 - val_acc: 0.5444\n",
            "Epoch 1598/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.7586 - acc: 0.5417 - val_loss: 0.8057 - val_acc: 0.5444\n",
            "Epoch 1599/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7835 - acc: 0.5500 - val_loss: 0.8058 - val_acc: 0.5444\n",
            "Epoch 1600/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7844 - acc: 0.5500 - val_loss: 0.8096 - val_acc: 0.5889\n",
            "Epoch 1601/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7870 - acc: 0.4917 - val_loss: 0.8022 - val_acc: 0.5444\n",
            "Epoch 1602/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7835 - acc: 0.5167 - val_loss: 0.8023 - val_acc: 0.5444\n",
            "Epoch 1603/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7844 - acc: 0.5250 - val_loss: 0.8097 - val_acc: 0.5444\n",
            "Epoch 1604/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7265 - acc: 0.5750 - val_loss: 0.7822 - val_acc: 0.5444\n",
            "Epoch 1605/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.8168 - acc: 0.5167 - val_loss: 0.7824 - val_acc: 0.5444\n",
            "Epoch 1606/2048\n",
            "120/120 [==============================] - 0s 381us/step - loss: 0.7419 - acc: 0.5417 - val_loss: 0.7824 - val_acc: 0.5778\n",
            "Epoch 1607/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7752 - acc: 0.5000 - val_loss: 0.7840 - val_acc: 0.5444\n",
            "Epoch 1608/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.7669 - acc: 0.4833 - val_loss: 0.7843 - val_acc: 0.5444\n",
            "Epoch 1609/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.7844 - acc: 0.5083 - val_loss: 0.7852 - val_acc: 0.5444\n",
            "Epoch 1610/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.7418 - acc: 0.5417 - val_loss: 0.7867 - val_acc: 0.5778\n",
            "Epoch 1611/2048\n",
            "120/120 [==============================] - 0s 357us/step - loss: 0.7470 - acc: 0.5500 - val_loss: 0.8069 - val_acc: 0.5444\n",
            "Epoch 1612/2048\n",
            "120/120 [==============================] - 0s 340us/step - loss: 0.8002 - acc: 0.5500 - val_loss: 0.8069 - val_acc: 0.5444\n",
            "Epoch 1613/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 0.7418 - acc: 0.5167 - val_loss: 0.8069 - val_acc: 0.5778\n",
            "Epoch 1614/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7752 - acc: 0.5417 - val_loss: 0.8069 - val_acc: 0.5444\n",
            "Epoch 1615/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.7251 - acc: 0.5583 - val_loss: 0.8069 - val_acc: 0.5444\n",
            "Epoch 1616/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7669 - acc: 0.4667 - val_loss: 0.8072 - val_acc: 0.5444\n",
            "Epoch 1617/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.7751 - acc: 0.5583 - val_loss: 0.8078 - val_acc: 0.5444\n",
            "Epoch 1618/2048\n",
            "120/120 [==============================] - 0s 346us/step - loss: 0.7836 - acc: 0.5000 - val_loss: 0.8075 - val_acc: 0.5444\n",
            "Epoch 1619/2048\n",
            "120/120 [==============================] - 0s 288us/step - loss: 0.7714 - acc: 0.5667 - val_loss: 0.7838 - val_acc: 0.5444\n",
            "Epoch 1620/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.7419 - acc: 0.5000 - val_loss: 0.7917 - val_acc: 0.5778\n",
            "Epoch 1621/2048\n",
            "120/120 [==============================] - 0s 340us/step - loss: 0.7752 - acc: 0.5500 - val_loss: 0.7936 - val_acc: 0.5444\n",
            "Epoch 1622/2048\n",
            "120/120 [==============================] - 0s 345us/step - loss: 0.7672 - acc: 0.5000 - val_loss: 0.7853 - val_acc: 0.5444\n",
            "Epoch 1623/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.8002 - acc: 0.5167 - val_loss: 0.7863 - val_acc: 0.5778\n",
            "Epoch 1624/2048\n",
            "120/120 [==============================] - 0s 345us/step - loss: 0.8002 - acc: 0.5083 - val_loss: 0.7867 - val_acc: 0.5444\n",
            "Epoch 1625/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7835 - acc: 0.5250 - val_loss: 0.7867 - val_acc: 0.5444\n",
            "Epoch 1626/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.7595 - acc: 0.5750 - val_loss: 0.8041 - val_acc: 0.5889\n",
            "Epoch 1627/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7501 - acc: 0.5583 - val_loss: 0.8042 - val_acc: 0.5556\n",
            "Epoch 1628/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7920 - acc: 0.5417 - val_loss: 0.8082 - val_acc: 0.5778\n",
            "Epoch 1629/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.7670 - acc: 0.5833 - val_loss: 0.8045 - val_acc: 0.5444\n",
            "Epoch 1630/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7712 - acc: 0.5250 - val_loss: 0.7873 - val_acc: 0.5444\n",
            "Epoch 1631/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7518 - acc: 0.5667 - val_loss: 0.7826 - val_acc: 0.5444\n",
            "Epoch 1632/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7753 - acc: 0.4750 - val_loss: 0.7848 - val_acc: 0.5444\n",
            "Epoch 1633/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7669 - acc: 0.5583 - val_loss: 0.7960 - val_acc: 0.5778\n",
            "Epoch 1634/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 0.8116 - acc: 0.4167 - val_loss: 0.7848 - val_acc: 0.5444\n",
            "Epoch 1635/2048\n",
            "120/120 [==============================] - 0s 399us/step - loss: 0.8280 - acc: 0.5417 - val_loss: 0.8011 - val_acc: 0.5778\n",
            "Epoch 1636/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.8095 - acc: 0.4917 - val_loss: 0.8061 - val_acc: 0.5444\n",
            "Epoch 1637/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7668 - acc: 0.5167 - val_loss: 0.8062 - val_acc: 0.5444\n",
            "Epoch 1638/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 0.7755 - acc: 0.5000 - val_loss: 0.7896 - val_acc: 0.5778\n",
            "Epoch 1639/2048\n",
            "120/120 [==============================] - 0s 286us/step - loss: 0.7585 - acc: 0.5000 - val_loss: 0.7898 - val_acc: 0.3889\n",
            "Epoch 1640/2048\n",
            "120/120 [==============================] - 0s 292us/step - loss: 0.7592 - acc: 0.5667 - val_loss: 0.7913 - val_acc: 0.5778\n",
            "Epoch 1641/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7668 - acc: 0.5583 - val_loss: 0.7913 - val_acc: 0.5444\n",
            "Epoch 1642/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7835 - acc: 0.5167 - val_loss: 0.7914 - val_acc: 0.5444\n",
            "Epoch 1643/2048\n",
            "120/120 [==============================] - 0s 345us/step - loss: 0.7668 - acc: 0.5667 - val_loss: 0.7915 - val_acc: 0.5444\n",
            "Epoch 1644/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7918 - acc: 0.5333 - val_loss: 0.7820 - val_acc: 0.5444\n",
            "Epoch 1645/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7670 - acc: 0.5083 - val_loss: 0.7982 - val_acc: 0.5778\n",
            "Epoch 1646/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7669 - acc: 0.5083 - val_loss: 0.8045 - val_acc: 0.5778\n",
            "Epoch 1647/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7430 - acc: 0.5167 - val_loss: 0.7824 - val_acc: 0.5444\n",
            "Epoch 1648/2048\n",
            "120/120 [==============================] - 0s 369us/step - loss: 0.7753 - acc: 0.5083 - val_loss: 0.7929 - val_acc: 0.3889\n",
            "Epoch 1649/2048\n",
            "120/120 [==============================] - 0s 288us/step - loss: 0.7419 - acc: 0.5250 - val_loss: 0.7943 - val_acc: 0.5444\n",
            "Epoch 1650/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.8002 - acc: 0.5167 - val_loss: 0.7950 - val_acc: 0.5778\n",
            "Epoch 1651/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7502 - acc: 0.5583 - val_loss: 0.7964 - val_acc: 0.5444\n",
            "Epoch 1652/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.8169 - acc: 0.4417 - val_loss: 0.8034 - val_acc: 0.5444\n",
            "Epoch 1653/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7835 - acc: 0.5250 - val_loss: 0.8036 - val_acc: 0.5778\n",
            "Epoch 1654/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.8002 - acc: 0.4750 - val_loss: 0.8086 - val_acc: 0.5778\n",
            "Epoch 1655/2048\n",
            "120/120 [==============================] - 0s 354us/step - loss: 0.7686 - acc: 0.4833 - val_loss: 0.8047 - val_acc: 0.5778\n",
            "Epoch 1656/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7685 - acc: 0.5250 - val_loss: 0.7781 - val_acc: 0.5556\n",
            "Epoch 1657/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.7251 - acc: 0.6167 - val_loss: 0.7788 - val_acc: 0.5556\n",
            "Epoch 1658/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7252 - acc: 0.6167 - val_loss: 0.7828 - val_acc: 0.5778\n",
            "Epoch 1659/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7874 - acc: 0.5000 - val_loss: 0.8027 - val_acc: 0.5778\n",
            "Epoch 1660/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7921 - acc: 0.5167 - val_loss: 0.8052 - val_acc: 0.5444\n",
            "Epoch 1661/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7675 - acc: 0.5000 - val_loss: 0.7980 - val_acc: 0.5778\n",
            "Epoch 1662/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 0.7919 - acc: 0.4833 - val_loss: 0.7990 - val_acc: 0.5444\n",
            "Epoch 1663/2048\n",
            "120/120 [==============================] - 0s 279us/step - loss: 0.7920 - acc: 0.4833 - val_loss: 0.8002 - val_acc: 0.5444\n",
            "Epoch 1664/2048\n",
            "120/120 [==============================] - 0s 296us/step - loss: 0.7918 - acc: 0.4500 - val_loss: 0.8007 - val_acc: 0.5444\n",
            "Epoch 1665/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7335 - acc: 0.5583 - val_loss: 0.8007 - val_acc: 0.5444\n",
            "Epoch 1666/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7668 - acc: 0.5000 - val_loss: 0.8008 - val_acc: 0.5444\n",
            "Epoch 1667/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7725 - acc: 0.5750 - val_loss: 0.8063 - val_acc: 0.5889\n",
            "Epoch 1668/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7877 - acc: 0.4583 - val_loss: 0.8061 - val_acc: 0.3889\n",
            "Epoch 1669/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7418 - acc: 0.5000 - val_loss: 0.8062 - val_acc: 0.5444\n",
            "Epoch 1670/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.8087 - acc: 0.4583 - val_loss: 0.8076 - val_acc: 0.5889\n",
            "Epoch 1671/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7836 - acc: 0.5083 - val_loss: 0.8016 - val_acc: 0.5778\n",
            "Epoch 1672/2048\n",
            "120/120 [==============================] - 0s 292us/step - loss: 0.7668 - acc: 0.5750 - val_loss: 0.8062 - val_acc: 0.5444\n",
            "Epoch 1673/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.8003 - acc: 0.4917 - val_loss: 0.8085 - val_acc: 0.5444\n",
            "Epoch 1674/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7659 - acc: 0.5167 - val_loss: 0.7828 - val_acc: 0.3889\n",
            "Epoch 1675/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.7757 - acc: 0.5417 - val_loss: 0.7986 - val_acc: 0.5778\n",
            "Epoch 1676/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7253 - acc: 0.5750 - val_loss: 0.8027 - val_acc: 0.5444\n",
            "Epoch 1677/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7919 - acc: 0.4917 - val_loss: 0.8026 - val_acc: 0.5778\n",
            "Epoch 1678/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.8188 - acc: 0.4667 - val_loss: 0.7598 - val_acc: 0.6000\n",
            "Epoch 1679/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7817 - acc: 0.5667 - val_loss: 0.7882 - val_acc: 0.5889\n",
            "Epoch 1680/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7669 - acc: 0.5250 - val_loss: 0.7899 - val_acc: 0.5889\n",
            "Epoch 1681/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.7503 - acc: 0.5167 - val_loss: 0.7923 - val_acc: 0.5778\n",
            "Epoch 1682/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7836 - acc: 0.4917 - val_loss: 0.7947 - val_acc: 0.5444\n",
            "Epoch 1683/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7751 - acc: 0.5333 - val_loss: 0.7948 - val_acc: 0.5778\n",
            "Epoch 1684/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7418 - acc: 0.5833 - val_loss: 0.7948 - val_acc: 0.5444\n",
            "Epoch 1685/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 0.7502 - acc: 0.5583 - val_loss: 0.7949 - val_acc: 0.5444\n",
            "Epoch 1686/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7598 - acc: 0.5417 - val_loss: 0.8051 - val_acc: 0.5444\n",
            "Epoch 1687/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7502 - acc: 0.5167 - val_loss: 0.8063 - val_acc: 0.5444\n",
            "Epoch 1688/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.7752 - acc: 0.5167 - val_loss: 0.8063 - val_acc: 0.5444\n",
            "Epoch 1689/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7587 - acc: 0.5250 - val_loss: 0.8039 - val_acc: 0.5444\n",
            "Epoch 1690/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7836 - acc: 0.4750 - val_loss: 0.8077 - val_acc: 0.5889\n",
            "Epoch 1691/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7543 - acc: 0.4833 - val_loss: 0.8021 - val_acc: 0.5444\n",
            "Epoch 1692/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 0.7668 - acc: 0.5083 - val_loss: 0.8023 - val_acc: 0.5778\n",
            "Epoch 1693/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7755 - acc: 0.5750 - val_loss: 0.8057 - val_acc: 0.5444\n",
            "Epoch 1694/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7870 - acc: 0.5500 - val_loss: 0.7921 - val_acc: 0.5444\n",
            "Epoch 1695/2048\n",
            "120/120 [==============================] - 0s 317us/step - loss: 0.8018 - acc: 0.5083 - val_loss: 0.7671 - val_acc: 0.6000\n",
            "Epoch 1696/2048\n",
            "120/120 [==============================] - 0s 338us/step - loss: 0.7502 - acc: 0.5333 - val_loss: 0.7671 - val_acc: 0.6000\n",
            "Epoch 1697/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7920 - acc: 0.4750 - val_loss: 0.7702 - val_acc: 0.5889\n",
            "Epoch 1698/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7502 - acc: 0.5167 - val_loss: 0.7701 - val_acc: 0.5889\n",
            "Epoch 1699/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.7919 - acc: 0.5250 - val_loss: 0.7856 - val_acc: 0.5778\n",
            "Epoch 1700/2048\n",
            "120/120 [==============================] - 0s 359us/step - loss: 0.7835 - acc: 0.5417 - val_loss: 0.7872 - val_acc: 0.5778\n",
            "Epoch 1701/2048\n",
            "120/120 [==============================] - 0s 355us/step - loss: 0.7585 - acc: 0.5083 - val_loss: 0.7875 - val_acc: 0.5778\n",
            "Epoch 1702/2048\n",
            "120/120 [==============================] - 0s 371us/step - loss: 0.7841 - acc: 0.5500 - val_loss: 0.7735 - val_acc: 0.5778\n",
            "Epoch 1703/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7919 - acc: 0.5000 - val_loss: 0.7756 - val_acc: 0.5778\n",
            "Epoch 1704/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7669 - acc: 0.5167 - val_loss: 0.7810 - val_acc: 0.5778\n",
            "Epoch 1705/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7672 - acc: 0.5000 - val_loss: 0.7691 - val_acc: 0.5556\n",
            "Epoch 1706/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7346 - acc: 0.5250 - val_loss: 0.8072 - val_acc: 0.5778\n",
            "Epoch 1707/2048\n",
            "120/120 [==============================] - 0s 356us/step - loss: 0.7501 - acc: 0.5250 - val_loss: 0.8072 - val_acc: 0.5778\n",
            "Epoch 1708/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.7668 - acc: 0.5583 - val_loss: 0.8078 - val_acc: 0.5778\n",
            "Epoch 1709/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.7760 - acc: 0.5083 - val_loss: 0.7779 - val_acc: 0.5778\n",
            "Epoch 1710/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.8169 - acc: 0.4750 - val_loss: 0.7797 - val_acc: 0.5444\n",
            "Epoch 1711/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.8025 - acc: 0.5083 - val_loss: 0.7986 - val_acc: 0.5778\n",
            "Epoch 1712/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7765 - acc: 0.5583 - val_loss: 0.8081 - val_acc: 0.5778\n",
            "Epoch 1713/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7587 - acc: 0.5167 - val_loss: 0.7908 - val_acc: 0.5444\n",
            "Epoch 1714/2048\n",
            "120/120 [==============================] - 0s 348us/step - loss: 0.7512 - acc: 0.6167 - val_loss: 0.7629 - val_acc: 0.6000\n",
            "Epoch 1715/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.8003 - acc: 0.5000 - val_loss: 0.7670 - val_acc: 0.5889\n",
            "Epoch 1716/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7753 - acc: 0.4750 - val_loss: 0.7683 - val_acc: 0.5444\n",
            "Epoch 1717/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7672 - acc: 0.5083 - val_loss: 0.7803 - val_acc: 0.5444\n",
            "Epoch 1718/2048\n",
            "120/120 [==============================] - 0s 356us/step - loss: 0.7829 - acc: 0.4583 - val_loss: 0.8004 - val_acc: 0.5444\n",
            "Epoch 1719/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.8169 - acc: 0.4583 - val_loss: 0.8004 - val_acc: 0.5778\n",
            "Epoch 1720/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7503 - acc: 0.4667 - val_loss: 0.8039 - val_acc: 0.5778\n",
            "Epoch 1721/2048\n",
            "120/120 [==============================] - 0s 359us/step - loss: 0.7761 - acc: 0.5583 - val_loss: 0.8088 - val_acc: 0.5444\n",
            "Epoch 1722/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7710 - acc: 0.4583 - val_loss: 0.7932 - val_acc: 0.5444\n",
            "Epoch 1723/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.7835 - acc: 0.4833 - val_loss: 0.7933 - val_acc: 0.5778\n",
            "Epoch 1724/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.7502 - acc: 0.5250 - val_loss: 0.7967 - val_acc: 0.5778\n",
            "Epoch 1725/2048\n",
            "120/120 [==============================] - 0s 290us/step - loss: 0.7590 - acc: 0.5417 - val_loss: 0.8043 - val_acc: 0.5778\n",
            "Epoch 1726/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7585 - acc: 0.5083 - val_loss: 0.8044 - val_acc: 0.5444\n",
            "Epoch 1727/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.8002 - acc: 0.4583 - val_loss: 0.8084 - val_acc: 0.5444\n",
            "Epoch 1728/2048\n",
            "120/120 [==============================] - 0s 286us/step - loss: 0.7917 - acc: 0.5917 - val_loss: 0.8084 - val_acc: 0.5778\n",
            "Epoch 1729/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7836 - acc: 0.5417 - val_loss: 0.8084 - val_acc: 0.5778\n",
            "Epoch 1730/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7919 - acc: 0.5333 - val_loss: 0.8092 - val_acc: 0.5778\n",
            "Epoch 1731/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.8002 - acc: 0.4917 - val_loss: 0.8093 - val_acc: 0.5444\n",
            "Epoch 1732/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7419 - acc: 0.5333 - val_loss: 0.8092 - val_acc: 0.5444\n",
            "Epoch 1733/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7497 - acc: 0.5917 - val_loss: 0.8176 - val_acc: 0.5889\n",
            "Epoch 1734/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7914 - acc: 0.4917 - val_loss: 0.8043 - val_acc: 0.5444\n",
            "Epoch 1735/2048\n",
            "120/120 [==============================] - 0s 296us/step - loss: 0.7574 - acc: 0.5917 - val_loss: 0.7628 - val_acc: 0.5556\n",
            "Epoch 1736/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7835 - acc: 0.5333 - val_loss: 0.7659 - val_acc: 0.5778\n",
            "Epoch 1737/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7752 - acc: 0.4500 - val_loss: 0.7668 - val_acc: 0.5556\n",
            "Epoch 1738/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7512 - acc: 0.5000 - val_loss: 0.7945 - val_acc: 0.5444\n",
            "Epoch 1739/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.7836 - acc: 0.4917 - val_loss: 0.7945 - val_acc: 0.5778\n",
            "Epoch 1740/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 0.7839 - acc: 0.4417 - val_loss: 0.7787 - val_acc: 0.5556\n",
            "Epoch 1741/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.7835 - acc: 0.5000 - val_loss: 0.7787 - val_acc: 0.5778\n",
            "Epoch 1742/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7336 - acc: 0.4917 - val_loss: 0.7787 - val_acc: 0.5778\n",
            "Epoch 1743/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7586 - acc: 0.6000 - val_loss: 0.7897 - val_acc: 0.5556\n",
            "Epoch 1744/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7419 - acc: 0.5250 - val_loss: 0.7903 - val_acc: 0.5778\n",
            "Epoch 1745/2048\n",
            "120/120 [==============================] - 0s 370us/step - loss: 0.7704 - acc: 0.6000 - val_loss: 0.7823 - val_acc: 0.5778\n",
            "Epoch 1746/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7923 - acc: 0.5083 - val_loss: 0.7936 - val_acc: 0.5444\n",
            "Epoch 1747/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.7415 - acc: 0.5667 - val_loss: 0.8026 - val_acc: 0.5778\n",
            "Epoch 1748/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7830 - acc: 0.5417 - val_loss: 0.7905 - val_acc: 0.5444\n",
            "Epoch 1749/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7913 - acc: 0.5250 - val_loss: 0.7751 - val_acc: 0.5889\n",
            "Epoch 1750/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7836 - acc: 0.4583 - val_loss: 0.7758 - val_acc: 0.5556\n",
            "Epoch 1751/2048\n",
            "120/120 [==============================] - 0s 352us/step - loss: 0.7752 - acc: 0.5250 - val_loss: 0.7761 - val_acc: 0.5556\n",
            "Epoch 1752/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7418 - acc: 0.5750 - val_loss: 0.7773 - val_acc: 0.5556\n",
            "Epoch 1753/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7836 - acc: 0.4750 - val_loss: 0.7772 - val_acc: 0.5556\n",
            "Epoch 1754/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7752 - acc: 0.5500 - val_loss: 0.7806 - val_acc: 0.5889\n",
            "Epoch 1755/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.7583 - acc: 0.5750 - val_loss: 0.7943 - val_acc: 0.5778\n",
            "Epoch 1756/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.7758 - acc: 0.5417 - val_loss: 0.7868 - val_acc: 0.3889\n",
            "Epoch 1757/2048\n",
            "120/120 [==============================] - 0s 289us/step - loss: 0.7585 - acc: 0.5417 - val_loss: 0.7886 - val_acc: 0.5778\n",
            "Epoch 1758/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 0.7586 - acc: 0.5500 - val_loss: 0.7990 - val_acc: 0.5556\n",
            "Epoch 1759/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.7418 - acc: 0.5583 - val_loss: 0.7990 - val_acc: 0.5556\n",
            "Epoch 1760/2048\n",
            "120/120 [==============================] - 0s 364us/step - loss: 0.7418 - acc: 0.5917 - val_loss: 0.7990 - val_acc: 0.5889\n",
            "Epoch 1761/2048\n",
            "120/120 [==============================] - 0s 388us/step - loss: 0.7756 - acc: 0.5500 - val_loss: 0.7743 - val_acc: 0.5889\n",
            "Epoch 1762/2048\n",
            "120/120 [==============================] - 0s 419us/step - loss: 0.7585 - acc: 0.5333 - val_loss: 0.7817 - val_acc: 0.5778\n",
            "Epoch 1763/2048\n",
            "120/120 [==============================] - 0s 357us/step - loss: 0.8170 - acc: 0.4583 - val_loss: 0.7821 - val_acc: 0.5778\n",
            "Epoch 1764/2048\n",
            "120/120 [==============================] - 0s 337us/step - loss: 0.7335 - acc: 0.5667 - val_loss: 0.7822 - val_acc: 0.5778\n",
            "Epoch 1765/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7674 - acc: 0.5583 - val_loss: 0.7991 - val_acc: 0.5556\n",
            "Epoch 1766/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7706 - acc: 0.5500 - val_loss: 0.7785 - val_acc: 0.5778\n",
            "Epoch 1767/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.7669 - acc: 0.4917 - val_loss: 0.7840 - val_acc: 0.3889\n",
            "Epoch 1768/2048\n",
            "120/120 [==============================] - 0s 349us/step - loss: 0.7335 - acc: 0.5667 - val_loss: 0.7862 - val_acc: 0.5778\n",
            "Epoch 1769/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7588 - acc: 0.5167 - val_loss: 0.8010 - val_acc: 0.5889\n",
            "Epoch 1770/2048\n",
            "120/120 [==============================] - 0s 359us/step - loss: 0.7755 - acc: 0.4833 - val_loss: 0.7772 - val_acc: 0.5778\n",
            "Epoch 1771/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7851 - acc: 0.4667 - val_loss: 0.7940 - val_acc: 0.5889\n",
            "Epoch 1772/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.7761 - acc: 0.5417 - val_loss: 0.7954 - val_acc: 0.5444\n",
            "Epoch 1773/2048\n",
            "120/120 [==============================] - 0s 350us/step - loss: 0.7251 - acc: 0.6000 - val_loss: 0.7955 - val_acc: 0.5778\n",
            "Epoch 1774/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.7758 - acc: 0.4833 - val_loss: 0.8006 - val_acc: 0.5889\n",
            "Epoch 1775/2048\n",
            "120/120 [==============================] - 0s 358us/step - loss: 0.7656 - acc: 0.5583 - val_loss: 0.7853 - val_acc: 0.5444\n",
            "Epoch 1776/2048\n",
            "120/120 [==============================] - 0s 284us/step - loss: 0.7668 - acc: 0.5333 - val_loss: 0.7860 - val_acc: 0.5778\n",
            "Epoch 1777/2048\n",
            "120/120 [==============================] - 0s 285us/step - loss: 0.7418 - acc: 0.5833 - val_loss: 0.7971 - val_acc: 0.5778\n",
            "Epoch 1778/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7503 - acc: 0.5250 - val_loss: 0.7992 - val_acc: 0.5444\n",
            "Epoch 1779/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7682 - acc: 0.5250 - val_loss: 0.8088 - val_acc: 0.5889\n",
            "Epoch 1780/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7418 - acc: 0.6333 - val_loss: 0.7988 - val_acc: 0.5444\n",
            "Epoch 1781/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7501 - acc: 0.5750 - val_loss: 0.8011 - val_acc: 0.5444\n",
            "Epoch 1782/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.7919 - acc: 0.5167 - val_loss: 0.8014 - val_acc: 0.5778\n",
            "Epoch 1783/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7504 - acc: 0.5917 - val_loss: 0.8057 - val_acc: 0.5444\n",
            "Epoch 1784/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.7659 - acc: 0.5583 - val_loss: 0.7983 - val_acc: 0.5444\n",
            "Epoch 1785/2048\n",
            "120/120 [==============================] - 0s 362us/step - loss: 0.7587 - acc: 0.5500 - val_loss: 0.8027 - val_acc: 0.5444\n",
            "Epoch 1786/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7503 - acc: 0.5250 - val_loss: 0.8062 - val_acc: 0.5444\n",
            "Epoch 1787/2048\n",
            "120/120 [==============================] - 0s 295us/step - loss: 0.7668 - acc: 0.5417 - val_loss: 0.8063 - val_acc: 0.5444\n",
            "Epoch 1788/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.8169 - acc: 0.4333 - val_loss: 0.8064 - val_acc: 0.3889\n",
            "Epoch 1789/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7548 - acc: 0.5333 - val_loss: 0.7652 - val_acc: 0.6000\n",
            "Epoch 1790/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7255 - acc: 0.5250 - val_loss: 0.7735 - val_acc: 0.5778\n",
            "Epoch 1791/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7307 - acc: 0.6167 - val_loss: 0.8069 - val_acc: 0.5444\n",
            "Epoch 1792/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7769 - acc: 0.5167 - val_loss: 0.7705 - val_acc: 0.5444\n",
            "Epoch 1793/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7503 - acc: 0.5417 - val_loss: 0.7710 - val_acc: 0.5889\n",
            "Epoch 1794/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.8086 - acc: 0.4583 - val_loss: 0.7735 - val_acc: 0.5444\n",
            "Epoch 1795/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7751 - acc: 0.5750 - val_loss: 0.7734 - val_acc: 0.5444\n",
            "Epoch 1796/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.7589 - acc: 0.5500 - val_loss: 0.7920 - val_acc: 0.5778\n",
            "Epoch 1797/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.7919 - acc: 0.5333 - val_loss: 0.7920 - val_acc: 0.5444\n",
            "Epoch 1798/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7676 - acc: 0.5417 - val_loss: 0.8099 - val_acc: 0.5778\n",
            "Epoch 1799/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.8151 - acc: 0.4750 - val_loss: 0.7860 - val_acc: 0.5778\n",
            "Epoch 1800/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7585 - acc: 0.5417 - val_loss: 0.7884 - val_acc: 0.5444\n",
            "Epoch 1801/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 0.7505 - acc: 0.5583 - val_loss: 0.8002 - val_acc: 0.5778\n",
            "Epoch 1802/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7335 - acc: 0.6083 - val_loss: 0.8010 - val_acc: 0.5444\n",
            "Epoch 1803/2048\n",
            "120/120 [==============================] - 0s 282us/step - loss: 0.7421 - acc: 0.5250 - val_loss: 0.8052 - val_acc: 0.5889\n",
            "Epoch 1804/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7504 - acc: 0.4917 - val_loss: 0.7992 - val_acc: 0.3889\n",
            "Epoch 1805/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.7927 - acc: 0.4667 - val_loss: 0.8072 - val_acc: 0.3889\n",
            "Epoch 1806/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.8002 - acc: 0.5000 - val_loss: 0.8071 - val_acc: 0.5778\n",
            "Epoch 1807/2048\n",
            "120/120 [==============================] - 0s 299us/step - loss: 0.7252 - acc: 0.5167 - val_loss: 0.8073 - val_acc: 0.5444\n",
            "Epoch 1808/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.7418 - acc: 0.5000 - val_loss: 0.8078 - val_acc: 0.5444\n",
            "Epoch 1809/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7835 - acc: 0.5500 - val_loss: 0.8079 - val_acc: 0.5778\n",
            "Epoch 1810/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7584 - acc: 0.5750 - val_loss: 0.8083 - val_acc: 0.5444\n",
            "Epoch 1811/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7585 - acc: 0.5500 - val_loss: 0.8087 - val_acc: 0.5778\n",
            "Epoch 1812/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7587 - acc: 0.5333 - val_loss: 0.8142 - val_acc: 0.5778\n",
            "Epoch 1813/2048\n",
            "120/120 [==============================] - 0s 295us/step - loss: 0.7800 - acc: 0.5750 - val_loss: 0.8086 - val_acc: 0.5778\n",
            "Epoch 1814/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7835 - acc: 0.4667 - val_loss: 0.8088 - val_acc: 0.5778\n",
            "Epoch 1815/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.7586 - acc: 0.4917 - val_loss: 0.8089 - val_acc: 0.5444\n",
            "Epoch 1816/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7637 - acc: 0.5500 - val_loss: 0.7751 - val_acc: 0.5556\n",
            "Epoch 1817/2048\n",
            "120/120 [==============================] - 0s 367us/step - loss: 0.7668 - acc: 0.5500 - val_loss: 0.7756 - val_acc: 0.5444\n",
            "Epoch 1818/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7585 - acc: 0.5667 - val_loss: 0.7837 - val_acc: 0.5444\n",
            "Epoch 1819/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7419 - acc: 0.4667 - val_loss: 0.7857 - val_acc: 0.3889\n",
            "Epoch 1820/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.8156 - acc: 0.4083 - val_loss: 0.7650 - val_acc: 0.5556\n",
            "Epoch 1821/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7919 - acc: 0.4833 - val_loss: 0.7644 - val_acc: 0.5556\n",
            "Epoch 1822/2048\n",
            "120/120 [==============================] - 0s 363us/step - loss: 0.7754 - acc: 0.5083 - val_loss: 0.7670 - val_acc: 0.5556\n",
            "Epoch 1823/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.7752 - acc: 0.4833 - val_loss: 0.7671 - val_acc: 0.5556\n",
            "Epoch 1824/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7505 - acc: 0.5083 - val_loss: 0.7839 - val_acc: 0.5444\n",
            "Epoch 1825/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7835 - acc: 0.5250 - val_loss: 0.7839 - val_acc: 0.5778\n",
            "Epoch 1826/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.8005 - acc: 0.4583 - val_loss: 0.7827 - val_acc: 0.5778\n",
            "Epoch 1827/2048\n",
            "120/120 [==============================] - 0s 339us/step - loss: 0.8085 - acc: 0.5000 - val_loss: 0.7833 - val_acc: 0.5444\n",
            "Epoch 1828/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7835 - acc: 0.5167 - val_loss: 0.7925 - val_acc: 0.5444\n",
            "Epoch 1829/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7439 - acc: 0.5667 - val_loss: 0.8087 - val_acc: 0.5444\n",
            "Epoch 1830/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.8045 - acc: 0.4333 - val_loss: 0.7978 - val_acc: 0.5444\n",
            "Epoch 1831/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 0.7835 - acc: 0.4917 - val_loss: 0.7979 - val_acc: 0.5778\n",
            "Epoch 1832/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7589 - acc: 0.5667 - val_loss: 0.8080 - val_acc: 0.5444\n",
            "Epoch 1833/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7744 - acc: 0.5333 - val_loss: 0.7929 - val_acc: 0.5778\n",
            "Epoch 1834/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7743 - acc: 0.5250 - val_loss: 0.7922 - val_acc: 0.5444\n",
            "Epoch 1835/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.8002 - acc: 0.4750 - val_loss: 0.7923 - val_acc: 0.5444\n",
            "Epoch 1836/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7735 - acc: 0.5083 - val_loss: 0.7778 - val_acc: 0.5889\n",
            "Epoch 1837/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7668 - acc: 0.5333 - val_loss: 0.7781 - val_acc: 0.5889\n",
            "Epoch 1838/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.8002 - acc: 0.5333 - val_loss: 0.7784 - val_acc: 0.5889\n",
            "Epoch 1839/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7669 - acc: 0.5500 - val_loss: 0.7838 - val_acc: 0.5889\n",
            "Epoch 1840/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7836 - acc: 0.4417 - val_loss: 0.7865 - val_acc: 0.3889\n",
            "Epoch 1841/2048\n",
            "120/120 [==============================] - 0s 344us/step - loss: 0.8086 - acc: 0.4833 - val_loss: 0.7694 - val_acc: 0.5444\n",
            "Epoch 1842/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.8170 - acc: 0.4750 - val_loss: 0.7850 - val_acc: 0.5778\n",
            "Epoch 1843/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.7659 - acc: 0.5333 - val_loss: 0.7769 - val_acc: 0.5778\n",
            "Epoch 1844/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7752 - acc: 0.4833 - val_loss: 0.7783 - val_acc: 0.5444\n",
            "Epoch 1845/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7585 - acc: 0.5333 - val_loss: 0.7783 - val_acc: 0.5444\n",
            "Epoch 1846/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7585 - acc: 0.5667 - val_loss: 0.7811 - val_acc: 0.5444\n",
            "Epoch 1847/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7585 - acc: 0.5333 - val_loss: 0.7813 - val_acc: 0.5778\n",
            "Epoch 1848/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7941 - acc: 0.4667 - val_loss: 0.8006 - val_acc: 0.5889\n",
            "Epoch 1849/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7585 - acc: 0.5333 - val_loss: 0.8009 - val_acc: 0.5889\n",
            "Epoch 1850/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.8001 - acc: 0.5083 - val_loss: 0.8012 - val_acc: 0.5556\n",
            "Epoch 1851/2048\n",
            "120/120 [==============================] - 0s 350us/step - loss: 0.7669 - acc: 0.5333 - val_loss: 0.8022 - val_acc: 0.5556\n",
            "Epoch 1852/2048\n",
            "120/120 [==============================] - 0s 357us/step - loss: 0.7758 - acc: 0.5917 - val_loss: 0.7849 - val_acc: 0.5778\n",
            "Epoch 1853/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7335 - acc: 0.5750 - val_loss: 0.7910 - val_acc: 0.5444\n",
            "Epoch 1854/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7836 - acc: 0.4417 - val_loss: 0.8000 - val_acc: 0.5444\n",
            "Epoch 1855/2048\n",
            "120/120 [==============================] - 0s 292us/step - loss: 0.7759 - acc: 0.5250 - val_loss: 0.8093 - val_acc: 0.5778\n",
            "Epoch 1856/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7598 - acc: 0.5750 - val_loss: 0.7996 - val_acc: 0.5444\n",
            "Epoch 1857/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.8003 - acc: 0.4333 - val_loss: 0.7999 - val_acc: 0.5778\n",
            "Epoch 1858/2048\n",
            "120/120 [==============================] - 0s 354us/step - loss: 0.7590 - acc: 0.5583 - val_loss: 0.8077 - val_acc: 0.5444\n",
            "Epoch 1859/2048\n",
            "120/120 [==============================] - 0s 336us/step - loss: 0.7752 - acc: 0.5250 - val_loss: 0.8077 - val_acc: 0.5778\n",
            "Epoch 1860/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.7597 - acc: 0.5583 - val_loss: 0.8016 - val_acc: 0.5778\n",
            "Epoch 1861/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.7919 - acc: 0.4917 - val_loss: 0.8026 - val_acc: 0.5444\n",
            "Epoch 1862/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7918 - acc: 0.5167 - val_loss: 0.8026 - val_acc: 0.5444\n",
            "Epoch 1863/2048\n",
            "120/120 [==============================] - 0s 300us/step - loss: 0.7421 - acc: 0.5667 - val_loss: 0.8098 - val_acc: 0.5778\n",
            "Epoch 1864/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7840 - acc: 0.5167 - val_loss: 0.8038 - val_acc: 0.3889\n",
            "Epoch 1865/2048\n",
            "120/120 [==============================] - 0s 346us/step - loss: 0.7920 - acc: 0.4167 - val_loss: 0.8068 - val_acc: 0.5444\n",
            "Epoch 1866/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7835 - acc: 0.5417 - val_loss: 0.8071 - val_acc: 0.3889\n",
            "Epoch 1867/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.7682 - acc: 0.5417 - val_loss: 0.7865 - val_acc: 0.5778\n",
            "Epoch 1868/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7335 - acc: 0.5583 - val_loss: 0.7872 - val_acc: 0.5778\n",
            "Epoch 1869/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7757 - acc: 0.4667 - val_loss: 0.8014 - val_acc: 0.5778\n",
            "Epoch 1870/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7335 - acc: 0.5917 - val_loss: 0.8039 - val_acc: 0.3889\n",
            "Epoch 1871/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7835 - acc: 0.5167 - val_loss: 0.8039 - val_acc: 0.5444\n",
            "Epoch 1872/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7361 - acc: 0.5583 - val_loss: 0.7735 - val_acc: 0.5444\n",
            "Epoch 1873/2048\n",
            "120/120 [==============================] - 0s 344us/step - loss: 0.7513 - acc: 0.5833 - val_loss: 0.8017 - val_acc: 0.5778\n",
            "Epoch 1874/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7835 - acc: 0.5250 - val_loss: 0.8035 - val_acc: 0.5778\n",
            "Epoch 1875/2048\n",
            "120/120 [==============================] - 0s 312us/step - loss: 0.7501 - acc: 0.5667 - val_loss: 0.8035 - val_acc: 0.5778\n",
            "Epoch 1876/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7919 - acc: 0.4917 - val_loss: 0.8041 - val_acc: 0.5778\n",
            "Epoch 1877/2048\n",
            "120/120 [==============================] - 0s 340us/step - loss: 0.7836 - acc: 0.5000 - val_loss: 0.8044 - val_acc: 0.3889\n",
            "Epoch 1878/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7251 - acc: 0.5583 - val_loss: 0.8042 - val_acc: 0.5778\n",
            "Epoch 1879/2048\n",
            "120/120 [==============================] - 0s 340us/step - loss: 0.7918 - acc: 0.5000 - val_loss: 0.8066 - val_acc: 0.5444\n",
            "Epoch 1880/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7727 - acc: 0.5500 - val_loss: 0.7993 - val_acc: 0.5778\n",
            "Epoch 1881/2048\n",
            "120/120 [==============================] - 0s 281us/step - loss: 0.7418 - acc: 0.5667 - val_loss: 0.7993 - val_acc: 0.5778\n",
            "Epoch 1882/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7502 - acc: 0.5500 - val_loss: 0.7993 - val_acc: 0.5444\n",
            "Epoch 1883/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7418 - acc: 0.5833 - val_loss: 0.7995 - val_acc: 0.5778\n",
            "Epoch 1884/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7418 - acc: 0.5833 - val_loss: 0.8004 - val_acc: 0.5444\n",
            "Epoch 1885/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7671 - acc: 0.5500 - val_loss: 0.7739 - val_acc: 0.5444\n",
            "Epoch 1886/2048\n",
            "120/120 [==============================] - 0s 296us/step - loss: 0.7773 - acc: 0.4500 - val_loss: 0.8012 - val_acc: 0.5444\n",
            "Epoch 1887/2048\n",
            "120/120 [==============================] - 0s 340us/step - loss: 0.7420 - acc: 0.5917 - val_loss: 0.8080 - val_acc: 0.5444\n",
            "Epoch 1888/2048\n",
            "120/120 [==============================] - 0s 352us/step - loss: 0.7835 - acc: 0.5167 - val_loss: 0.8083 - val_acc: 0.5444\n",
            "Epoch 1889/2048\n",
            "120/120 [==============================] - 0s 364us/step - loss: 0.8003 - acc: 0.4667 - val_loss: 0.8077 - val_acc: 0.5556\n",
            "Epoch 1890/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7839 - acc: 0.5333 - val_loss: 0.8015 - val_acc: 0.5778\n",
            "Epoch 1891/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7585 - acc: 0.5500 - val_loss: 0.8025 - val_acc: 0.5778\n",
            "Epoch 1892/2048\n",
            "120/120 [==============================] - 0s 334us/step - loss: 0.7669 - acc: 0.5000 - val_loss: 0.8033 - val_acc: 0.5778\n",
            "Epoch 1893/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.8019 - acc: 0.4417 - val_loss: 0.7664 - val_acc: 0.5889\n",
            "Epoch 1894/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7168 - acc: 0.5583 - val_loss: 0.7666 - val_acc: 0.5444\n",
            "Epoch 1895/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7523 - acc: 0.5167 - val_loss: 0.7749 - val_acc: 0.5444\n",
            "Epoch 1896/2048\n",
            "120/120 [==============================] - 0s 289us/step - loss: 0.7586 - acc: 0.5417 - val_loss: 0.7820 - val_acc: 0.5444\n",
            "Epoch 1897/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.7925 - acc: 0.5000 - val_loss: 0.7774 - val_acc: 0.5778\n",
            "Epoch 1898/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7501 - acc: 0.5500 - val_loss: 0.7794 - val_acc: 0.5444\n",
            "Epoch 1899/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7589 - acc: 0.5250 - val_loss: 0.7976 - val_acc: 0.5444\n",
            "Epoch 1900/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 0.7752 - acc: 0.5333 - val_loss: 0.7977 - val_acc: 0.5444\n",
            "Epoch 1901/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7585 - acc: 0.5250 - val_loss: 0.7994 - val_acc: 0.5444\n",
            "Epoch 1902/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.7588 - acc: 0.5250 - val_loss: 0.8064 - val_acc: 0.5778\n",
            "Epoch 1903/2048\n",
            "120/120 [==============================] - 0s 353us/step - loss: 0.8085 - acc: 0.5333 - val_loss: 0.8070 - val_acc: 0.3889\n",
            "Epoch 1904/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7502 - acc: 0.5417 - val_loss: 0.8070 - val_acc: 0.5444\n",
            "Epoch 1905/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7836 - acc: 0.5500 - val_loss: 0.8128 - val_acc: 0.5444\n",
            "Epoch 1906/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7784 - acc: 0.4917 - val_loss: 0.7811 - val_acc: 0.5778\n",
            "Epoch 1907/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7839 - acc: 0.4750 - val_loss: 0.7675 - val_acc: 0.3889\n",
            "Epoch 1908/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.8002 - acc: 0.5167 - val_loss: 0.7680 - val_acc: 0.3889\n",
            "Epoch 1909/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.8252 - acc: 0.4500 - val_loss: 0.7680 - val_acc: 0.5556\n",
            "Epoch 1910/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7502 - acc: 0.5167 - val_loss: 0.7679 - val_acc: 0.6000\n",
            "Epoch 1911/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7918 - acc: 0.4917 - val_loss: 0.7679 - val_acc: 0.5556\n",
            "Epoch 1912/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7922 - acc: 0.5083 - val_loss: 0.7711 - val_acc: 0.6000\n",
            "Epoch 1913/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7585 - acc: 0.5417 - val_loss: 0.7768 - val_acc: 0.5444\n",
            "Epoch 1914/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7668 - acc: 0.5333 - val_loss: 0.7780 - val_acc: 0.5778\n",
            "Epoch 1915/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7755 - acc: 0.5083 - val_loss: 0.8060 - val_acc: 0.5444\n",
            "Epoch 1916/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7753 - acc: 0.5667 - val_loss: 0.7978 - val_acc: 0.5778\n",
            "Epoch 1917/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.8039 - acc: 0.5667 - val_loss: 0.7687 - val_acc: 0.6000\n",
            "Epoch 1918/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7669 - acc: 0.5250 - val_loss: 0.7715 - val_acc: 0.5556\n",
            "Epoch 1919/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7753 - acc: 0.5833 - val_loss: 0.7897 - val_acc: 0.5444\n",
            "Epoch 1920/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.8002 - acc: 0.4750 - val_loss: 0.7900 - val_acc: 0.3889\n",
            "Epoch 1921/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7584 - acc: 0.5833 - val_loss: 0.7899 - val_acc: 0.5444\n",
            "Epoch 1922/2048\n",
            "120/120 [==============================] - 0s 331us/step - loss: 0.7751 - acc: 0.5583 - val_loss: 0.7899 - val_acc: 0.5889\n",
            "Epoch 1923/2048\n",
            "120/120 [==============================] - 0s 288us/step - loss: 0.7401 - acc: 0.6167 - val_loss: 0.8023 - val_acc: 0.5889\n",
            "Epoch 1924/2048\n",
            "120/120 [==============================] - 0s 289us/step - loss: 0.7668 - acc: 0.5000 - val_loss: 0.8024 - val_acc: 0.5889\n",
            "Epoch 1925/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.7252 - acc: 0.5667 - val_loss: 0.8038 - val_acc: 0.5556\n",
            "Epoch 1926/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7585 - acc: 0.4833 - val_loss: 0.8039 - val_acc: 0.5889\n",
            "Epoch 1927/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7758 - acc: 0.5333 - val_loss: 0.8082 - val_acc: 0.5444\n",
            "Epoch 1928/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7351 - acc: 0.5167 - val_loss: 0.8038 - val_acc: 0.5778\n",
            "Epoch 1929/2048\n",
            "120/120 [==============================] - 0s 290us/step - loss: 0.7334 - acc: 0.5667 - val_loss: 0.8067 - val_acc: 0.5444\n",
            "Epoch 1930/2048\n",
            "120/120 [==============================] - 0s 370us/step - loss: 0.8169 - acc: 0.4500 - val_loss: 0.8066 - val_acc: 0.5778\n",
            "Epoch 1931/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7613 - acc: 0.5583 - val_loss: 0.7867 - val_acc: 0.5444\n",
            "Epoch 1932/2048\n",
            "120/120 [==============================] - 0s 288us/step - loss: 0.7585 - acc: 0.5917 - val_loss: 0.7871 - val_acc: 0.5444\n",
            "Epoch 1933/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7836 - acc: 0.4917 - val_loss: 0.7874 - val_acc: 0.5778\n",
            "Epoch 1934/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 0.7585 - acc: 0.5083 - val_loss: 0.7874 - val_acc: 0.5778\n",
            "Epoch 1935/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7944 - acc: 0.4583 - val_loss: 0.7961 - val_acc: 0.5778\n",
            "Epoch 1936/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7422 - acc: 0.6000 - val_loss: 0.7769 - val_acc: 0.5556\n",
            "Epoch 1937/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7587 - acc: 0.5417 - val_loss: 0.7940 - val_acc: 0.3889\n",
            "Epoch 1938/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7669 - acc: 0.4917 - val_loss: 0.7939 - val_acc: 0.5444\n",
            "Epoch 1939/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7585 - acc: 0.5250 - val_loss: 0.7949 - val_acc: 0.5444\n",
            "Epoch 1940/2048\n",
            "120/120 [==============================] - 0s 306us/step - loss: 0.7419 - acc: 0.4750 - val_loss: 0.7952 - val_acc: 0.5778\n",
            "Epoch 1941/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7325 - acc: 0.5750 - val_loss: 0.8046 - val_acc: 0.5444\n",
            "Epoch 1942/2048\n",
            "120/120 [==============================] - 0s 301us/step - loss: 0.8169 - acc: 0.5250 - val_loss: 0.8066 - val_acc: 0.3889\n",
            "Epoch 1943/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.7251 - acc: 0.5583 - val_loss: 0.8065 - val_acc: 0.5778\n",
            "Epoch 1944/2048\n",
            "120/120 [==============================] - 0s 288us/step - loss: 0.7336 - acc: 0.5250 - val_loss: 0.7845 - val_acc: 0.5778\n",
            "Epoch 1945/2048\n",
            "120/120 [==============================] - 0s 351us/step - loss: 0.7750 - acc: 0.5417 - val_loss: 0.8050 - val_acc: 0.5778\n",
            "Epoch 1946/2048\n",
            "120/120 [==============================] - 0s 295us/step - loss: 0.7752 - acc: 0.5000 - val_loss: 0.8091 - val_acc: 0.5333\n",
            "Epoch 1947/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.7587 - acc: 0.5000 - val_loss: 0.7841 - val_acc: 0.5444\n",
            "Epoch 1948/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7752 - acc: 0.5417 - val_loss: 0.7853 - val_acc: 0.5444\n",
            "Epoch 1949/2048\n",
            "120/120 [==============================] - 0s 370us/step - loss: 0.7419 - acc: 0.5667 - val_loss: 0.7944 - val_acc: 0.5444\n",
            "Epoch 1950/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7668 - acc: 0.5583 - val_loss: 0.7945 - val_acc: 0.5778\n",
            "Epoch 1951/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 0.7668 - acc: 0.5750 - val_loss: 0.7964 - val_acc: 0.5778\n",
            "Epoch 1952/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7418 - acc: 0.5250 - val_loss: 0.8002 - val_acc: 0.5778\n",
            "Epoch 1953/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.7753 - acc: 0.4667 - val_loss: 0.8074 - val_acc: 0.5889\n",
            "Epoch 1954/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7697 - acc: 0.5500 - val_loss: 0.7921 - val_acc: 0.5556\n",
            "Epoch 1955/2048\n",
            "120/120 [==============================] - 0s 356us/step - loss: 0.7503 - acc: 0.5000 - val_loss: 0.7929 - val_acc: 0.5444\n",
            "Epoch 1956/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7669 - acc: 0.5417 - val_loss: 0.7929 - val_acc: 0.5444\n",
            "Epoch 1957/2048\n",
            "120/120 [==============================] - 0s 324us/step - loss: 0.7529 - acc: 0.6250 - val_loss: 0.7675 - val_acc: 0.5556\n",
            "Epoch 1958/2048\n",
            "120/120 [==============================] - 0s 372us/step - loss: 0.7755 - acc: 0.5500 - val_loss: 0.7857 - val_acc: 0.5444\n",
            "Epoch 1959/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.7732 - acc: 0.4917 - val_loss: 0.8070 - val_acc: 0.5444\n",
            "Epoch 1960/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7926 - acc: 0.4833 - val_loss: 0.7905 - val_acc: 0.5444\n",
            "Epoch 1961/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7585 - acc: 0.6167 - val_loss: 0.7905 - val_acc: 0.5778\n",
            "Epoch 1962/2048\n",
            "120/120 [==============================] - 0s 304us/step - loss: 0.7752 - acc: 0.5333 - val_loss: 0.7912 - val_acc: 0.5444\n",
            "Epoch 1963/2048\n",
            "120/120 [==============================] - 0s 310us/step - loss: 0.7503 - acc: 0.6167 - val_loss: 0.7995 - val_acc: 0.5778\n",
            "Epoch 1964/2048\n",
            "120/120 [==============================] - 0s 295us/step - loss: 0.7718 - acc: 0.4917 - val_loss: 0.7648 - val_acc: 0.5556\n",
            "Epoch 1965/2048\n",
            "120/120 [==============================] - 0s 316us/step - loss: 0.7503 - acc: 0.5583 - val_loss: 0.7705 - val_acc: 0.5889\n",
            "Epoch 1966/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.8085 - acc: 0.5000 - val_loss: 0.7706 - val_acc: 0.5889\n",
            "Epoch 1967/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7419 - acc: 0.4917 - val_loss: 0.7706 - val_acc: 0.5889\n",
            "Epoch 1968/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7919 - acc: 0.4667 - val_loss: 0.7714 - val_acc: 0.5889\n",
            "Epoch 1969/2048\n",
            "120/120 [==============================] - 0s 329us/step - loss: 0.7501 - acc: 0.5833 - val_loss: 0.7715 - val_acc: 0.5889\n",
            "Epoch 1970/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7918 - acc: 0.5167 - val_loss: 0.7776 - val_acc: 0.3889\n",
            "Epoch 1971/2048\n",
            "120/120 [==============================] - 0s 291us/step - loss: 0.8045 - acc: 0.5250 - val_loss: 0.7636 - val_acc: 0.5556\n",
            "Epoch 1972/2048\n",
            "120/120 [==============================] - 0s 296us/step - loss: 0.7921 - acc: 0.5417 - val_loss: 0.7804 - val_acc: 0.5444\n",
            "Epoch 1973/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7752 - acc: 0.5417 - val_loss: 0.7820 - val_acc: 0.5444\n",
            "Epoch 1974/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7168 - acc: 0.6083 - val_loss: 0.7820 - val_acc: 0.5778\n",
            "Epoch 1975/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7669 - acc: 0.6000 - val_loss: 0.7714 - val_acc: 0.5556\n",
            "Epoch 1976/2048\n",
            "120/120 [==============================] - 0s 366us/step - loss: 0.7670 - acc: 0.5333 - val_loss: 0.8016 - val_acc: 0.5444\n",
            "Epoch 1977/2048\n",
            "120/120 [==============================] - 0s 292us/step - loss: 0.8086 - acc: 0.4250 - val_loss: 0.8018 - val_acc: 0.5444\n",
            "Epoch 1978/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.7919 - acc: 0.4750 - val_loss: 0.8017 - val_acc: 0.5778\n",
            "Epoch 1979/2048\n",
            "120/120 [==============================] - 0s 281us/step - loss: 0.8002 - acc: 0.4750 - val_loss: 0.8028 - val_acc: 0.5778\n",
            "Epoch 1980/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.8031 - acc: 0.5083 - val_loss: 0.7868 - val_acc: 0.5444\n",
            "Epoch 1981/2048\n",
            "120/120 [==============================] - 0s 318us/step - loss: 0.7751 - acc: 0.5667 - val_loss: 0.7882 - val_acc: 0.5444\n",
            "Epoch 1982/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.7419 - acc: 0.4917 - val_loss: 0.7949 - val_acc: 0.5444\n",
            "Epoch 1983/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.7345 - acc: 0.6083 - val_loss: 0.8085 - val_acc: 0.5778\n",
            "Epoch 1984/2048\n",
            "120/120 [==============================] - 0s 305us/step - loss: 0.7432 - acc: 0.5250 - val_loss: 0.8030 - val_acc: 0.5444\n",
            "Epoch 1985/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7585 - acc: 0.5417 - val_loss: 0.8079 - val_acc: 0.5778\n",
            "Epoch 1986/2048\n",
            "120/120 [==============================] - 0s 294us/step - loss: 0.8099 - acc: 0.4833 - val_loss: 0.7665 - val_acc: 0.5556\n",
            "Epoch 1987/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7335 - acc: 0.6000 - val_loss: 0.7688 - val_acc: 0.5556\n",
            "Epoch 1988/2048\n",
            "120/120 [==============================] - 0s 328us/step - loss: 0.7758 - acc: 0.6000 - val_loss: 0.7820 - val_acc: 0.5444\n",
            "Epoch 1989/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7836 - acc: 0.5333 - val_loss: 0.7837 - val_acc: 0.5444\n",
            "Epoch 1990/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7753 - acc: 0.5333 - val_loss: 0.7916 - val_acc: 0.5444\n",
            "Epoch 1991/2048\n",
            "120/120 [==============================] - 0s 319us/step - loss: 0.7428 - acc: 0.5833 - val_loss: 0.8047 - val_acc: 0.5444\n",
            "Epoch 1992/2048\n",
            "120/120 [==============================] - 0s 320us/step - loss: 0.7836 - acc: 0.4750 - val_loss: 0.8048 - val_acc: 0.5778\n",
            "Epoch 1993/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7585 - acc: 0.5417 - val_loss: 0.8048 - val_acc: 0.5778\n",
            "Epoch 1994/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7585 - acc: 0.5583 - val_loss: 0.8049 - val_acc: 0.5444\n",
            "Epoch 1995/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 0.7669 - acc: 0.5500 - val_loss: 0.8049 - val_acc: 0.5778\n",
            "Epoch 1996/2048\n",
            "120/120 [==============================] - 0s 367us/step - loss: 0.7920 - acc: 0.4750 - val_loss: 0.7920 - val_acc: 0.3889\n",
            "Epoch 1997/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7751 - acc: 0.5417 - val_loss: 0.7918 - val_acc: 0.5778\n",
            "Epoch 1998/2048\n",
            "120/120 [==============================] - 0s 315us/step - loss: 0.7586 - acc: 0.4583 - val_loss: 0.7954 - val_acc: 0.5444\n",
            "Epoch 1999/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7920 - acc: 0.5000 - val_loss: 0.8096 - val_acc: 0.3889\n",
            "Epoch 2000/2048\n",
            "120/120 [==============================] - 0s 323us/step - loss: 0.7569 - acc: 0.5333 - val_loss: 0.7904 - val_acc: 0.5444\n",
            "Epoch 2001/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7335 - acc: 0.5583 - val_loss: 0.7937 - val_acc: 0.5778\n",
            "Epoch 2002/2048\n",
            "120/120 [==============================] - 0s 311us/step - loss: 0.8006 - acc: 0.5083 - val_loss: 0.7785 - val_acc: 0.5778\n",
            "Epoch 2003/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7757 - acc: 0.5583 - val_loss: 0.7996 - val_acc: 0.5444\n",
            "Epoch 2004/2048\n",
            "120/120 [==============================] - 0s 330us/step - loss: 0.7428 - acc: 0.5083 - val_loss: 0.8104 - val_acc: 0.5444\n",
            "Epoch 2005/2048\n",
            "120/120 [==============================] - 0s 344us/step - loss: 0.7752 - acc: 0.5083 - val_loss: 0.8108 - val_acc: 0.5889\n",
            "Epoch 2006/2048\n",
            "120/120 [==============================] - 0s 344us/step - loss: 0.7674 - acc: 0.5250 - val_loss: 0.8002 - val_acc: 0.5444\n",
            "Epoch 2007/2048\n",
            "120/120 [==============================] - 0s 341us/step - loss: 0.7335 - acc: 0.6000 - val_loss: 0.8002 - val_acc: 0.5778\n",
            "Epoch 2008/2048\n",
            "120/120 [==============================] - 0s 298us/step - loss: 0.7753 - acc: 0.4583 - val_loss: 0.7936 - val_acc: 0.5778\n",
            "Epoch 2009/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7752 - acc: 0.5583 - val_loss: 0.7951 - val_acc: 0.5778\n",
            "Epoch 2010/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7669 - acc: 0.5417 - val_loss: 0.7952 - val_acc: 0.5444\n",
            "Epoch 2011/2048\n",
            "120/120 [==============================] - 0s 379us/step - loss: 0.7617 - acc: 0.5667 - val_loss: 0.8065 - val_acc: 0.5778\n",
            "Epoch 2012/2048\n",
            "120/120 [==============================] - 0s 321us/step - loss: 0.7584 - acc: 0.5833 - val_loss: 0.8066 - val_acc: 0.5444\n",
            "Epoch 2013/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7969 - acc: 0.5333 - val_loss: 0.7747 - val_acc: 0.5889\n",
            "Epoch 2014/2048\n",
            "120/120 [==============================] - 0s 401us/step - loss: 0.7752 - acc: 0.5417 - val_loss: 0.7749 - val_acc: 0.5556\n",
            "Epoch 2015/2048\n",
            "120/120 [==============================] - 0s 358us/step - loss: 0.7252 - acc: 0.5833 - val_loss: 0.7772 - val_acc: 0.5778\n",
            "Epoch 2016/2048\n",
            "120/120 [==============================] - 0s 308us/step - loss: 0.7835 - acc: 0.4750 - val_loss: 0.7773 - val_acc: 0.5778\n",
            "Epoch 2017/2048\n",
            "120/120 [==============================] - 0s 347us/step - loss: 0.7339 - acc: 0.5083 - val_loss: 0.7930 - val_acc: 0.5444\n",
            "Epoch 2018/2048\n",
            "120/120 [==============================] - 0s 333us/step - loss: 0.7752 - acc: 0.5167 - val_loss: 0.7931 - val_acc: 0.3889\n",
            "Epoch 2019/2048\n",
            "120/120 [==============================] - 0s 327us/step - loss: 0.7752 - acc: 0.4917 - val_loss: 0.7980 - val_acc: 0.5444\n",
            "Epoch 2020/2048\n",
            "120/120 [==============================] - 0s 292us/step - loss: 0.7547 - acc: 0.5083 - val_loss: 0.7728 - val_acc: 0.3889\n",
            "Epoch 2021/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.8007 - acc: 0.4667 - val_loss: 0.7725 - val_acc: 0.5556\n",
            "Epoch 2022/2048\n",
            "120/120 [==============================] - 0s 284us/step - loss: 0.7918 - acc: 0.5083 - val_loss: 0.7726 - val_acc: 0.5556\n",
            "Epoch 2023/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.8002 - acc: 0.5000 - val_loss: 0.7758 - val_acc: 0.5889\n",
            "Epoch 2024/2048\n",
            "120/120 [==============================] - 0s 342us/step - loss: 0.7752 - acc: 0.5083 - val_loss: 0.7841 - val_acc: 0.5444\n",
            "Epoch 2025/2048\n",
            "120/120 [==============================] - 0s 397us/step - loss: 0.7921 - acc: 0.4500 - val_loss: 0.7798 - val_acc: 0.5778\n",
            "Epoch 2026/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.8002 - acc: 0.4917 - val_loss: 0.7845 - val_acc: 0.5444\n",
            "Epoch 2027/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7585 - acc: 0.5000 - val_loss: 0.7856 - val_acc: 0.5778\n",
            "Epoch 2028/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.7496 - acc: 0.5833 - val_loss: 0.7894 - val_acc: 0.5778\n",
            "Epoch 2029/2048\n",
            "120/120 [==============================] - 0s 346us/step - loss: 0.7752 - acc: 0.5250 - val_loss: 0.7915 - val_acc: 0.5778\n",
            "Epoch 2030/2048\n",
            "120/120 [==============================] - 0s 293us/step - loss: 0.8108 - acc: 0.4333 - val_loss: 0.8088 - val_acc: 0.5778\n",
            "Epoch 2031/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.7763 - acc: 0.5917 - val_loss: 0.7930 - val_acc: 0.5444\n",
            "Epoch 2032/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.7835 - acc: 0.5583 - val_loss: 0.7930 - val_acc: 0.5778\n",
            "Epoch 2033/2048\n",
            "120/120 [==============================] - 0s 307us/step - loss: 0.7502 - acc: 0.5417 - val_loss: 0.7931 - val_acc: 0.5444\n",
            "Epoch 2034/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7585 - acc: 0.5583 - val_loss: 0.7931 - val_acc: 0.5444\n",
            "Epoch 2035/2048\n",
            "120/120 [==============================] - 0s 335us/step - loss: 0.7502 - acc: 0.5917 - val_loss: 0.7909 - val_acc: 0.5778\n",
            "Epoch 2036/2048\n",
            "120/120 [==============================] - 0s 326us/step - loss: 0.7585 - acc: 0.5083 - val_loss: 0.7909 - val_acc: 0.5778\n",
            "Epoch 2037/2048\n",
            "120/120 [==============================] - 0s 325us/step - loss: 0.8007 - acc: 0.5000 - val_loss: 0.7688 - val_acc: 0.5444\n",
            "Epoch 2038/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.7668 - acc: 0.5583 - val_loss: 0.7895 - val_acc: 0.5778\n",
            "Epoch 2039/2048\n",
            "120/120 [==============================] - 0s 302us/step - loss: 0.7419 - acc: 0.5667 - val_loss: 0.8017 - val_acc: 0.5444\n",
            "Epoch 2040/2048\n",
            "120/120 [==============================] - 0s 297us/step - loss: 0.7677 - acc: 0.4833 - val_loss: 0.7717 - val_acc: 0.5444\n",
            "Epoch 2041/2048\n",
            "120/120 [==============================] - 0s 322us/step - loss: 0.7423 - acc: 0.5750 - val_loss: 0.7942 - val_acc: 0.5444\n",
            "Epoch 2042/2048\n",
            "120/120 [==============================] - 0s 309us/step - loss: 0.8002 - acc: 0.4667 - val_loss: 0.7942 - val_acc: 0.5778\n",
            "Epoch 2043/2048\n",
            "120/120 [==============================] - 0s 332us/step - loss: 0.8002 - acc: 0.4750 - val_loss: 0.7944 - val_acc: 0.3889\n",
            "Epoch 2044/2048\n",
            "120/120 [==============================] - 0s 343us/step - loss: 0.7668 - acc: 0.5500 - val_loss: 0.7943 - val_acc: 0.5778\n",
            "Epoch 2045/2048\n",
            "120/120 [==============================] - 0s 373us/step - loss: 0.7674 - acc: 0.4750 - val_loss: 0.8048 - val_acc: 0.5444\n",
            "Epoch 2046/2048\n",
            "120/120 [==============================] - 0s 313us/step - loss: 0.7585 - acc: 0.5500 - val_loss: 0.8064 - val_acc: 0.5444\n",
            "Epoch 2047/2048\n",
            "120/120 [==============================] - 0s 303us/step - loss: 0.7675 - acc: 0.5667 - val_loss: 0.8080 - val_acc: 0.5444\n",
            "Epoch 2048/2048\n",
            "120/120 [==============================] - 0s 314us/step - loss: 0.7967 - acc: 0.5417 - val_loss: 0.7863 - val_acc: 0.5778\n",
            "Test loss (x_profiles): 0.7863280640708076\n",
            "Test accuracy (x_profiles): 0.5777777857250638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9AXUgJPsphH",
        "colab_type": "text"
      },
      "source": [
        "### Geometric Shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMKehODestJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shapes_dataset_path = 'drive/My Drive/PI 1/Datasets/shapes'\n",
        "\n",
        "triangles_path = shapes_dataset_path + '/triangles/'\n",
        "squares_path = shapes_dataset_path + '/squares/'\n",
        "circles_path = shapes_dataset_path + '/circles/'\n",
        "\n",
        "\n",
        "triangles = find_files(triangles_path)\n",
        "squares = find_files(squares_path)\n",
        "circles = find_files(circles_path)\n",
        "\n",
        "\n",
        "triangle_images = load_images(triangles, triangles_path)\n",
        "square_images = load_images(squares, squares_path)\n",
        "circle_images = load_images(circles, circles_path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}